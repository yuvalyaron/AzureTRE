{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Azure TRE Overview What is Azure TRE? Across the health industry, be it a pharmaceutical company interrogating clinical trial results, or a public health provider analyzing electronic health records, there is the need to enable researchers, analysts, and developers to work with sensitive data sets. Trusted Research Environments (TREs) enable organisations to provide research teams secure access to these data sets along side tooling to ensure a researchers can be productive. Further information on TREs in general can be found in many places, one good resource is HDR UK . The Azure Trusted Research Environment project is an accelerator to assist Microsoft customers and partners who want to build out Trusted Research environments on Azure. This project enables authorized users to deploy and configure secure workspaces and researcher tooling without a dependency on IT teams. This project is typically implemented alongside a data platform that provides research ready datasets to TRE workspaces: TREs are not \u201cone size fits all\u201d, hence although the Azure TRE has a number of out of the box features, the project has been built be extensible, and hence tooling and data platform agnostic. Core features include: Self-service for administrators \u2013 workspace creation and administration Self-service for research teams \u2013 research tooling creation and administration Package and repository mirroring Extensible architecture - build your own service templates as required Azure Active Directory integration Airlock Cost reporting Ready to workspace templates including: Restricted with data exfiltration control Unrestricted for open data Ready to go workspace service templates including: Virtual Desktops: Windows, Linux AzureML (Jupyter, R Studio, VS Code) ML Flow, Gitea","title":"Introducing the AzureTRE"},{"location":"#azure-tre-overview","text":"","title":"Azure TRE Overview"},{"location":"#what-is-azure-tre","text":"Across the health industry, be it a pharmaceutical company interrogating clinical trial results, or a public health provider analyzing electronic health records, there is the need to enable researchers, analysts, and developers to work with sensitive data sets. Trusted Research Environments (TREs) enable organisations to provide research teams secure access to these data sets along side tooling to ensure a researchers can be productive. Further information on TREs in general can be found in many places, one good resource is HDR UK . The Azure Trusted Research Environment project is an accelerator to assist Microsoft customers and partners who want to build out Trusted Research environments on Azure. This project enables authorized users to deploy and configure secure workspaces and researcher tooling without a dependency on IT teams. This project is typically implemented alongside a data platform that provides research ready datasets to TRE workspaces: TREs are not \u201cone size fits all\u201d, hence although the Azure TRE has a number of out of the box features, the project has been built be extensible, and hence tooling and data platform agnostic. Core features include: Self-service for administrators \u2013 workspace creation and administration Self-service for research teams \u2013 research tooling creation and administration Package and repository mirroring Extensible architecture - build your own service templates as required Azure Active Directory integration Airlock Cost reporting Ready to workspace templates including: Restricted with data exfiltration control Unrestricted for open data Ready to go workspace service templates including: Virtual Desktops: Windows, Linux AzureML (Jupyter, R Studio, VS Code) ML Flow, Gitea","title":"What is Azure TRE?"},{"location":"coming-soon/","text":"Coming Soon We're working to improve our documentation, and fill in some gaps. Unfortunately, this particular page is one of the gaps we're looking to fill and isn't yet available. How to Contribute to our Documentation If you have any comments or suggestions about our documentation then you can visit our GitHub project and either raise a new issue, or comment on one of the existing ones. You can find our existing documentation issues on GitHub by clicking on the link below: Existing Documentation Issues Or, you can raise a new issue by clicking on this link: Report an Issue or Make a Suggestion Thank you for your patience and support!","title":"Coming Soon"},{"location":"coming-soon/#coming-soon","text":"We're working to improve our documentation, and fill in some gaps. Unfortunately, this particular page is one of the gaps we're looking to fill and isn't yet available.","title":"Coming Soon"},{"location":"coming-soon/#how-to-contribute-to-our-documentation","text":"If you have any comments or suggestions about our documentation then you can visit our GitHub project and either raise a new issue, or comment on one of the existing ones. You can find our existing documentation issues on GitHub by clicking on the link below: Existing Documentation Issues Or, you can raise a new issue by clicking on this link: Report an Issue or Make a Suggestion Thank you for your patience and support!","title":"How to Contribute to our Documentation"},{"location":"azure-tre-overview/airlock/","text":"Airlock In a Trusted Research Environment (TRE) the workspaces represent a security boundary that enables researchers to access data, execute analysis, apply algorithms and collect reports. The airlock capability is the only mechanism that allows users to import or export data, tools or other file based artefacts in a secure fashion with a human approval. This constitutes the mechanism focused on preventing data exfiltration and securing TRE and its workspaces from inappropriate data, while allowing researchers to work on their projects and execute their tasks. The airlock feature brings several actions: ingress/egress Mechanism; Data movement; Security gates; Approval mechanism and Notifications. As part of TRE's Safe settings all activity must be tracked for auditing purposes. The Airlock feature aims to address these goals: Prevent unauthorised data import or export. Provide a process to allow approved data to be imported through the security boundary of a TRE Workspace. TRE provides functionality to track requests and decisions, supporting cycles of revision, approval or rejection. Data being imported with an airlock import process can be automatically scanned for security issues. Data being exported or imported must be manually reviewed by the Airlock Manager. Notify the requesting researcher of the process progress and/or required actions. All steps within the airlock process are audited. Typically in a TRE, the Airlock feature would be used to allow a researcher to export the outputs of a research project such as summary results. With the airlock, data to be exported must go through a human review, typically undertaken by a data governance team. The Airlock feature will create events on every meaningful step of the process. This will enable increased flexibility by allowing an organization to extend the notification mechanism. Ingress/Egress Mechanism The Airlock allows a TRE user to start the import or export process to a given workspace. A number of milestones must be reached in order to complete a successful import or export. These milestones are defined using the following states: Draft : An Airlock request has been created but has not yet started. The TRE User/Researcher has now access to a storage location and they must identify the data to be processed. At this point the airlock import/export processes allow a single file to be processed. However a compressed file may be used (zip). Submitted : The request was submitted by the researcher (not yet processed). In-Review : The request is ready to be reviewed. This state can be reached directly from Submitted state or after going through a successful security scan (found clean). Approval In-progress : The Airlock request has been approved, however data movement is still ongoing. Approved : The Airlock request has been approved. At this state, data has been securely verified and manually reviewed. The data is now in its final location. For an import process the data is now available in the TRE workspace, it can be accessed by the requestor from within the workspace. Rejection In-progress : The Airlock request has been rejected, however data movement is still ongoing. Rejected : The Airlock request has been rejected. The data in the process was rejected manually by the Airlock Manager. Cancelled : The Airlock request was manually cancelled by the requestor TRE user, a Workspace owner or a TRE administrator. The cancelation is only allowed when the request is not actively changing (i.e. Draft or In-Review state). Blocking In-progress : The Airlock request has been blocked, however data movement is still ongoing. Blocked By Scan : The Airlock request has been blocked. The security analysis found issues in the submitted data and consequently quarantined the data. graph TD A[Researcher wants to export data from TRE Workspace] -->|Request created| B[Request in state Draft] B-->|Researcher gets link to storage container and uploads data| B B-->|Request submitted| C[Submitted] C--> D{Security issues found?} D-->|Yes| E[Blocking In-progress] D-->|No| G[In-Review] E:::temporary--> F((Blocked By Scan)) G-->|Human Review| H{Is data appropriate to export?} H-->|Approve| I[Approval In-progress] H-->|Reject| J[Rejection In-progress] I:::temporary-->K((Approved)) J:::temporary-->L((Rejected)) B-->|Request Canceled| X((Canceled)) G-->|Request Canceled| X H-->|Request Canceled| X classDef temporary stroke-dasharray: 5 5 Airlock state flow diagram for an Airlock export request When an airlock process is created the initial state is Draft and the required infrastructure will get created providing a single container to isolate the data in the request. Once completed, the user will be able to get a link for this container inside the storage account (URL + SAS token) that they can use to upload the desired data to be processed (import or export). This storage location is external for import ( stalimex ) or internal for export ( stalexint ), however only accessible to the requestor (ex: a TRE user/researcher). The user will be able to upload a file to the provided storage location, using any tool of their preference: Azure Storage Explorer or AzCopy which is a command line tool. The user Submits the request (TRE API call) starting the data movement (to the stalimip - import in-progress or stalexip - export in-progress). The airlock request is now in state Submitted . If enabled, the Security Scanning is started. In the case that security flaws are found, the request state becomes Blocking In-progress while the data is moved to blocked storage (either import blocked stalimblocked or export blocked stalexblocked ). In this case, the request is finalized with the state Blocked By Scan . If the Security Scanning does not identify any security flaws, the request state becomes In-Review . Simultaneously, a notification is sent to the Airlock Manager user. The user needs to ask for the container URL using the TRE API (SAS token + URL with READ permission). The Security Scanning can be disabled, changing the request state from Submitted straight to In-Review . The Airlock Manager will manually review the data using the tools of their choice available in the TRE workspace. Once review is completed, the Airlock Manager will have to Approve or Reject the airlock proces, though a TRE API call. At this point, the request will change state to either Approval In-progress or Rejection In-progress , while the data movement occurs moving afterwards to Approved or Rejected accordingly. The data will now be in the final storage destination: stalexapp - export approved or stalimapp - import approved. With this state change, a notification will be triggered to the requestor including the location of the processed data in the form of an URL + SAS token. Data movement For any airlock process, there is data movement either into a TRE workspace (in import process) or from a TRE workspace (in export process). Being a TRE Workspace boundary, there are networking configurations designed to achieve this goal. The data movement will guarantee that the data is automatically verified for security flaws and manually reviewed, before placing data inside the TRE Workspace. Also, the process guarantees that data is not tampered with throughout the process. In an import process, data will transition from more public locations (yet confined to the requestor) to TRE workspace storage, after guaranteeing security automatically and by manual review. In an export process, data will transition from internal locations (available to the requestor) to public locations in the TRE, after going through a manual review. Considering that the Airlock requests may require large data movements, the operations can have longer durations, hence becoming the operations asynchronous. This is why states like Approval In-progress , Rejection In-progress or Blocking In-progress will be set while there are data movement operations. The data movement mechanism is data-driven, allowing an organization to extend how request data transitions between Security Scan The identified data in a airlock proces, will be submited to a security scan. If the security scan identifies issues the data is quarantined and a report is added to the process metadata. Both the requestor and Workspace Owner are notified. For a successful security scan, the data will remain in state In-progress , and accessible to the Workspace Owner. The Security scan will be optional, behind a feature flag enabled by a script The outcome of the security scan will be either the in-progress ( stalexip ) storage or blocked ( stalexblocked ) An airlock process will guarantee that the content being imported/exported is secure. It is envisioned that a set of security gates are identified to be executed successfully for a process to be approved. Approval mechanism The approval mechanism, is bundled with any airlock process, providing a specific way to approve or reject the data. This mechanism will allow the Airlock Managers to explicitly approve/reject the process, after having access to the data. The Airlock Manager users will be able to execute a manual review on the data using the tools available to them in a review TRE Workspace. Once this manual review is executed, Airlock Managers can proactively approve or reject the airlock request. The only goal of the Approval mechanism is to provide a cycle of revision, approval or rejection while tracking the decision. This mechanism will provide access to the data in the airlock process, and will be able to use a VM in TRE workspace. The data review will be the Airlock Manager responsibility It is envisioned that this mechanism to be more flexible and extensible. The Airlock Manager is a role defined at the workspace instance level and assigned to identities. Initially, the Owner role will be used. Notifications Throughout the airlock process, the notification mechanism will notify the relevant people of the process. Both the requestor (TRE User/Researcher) and the Workspace Owner will be notified by email of the relevant process events. Whenever the airlock process changes to a state of Draft , Submitted , Approved , Rejected , Approval In-progress , Rejection In-progress , Blocked By Scan or Cancelled , the process requestor gets notified. When the state changes to In-progress the Workspace Owner (Airlock Manager) gets notified. The Notification mechanism is also data-driven, allowing an organization to extend the notifications behavior. The mechanism is exemplified with a Logic App determining the notifications logic. Notifications will work with All TRE users being AAD users (guests or not), with email defined \u2013 if not, notifications will not be sent. Architecture The Airlock feature is supported by infrastructure at the TRE and workspace level, containing a set of storage accounts. Each Airlock request will provision and use unique storage containers with the request id in its name. graph LR subgraph TRE Workspace E[(stalimapp</br>import approved)] end subgraph TRE A[(stalimex</br>import external)]-->|Request Submitted| B B[(stalimip</br>import in-progress)]-->|Security issues found| D[(stalimblocked</br>import blocked)] B-->|No security issues found| review{Manual</br>Approval} review-->|Rejected| C[(stalimrej</br>import rejected)] review-->|Approved| E end subgraph External data(Data to import)-->A end Data movement in an Airlock import request TRE: stalimex - storage (st) airlock (al) import (im) external (ex) stalimip - storage (st) airlock (al) import (im) in-progress (ip) stalimrej - storage (st) airlock (al) import (im) rejected (rej) stalimblocked - storage (st) airlock (al) import (im) blocked stalexapp - storage (st) airlock (al) export (ex) approved (app) Workspace: stalimapp - workspace storage (st) airlock (al) import (im) approved (app) stalexint - workspace storage (st) airlock (al) export (ex) internal (int) stalexip - workspace storage (st) airlock (al) export (ex) in-progress (ip) stalexrej - workspace storage (st) airlock (al) export (ex) rejected (rej) stalexblocked - workspace storage (st) airlock (al) export (ex) blocked The external storage accounts ( stalimex , stalexapp ), are not bound to any vnet and are accessible (with SAS token) via the internet The internal storage account ( stalexint ) is bound to the workspace vnet, so ONLY TRE Users/Researchers on that workspace can access it The (export) in-progress storage account ( stalexip ) is bound to the workspace vnet The (export) blocked storage account ( stalexblocked ) is bound to the workspace vnet The (export) rejected storage account ( stalexrej ) is bound to the workspace vnet The (import) in-progress storage account ( stalimip ) is bound to the TRE CORE vnet The (import) blocked storage account ( stalimblocked ) is bound to the TRE CORE vnet The (import) rejected storage account ( stalimrej ) is bound to the TRE CORE vnet The (import) approved storage account ( stalimapp ) is bound to the workspace vnet In the TRE Core, the TRE API will provide the airlock API endpoints allowing to advance the process. The TRE API will expose the following methods: Method Endpoint Description POST /api/workspaces/{workspace_id}/requests Create an Airlock request (in Draft ) POST /api/workspaces/{workspace_id}/requests/{airlock_request_id}/link Get the url and token to access an Airlock Request POST /api/workspaces/{workspace_id}/requests/{airlock_request_id}/review Reviews an Airlock request POST /api/workspaces/{workspace_id}/requests/{airlock_request_id}/cancel Cancels an Airlock request Also in the airlock feature there is the Airlock Processor which handles the events that are created throughout the process, signalling state changes from blobs created, status changed or security scans finalized. Airlock flow The following sequence diagram detailing the Airlock feature and its event driven behaviour:","title":"Airlock"},{"location":"azure-tre-overview/airlock/#airlock","text":"In a Trusted Research Environment (TRE) the workspaces represent a security boundary that enables researchers to access data, execute analysis, apply algorithms and collect reports. The airlock capability is the only mechanism that allows users to import or export data, tools or other file based artefacts in a secure fashion with a human approval. This constitutes the mechanism focused on preventing data exfiltration and securing TRE and its workspaces from inappropriate data, while allowing researchers to work on their projects and execute their tasks. The airlock feature brings several actions: ingress/egress Mechanism; Data movement; Security gates; Approval mechanism and Notifications. As part of TRE's Safe settings all activity must be tracked for auditing purposes. The Airlock feature aims to address these goals: Prevent unauthorised data import or export. Provide a process to allow approved data to be imported through the security boundary of a TRE Workspace. TRE provides functionality to track requests and decisions, supporting cycles of revision, approval or rejection. Data being imported with an airlock import process can be automatically scanned for security issues. Data being exported or imported must be manually reviewed by the Airlock Manager. Notify the requesting researcher of the process progress and/or required actions. All steps within the airlock process are audited. Typically in a TRE, the Airlock feature would be used to allow a researcher to export the outputs of a research project such as summary results. With the airlock, data to be exported must go through a human review, typically undertaken by a data governance team. The Airlock feature will create events on every meaningful step of the process. This will enable increased flexibility by allowing an organization to extend the notification mechanism.","title":"Airlock"},{"location":"azure-tre-overview/airlock/#ingressegress-mechanism","text":"The Airlock allows a TRE user to start the import or export process to a given workspace. A number of milestones must be reached in order to complete a successful import or export. These milestones are defined using the following states: Draft : An Airlock request has been created but has not yet started. The TRE User/Researcher has now access to a storage location and they must identify the data to be processed. At this point the airlock import/export processes allow a single file to be processed. However a compressed file may be used (zip). Submitted : The request was submitted by the researcher (not yet processed). In-Review : The request is ready to be reviewed. This state can be reached directly from Submitted state or after going through a successful security scan (found clean). Approval In-progress : The Airlock request has been approved, however data movement is still ongoing. Approved : The Airlock request has been approved. At this state, data has been securely verified and manually reviewed. The data is now in its final location. For an import process the data is now available in the TRE workspace, it can be accessed by the requestor from within the workspace. Rejection In-progress : The Airlock request has been rejected, however data movement is still ongoing. Rejected : The Airlock request has been rejected. The data in the process was rejected manually by the Airlock Manager. Cancelled : The Airlock request was manually cancelled by the requestor TRE user, a Workspace owner or a TRE administrator. The cancelation is only allowed when the request is not actively changing (i.e. Draft or In-Review state). Blocking In-progress : The Airlock request has been blocked, however data movement is still ongoing. Blocked By Scan : The Airlock request has been blocked. The security analysis found issues in the submitted data and consequently quarantined the data. graph TD A[Researcher wants to export data from TRE Workspace] -->|Request created| B[Request in state Draft] B-->|Researcher gets link to storage container and uploads data| B B-->|Request submitted| C[Submitted] C--> D{Security issues found?} D-->|Yes| E[Blocking In-progress] D-->|No| G[In-Review] E:::temporary--> F((Blocked By Scan)) G-->|Human Review| H{Is data appropriate to export?} H-->|Approve| I[Approval In-progress] H-->|Reject| J[Rejection In-progress] I:::temporary-->K((Approved)) J:::temporary-->L((Rejected)) B-->|Request Canceled| X((Canceled)) G-->|Request Canceled| X H-->|Request Canceled| X classDef temporary stroke-dasharray: 5 5 Airlock state flow diagram for an Airlock export request When an airlock process is created the initial state is Draft and the required infrastructure will get created providing a single container to isolate the data in the request. Once completed, the user will be able to get a link for this container inside the storage account (URL + SAS token) that they can use to upload the desired data to be processed (import or export). This storage location is external for import ( stalimex ) or internal for export ( stalexint ), however only accessible to the requestor (ex: a TRE user/researcher). The user will be able to upload a file to the provided storage location, using any tool of their preference: Azure Storage Explorer or AzCopy which is a command line tool. The user Submits the request (TRE API call) starting the data movement (to the stalimip - import in-progress or stalexip - export in-progress). The airlock request is now in state Submitted . If enabled, the Security Scanning is started. In the case that security flaws are found, the request state becomes Blocking In-progress while the data is moved to blocked storage (either import blocked stalimblocked or export blocked stalexblocked ). In this case, the request is finalized with the state Blocked By Scan . If the Security Scanning does not identify any security flaws, the request state becomes In-Review . Simultaneously, a notification is sent to the Airlock Manager user. The user needs to ask for the container URL using the TRE API (SAS token + URL with READ permission). The Security Scanning can be disabled, changing the request state from Submitted straight to In-Review . The Airlock Manager will manually review the data using the tools of their choice available in the TRE workspace. Once review is completed, the Airlock Manager will have to Approve or Reject the airlock proces, though a TRE API call. At this point, the request will change state to either Approval In-progress or Rejection In-progress , while the data movement occurs moving afterwards to Approved or Rejected accordingly. The data will now be in the final storage destination: stalexapp - export approved or stalimapp - import approved. With this state change, a notification will be triggered to the requestor including the location of the processed data in the form of an URL + SAS token.","title":"Ingress/Egress Mechanism"},{"location":"azure-tre-overview/airlock/#data-movement","text":"For any airlock process, there is data movement either into a TRE workspace (in import process) or from a TRE workspace (in export process). Being a TRE Workspace boundary, there are networking configurations designed to achieve this goal. The data movement will guarantee that the data is automatically verified for security flaws and manually reviewed, before placing data inside the TRE Workspace. Also, the process guarantees that data is not tampered with throughout the process. In an import process, data will transition from more public locations (yet confined to the requestor) to TRE workspace storage, after guaranteeing security automatically and by manual review. In an export process, data will transition from internal locations (available to the requestor) to public locations in the TRE, after going through a manual review. Considering that the Airlock requests may require large data movements, the operations can have longer durations, hence becoming the operations asynchronous. This is why states like Approval In-progress , Rejection In-progress or Blocking In-progress will be set while there are data movement operations. The data movement mechanism is data-driven, allowing an organization to extend how request data transitions between","title":"Data movement"},{"location":"azure-tre-overview/airlock/#security-scan","text":"The identified data in a airlock proces, will be submited to a security scan. If the security scan identifies issues the data is quarantined and a report is added to the process metadata. Both the requestor and Workspace Owner are notified. For a successful security scan, the data will remain in state In-progress , and accessible to the Workspace Owner. The Security scan will be optional, behind a feature flag enabled by a script The outcome of the security scan will be either the in-progress ( stalexip ) storage or blocked ( stalexblocked ) An airlock process will guarantee that the content being imported/exported is secure. It is envisioned that a set of security gates are identified to be executed successfully for a process to be approved.","title":"Security Scan"},{"location":"azure-tre-overview/airlock/#approval-mechanism","text":"The approval mechanism, is bundled with any airlock process, providing a specific way to approve or reject the data. This mechanism will allow the Airlock Managers to explicitly approve/reject the process, after having access to the data. The Airlock Manager users will be able to execute a manual review on the data using the tools available to them in a review TRE Workspace. Once this manual review is executed, Airlock Managers can proactively approve or reject the airlock request. The only goal of the Approval mechanism is to provide a cycle of revision, approval or rejection while tracking the decision. This mechanism will provide access to the data in the airlock process, and will be able to use a VM in TRE workspace. The data review will be the Airlock Manager responsibility It is envisioned that this mechanism to be more flexible and extensible. The Airlock Manager is a role defined at the workspace instance level and assigned to identities. Initially, the Owner role will be used.","title":"Approval mechanism"},{"location":"azure-tre-overview/airlock/#notifications","text":"Throughout the airlock process, the notification mechanism will notify the relevant people of the process. Both the requestor (TRE User/Researcher) and the Workspace Owner will be notified by email of the relevant process events. Whenever the airlock process changes to a state of Draft , Submitted , Approved , Rejected , Approval In-progress , Rejection In-progress , Blocked By Scan or Cancelled , the process requestor gets notified. When the state changes to In-progress the Workspace Owner (Airlock Manager) gets notified. The Notification mechanism is also data-driven, allowing an organization to extend the notifications behavior. The mechanism is exemplified with a Logic App determining the notifications logic. Notifications will work with All TRE users being AAD users (guests or not), with email defined \u2013 if not, notifications will not be sent.","title":"Notifications"},{"location":"azure-tre-overview/airlock/#architecture","text":"The Airlock feature is supported by infrastructure at the TRE and workspace level, containing a set of storage accounts. Each Airlock request will provision and use unique storage containers with the request id in its name. graph LR subgraph TRE Workspace E[(stalimapp</br>import approved)] end subgraph TRE A[(stalimex</br>import external)]-->|Request Submitted| B B[(stalimip</br>import in-progress)]-->|Security issues found| D[(stalimblocked</br>import blocked)] B-->|No security issues found| review{Manual</br>Approval} review-->|Rejected| C[(stalimrej</br>import rejected)] review-->|Approved| E end subgraph External data(Data to import)-->A end Data movement in an Airlock import request TRE: stalimex - storage (st) airlock (al) import (im) external (ex) stalimip - storage (st) airlock (al) import (im) in-progress (ip) stalimrej - storage (st) airlock (al) import (im) rejected (rej) stalimblocked - storage (st) airlock (al) import (im) blocked stalexapp - storage (st) airlock (al) export (ex) approved (app) Workspace: stalimapp - workspace storage (st) airlock (al) import (im) approved (app) stalexint - workspace storage (st) airlock (al) export (ex) internal (int) stalexip - workspace storage (st) airlock (al) export (ex) in-progress (ip) stalexrej - workspace storage (st) airlock (al) export (ex) rejected (rej) stalexblocked - workspace storage (st) airlock (al) export (ex) blocked The external storage accounts ( stalimex , stalexapp ), are not bound to any vnet and are accessible (with SAS token) via the internet The internal storage account ( stalexint ) is bound to the workspace vnet, so ONLY TRE Users/Researchers on that workspace can access it The (export) in-progress storage account ( stalexip ) is bound to the workspace vnet The (export) blocked storage account ( stalexblocked ) is bound to the workspace vnet The (export) rejected storage account ( stalexrej ) is bound to the workspace vnet The (import) in-progress storage account ( stalimip ) is bound to the TRE CORE vnet The (import) blocked storage account ( stalimblocked ) is bound to the TRE CORE vnet The (import) rejected storage account ( stalimrej ) is bound to the TRE CORE vnet The (import) approved storage account ( stalimapp ) is bound to the workspace vnet In the TRE Core, the TRE API will provide the airlock API endpoints allowing to advance the process. The TRE API will expose the following methods: Method Endpoint Description POST /api/workspaces/{workspace_id}/requests Create an Airlock request (in Draft ) POST /api/workspaces/{workspace_id}/requests/{airlock_request_id}/link Get the url and token to access an Airlock Request POST /api/workspaces/{workspace_id}/requests/{airlock_request_id}/review Reviews an Airlock request POST /api/workspaces/{workspace_id}/requests/{airlock_request_id}/cancel Cancels an Airlock request Also in the airlock feature there is the Airlock Processor which handles the events that are created throughout the process, signalling state changes from blobs created, status changed or security scans finalized.","title":"Architecture"},{"location":"azure-tre-overview/airlock/#airlock-flow","text":"The following sequence diagram detailing the Airlock feature and its event driven behaviour:","title":"Airlock flow"},{"location":"azure-tre-overview/architecture/","text":"Azure TRE Architecture The Azure Trusted Research Environment (TRE) consists of multiple components, all encapsulated in networks with restricted ingress- & egress traffic. There is one network for the core components and one network per Workspace. All traffic has to be explicitly allowed by the Application Gateway or the Firewall. The Azure resources outside the network boundries of the Azure TRE are Azure Active Directory, Microsoft Graph and TRE Management. TRE Management are resources used during deployment. The Azure TRE core plane consists of two groups of components: API & Composition Service Shared Services The TRE API is a service that users can interact with to request changes to workspaces e.g., to create, update, delete workspaces and workspace services inside each workspace. The Composition Service is doing the actual work of mutating the state of each Workspace including the Workspace Services. Ingress/egress components governs all inbound and outbound traffic from the public Internet to and from Azure TRE including the Workspaces. The Firewall Service is managing the egress rules of the Firewall. Shared Services are services available to all Workspaces. Source Mirror can mirror source repositories such as GitHub, but only allowing read-access, hence data from a Workspace cannot be pushed to a source repository. Package Mirror is also a read-only front for developer/researcher application package services like NPM, PyPI, and NuGet and operating system application package services like apt-get and Windows Package Manager (winget). Azure Resources The following diagram shows the Azure components deployed as part of a typical TRE deployment. The exact configuration will vary depending on the specific deployment. For a full breakdown of Azure Resources see Azure TRE Resources Breakdown Composition Service The Composition Service is responsible for managing and mutating Workspaces and Workspace Services. It consists of multiple components: Component Name Responsibility / Description TRE API An API responsible for performing all operations on Workspaces and managing Workspace Templates. Configuration Store Keeping the state of Workspaces and Workspace Templates. The store uses Cosmos DB (SQL) . Service Bus Azure Service Bus responsible for reliable delivery of messages between components. Resource Processor Responsible for starting the process of mutating a Workspace via a Workspace Template. A Workspace is an instance of a Workspace Template. A Workspace Template is implemented as a Porter bundle - read more about Authoring workspaces templates . A Porter bundle is a fully encapsulated versioned bundle with everything needed (binaries, scripts, IaC templates etc.) to provision an instance of Workspace Template. To automate Porter it needs a place to live in Azure TRE. The home chosen for Porter to run was a Linux virtual machine. This Azure TRE component encompassing Porter and its dependencies is called Resource Processor . During the deployment of Resource Processor itself it is given the credentials of a managed identity with the privileges to modify and deploy resources to the subscription associated with the Azure TRE instance. Resource Processor later then uses these credentials to receive and send Service Bus messages, authorizes Porter to deploy Porter bundles and to access the storage account to update installation data. The logic in Resource Processor is written in Python. The Resource Processor implementation is located in resource_processor folder of the repository. The TRE Administrator can register a Porter bundle to use the Composition Service to provision instances of the Workspace Templates. This requires: The Porter bundle to be pushed to the Azure Container Registry (ACR). Registering the Workspace through the API. Details on how to register a Workspace Template . Provisioning a Workspace The flow to provision a Workspace is as follows (the flow is the same for all kinds of mutations to a Workspace): TRE Admin sends an HTTP request to the TRE API to create a new Workspace. The request contains information like the name of the Workspace, the Workspace Template to use, and the parameters required for the Workspace Template (Workspace Templates can expose the parameters via a JSON Schema ). The API saves the desired state of the Workspace in the Configuration Store. The API sends a command message with the Workspace Template reference and parameters to the workspacequeue . { \"action\" : \"install\" , \"id\" : \"base\" , \"name\" : \"BaseWorkspaceTemplate\" , \"version\" : \"1.0\" , \"parameters\" : { \"param1\" : \"value1\" } } The Resource Processor picks up the new message from the service bus queue. The Resource Processor processes the command by executing the Porter bundle (the implementation of a Workspace Template). # simplified for readability porter <action> --reference <ACR name>.azurecr.io/bundles/<name>:<version> --params key = value --cred <credentials set name or file> # Example porter install --reference msfttreacr.azurecr.io/bundles/BaseWorkspaceTemplate:1.0 --params param1 = value1 --cred arm_auth_local_debugging.json Deployments are carried out against the Azure Subscription using a User Assigned Managed Identity. The arm_auth_local_debugging.json tells Porter where the credential information can be found and for the Resource Processor they are set as environment variables. Porter bundle actions are required to be idempotent, so if a deployment fails, the Resource Processor can retry. The Porter Docker bundle is pulled from the Azure Container Registry (ACR) and executed. The Porter bundle executes against Azure Resource Manager to provision Azure resources. Any kind of infrastructure of code frameworks like ARM, Terraform, or Pulumi can be used or scripted via PowerShell or Azure CLI. Porter stores state and outputs in Azure Storage Containers. State for keeping persistent state between executions of a bundled with the same Workspace. For the time being, the Porter bundle updates Firewall rules directly setting egress rules. An enhancement to implement a Shared Firewall services is planned ( #882 ). The Resource Processor sends events to the deploymentstatus queue on state changes and informs if the deployment succeeded or failed. The API receives the status of the Porter bundle execution. The API updates the status of the Porter bundle execution in the Configuration Store.","title":"System Architecture"},{"location":"azure-tre-overview/architecture/#azure-tre-architecture","text":"The Azure Trusted Research Environment (TRE) consists of multiple components, all encapsulated in networks with restricted ingress- & egress traffic. There is one network for the core components and one network per Workspace. All traffic has to be explicitly allowed by the Application Gateway or the Firewall. The Azure resources outside the network boundries of the Azure TRE are Azure Active Directory, Microsoft Graph and TRE Management. TRE Management are resources used during deployment. The Azure TRE core plane consists of two groups of components: API & Composition Service Shared Services The TRE API is a service that users can interact with to request changes to workspaces e.g., to create, update, delete workspaces and workspace services inside each workspace. The Composition Service is doing the actual work of mutating the state of each Workspace including the Workspace Services. Ingress/egress components governs all inbound and outbound traffic from the public Internet to and from Azure TRE including the Workspaces. The Firewall Service is managing the egress rules of the Firewall. Shared Services are services available to all Workspaces. Source Mirror can mirror source repositories such as GitHub, but only allowing read-access, hence data from a Workspace cannot be pushed to a source repository. Package Mirror is also a read-only front for developer/researcher application package services like NPM, PyPI, and NuGet and operating system application package services like apt-get and Windows Package Manager (winget).","title":"Azure TRE Architecture"},{"location":"azure-tre-overview/architecture/#azure-resources","text":"The following diagram shows the Azure components deployed as part of a typical TRE deployment. The exact configuration will vary depending on the specific deployment. For a full breakdown of Azure Resources see Azure TRE Resources Breakdown","title":"Azure Resources"},{"location":"azure-tre-overview/architecture/#composition-service","text":"The Composition Service is responsible for managing and mutating Workspaces and Workspace Services. It consists of multiple components: Component Name Responsibility / Description TRE API An API responsible for performing all operations on Workspaces and managing Workspace Templates. Configuration Store Keeping the state of Workspaces and Workspace Templates. The store uses Cosmos DB (SQL) . Service Bus Azure Service Bus responsible for reliable delivery of messages between components. Resource Processor Responsible for starting the process of mutating a Workspace via a Workspace Template. A Workspace is an instance of a Workspace Template. A Workspace Template is implemented as a Porter bundle - read more about Authoring workspaces templates . A Porter bundle is a fully encapsulated versioned bundle with everything needed (binaries, scripts, IaC templates etc.) to provision an instance of Workspace Template. To automate Porter it needs a place to live in Azure TRE. The home chosen for Porter to run was a Linux virtual machine. This Azure TRE component encompassing Porter and its dependencies is called Resource Processor . During the deployment of Resource Processor itself it is given the credentials of a managed identity with the privileges to modify and deploy resources to the subscription associated with the Azure TRE instance. Resource Processor later then uses these credentials to receive and send Service Bus messages, authorizes Porter to deploy Porter bundles and to access the storage account to update installation data. The logic in Resource Processor is written in Python. The Resource Processor implementation is located in resource_processor folder of the repository. The TRE Administrator can register a Porter bundle to use the Composition Service to provision instances of the Workspace Templates. This requires: The Porter bundle to be pushed to the Azure Container Registry (ACR). Registering the Workspace through the API. Details on how to register a Workspace Template .","title":"Composition Service"},{"location":"azure-tre-overview/architecture/#provisioning-a-workspace","text":"The flow to provision a Workspace is as follows (the flow is the same for all kinds of mutations to a Workspace): TRE Admin sends an HTTP request to the TRE API to create a new Workspace. The request contains information like the name of the Workspace, the Workspace Template to use, and the parameters required for the Workspace Template (Workspace Templates can expose the parameters via a JSON Schema ). The API saves the desired state of the Workspace in the Configuration Store. The API sends a command message with the Workspace Template reference and parameters to the workspacequeue . { \"action\" : \"install\" , \"id\" : \"base\" , \"name\" : \"BaseWorkspaceTemplate\" , \"version\" : \"1.0\" , \"parameters\" : { \"param1\" : \"value1\" } } The Resource Processor picks up the new message from the service bus queue. The Resource Processor processes the command by executing the Porter bundle (the implementation of a Workspace Template). # simplified for readability porter <action> --reference <ACR name>.azurecr.io/bundles/<name>:<version> --params key = value --cred <credentials set name or file> # Example porter install --reference msfttreacr.azurecr.io/bundles/BaseWorkspaceTemplate:1.0 --params param1 = value1 --cred arm_auth_local_debugging.json Deployments are carried out against the Azure Subscription using a User Assigned Managed Identity. The arm_auth_local_debugging.json tells Porter where the credential information can be found and for the Resource Processor they are set as environment variables. Porter bundle actions are required to be idempotent, so if a deployment fails, the Resource Processor can retry. The Porter Docker bundle is pulled from the Azure Container Registry (ACR) and executed. The Porter bundle executes against Azure Resource Manager to provision Azure resources. Any kind of infrastructure of code frameworks like ARM, Terraform, or Pulumi can be used or scripted via PowerShell or Azure CLI. Porter stores state and outputs in Azure Storage Containers. State for keeping persistent state between executions of a bundled with the same Workspace. For the time being, the Porter bundle updates Firewall rules directly setting egress rules. An enhancement to implement a Shared Firewall services is planned ( #882 ). The Resource Processor sends events to the deploymentstatus queue on state changes and informs if the deployment succeeded or failed. The API receives the status of the Porter bundle execution. The API updates the status of the Porter bundle execution in the Configuration Store.","title":"Provisioning a Workspace"},{"location":"azure-tre-overview/compliance-info/","text":"Compliance Information Info Coming soon We're working to improve our documentation, and fill in some gaps. Unfortunately, this particular page is one of the gaps we're looking to fill and isn't yet available. How to Contribute to our Documentation If you have any comments or suggestions about our documentation then you can visit our GitHub project and either raise a new issue, or comment on one of the existing ones. You can find our existing documentation issues on GitHub by clicking on the link below: Existing Documentation Issues Or, you can raise a new issue by clicking on this link: Report an Issue or Make a Suggestion Thank you for your patience and support!","title":"Compliance Information"},{"location":"azure-tre-overview/compliance-info/#compliance-information","text":"Info Coming soon We're working to improve our documentation, and fill in some gaps. Unfortunately, this particular page is one of the gaps we're looking to fill and isn't yet available.","title":"Compliance Information"},{"location":"azure-tre-overview/compliance-info/#how-to-contribute-to-our-documentation","text":"If you have any comments or suggestions about our documentation then you can visit our GitHub project and either raise a new issue, or comment on one of the existing ones. You can find our existing documentation issues on GitHub by clicking on the link below: Existing Documentation Issues Or, you can raise a new issue by clicking on this link: Report an Issue or Make a Suggestion Thank you for your patience and support!","title":"How to Contribute to our Documentation"},{"location":"azure-tre-overview/cost-reporting/","text":"Cost Reporting The exact running costs will depend on the number of workspaces you have deployed, the workspace services you have enabled within them and the Azure Data center region. TRE users can use the Azure TRE cost API to get a report of the running costs of TRE resources according to their role. TRE provides a set of cost APIs which generates costs reports by custom timeframe, and level of details according to user's role. Cost APIs are based on Azure Cost Management and TRE Templates azure resource tagging , Azure resources must be tagged when authoring new template. Cost APIs Method Endpoint Description Allowed Roles Level of details GET /api/costs Get overall costs of a TRE Instance TRE Admin Core services, Shared services, workspaces GET /api/workspace/{workspace_id}/costs Get workspace costs TRE Admin, Workspace Owner Workspace, workspace services, user resources Get overall cost report Description Get overall cost report for TRE instance (core services), per shared services and per workspace Authorization Only TRE Admin can call this url, others will get unauthorized Endpoint GET /api/costs Query Parameters Parameter name Type Description Default Value from, to datetime Custom time period, up to 1 year timeframe, iso-8601 format Month to date period granularity Enum (Daily, None) The granularity of rows in the query. None Output { \"coreServices\" : [ { \"date\" : \"\" , \"cost\" : \"\" , \"currency\" : \"\" } ], \"sharedServices\" : [ { \"id\" : \"shared service id\" , \"name\" : \"shared service name\" , \"costs\" : [ { \"date\" : \"\" , \"cost\" : \"\" , \"currency\" : \"\" } ] }], \"workspaces\" : [ { \"id\" : \"workspace id\" , \"name\" : \"workspace name\" , \"costs\" :[ { \"date\" : \"\" , \"cost\" : \"\" , \"currency\" : \"\" } ]} ] } Get workspace cost report Description Get overall cost report for a specific workspace Authorization Only TRE Admin and the workspace owner can call this url, others will get unauthorized Input GET /api/workspaces/{workspace_id}/costs Query Parameters Parameter name Type Description Default Value from, to datetime Custom time period, up to 1 year timeframe, iso-8601 format Month to date period granularity Enum (Daily, None) The granularity of rows in the query. None workspace_id Guid The workspace id to generate report for Required field for workspace and user resource level apis Output { \"id\" : \"workspace id\" , \"name\" : \"workspace name\" , \"workspaceServices\" :[{ \"id\" : \"workspace service id\" , \"name\" : \"workspace service name\" , \"costs\" :[{ \"date\" : \"\" , \"cost\" : \"\" , \"currency\" : \"\" }], \"userResources\" :[{ \"id\" : \"user resource id\" , \"name\" : \"user resource name\" , \"costs\" :[{ \"date\" : \"\" , \"cost\" : \"\" , \"currency\" : \"\" }], }] }] } Sequence Diagram source Limitations and notes Cost and usage data is typically available in Cost Management within 8-24 hours. Tags aren't applied to historical data, template authors need to make sure all relevant Azure resources of a TRE resource are tagged as instructed . Cost records might include multiple currencies for the same date and TRE resource. Once cost data becomes available in Cost Management, it will be retained for at least seven years. Only the last 13 months is available from the TRE Cost API and Azure Portal. For historical data before 13 months, please use Exports or the UsageDetails API . There are several Azure Offers that currently are not supported yet, Azure Offers are types of Azure subscriptions, for full list of supported and unspported Azure Offers please refer to Supported Microsoft Azure offers , Azure TRE will not display costs for unsupported Azure subscriptions. For more information please refer to Understand Cost Management data and Cost API swagger docs. Azure Resources Tagging TRE Cost Reporting is based on Azure tagging to be able to generate cost report for core services, shared services, workspace, workspace services and user resources. Templates authors need to make sure that underling Azure resources are tagged with the following tags: Tag Value Applies to tre_id Unique ID of the TRE instance All resources of a TRE instance tre_core_service_id Unique ID of the TRE instance All TRE core azure resources shared_service_id The shared service unique ID Shared Services workspace_id The workspace unique ID Workspaces, Workspace Services and User Resources workspace_service_id The workspace service unique ID Workspace Services and User Resources user_resource_id The user resoruce unique ID User Resources Notes Main Azure Container Registry and Storage Account are not be tagged as those resources are used to spin up more than one Azure TRE Instance. There are some cases in which azure resources cannot get tagged by template author due to different reasons, for example services get deployed outside of TRE (Example being Cyclecloud or Cromwell on Azure), or services which doesn't support tagging for cost management (for example Azure ML compute). for the full list of tag support of Azure see this article . TRE Cost API Logic Cost management query API, which Azure TRE Cost APIs are based upon, returns a flat result of all cost with every tag combination which exists on the filtered resources by the provided tag, meaning that a resource which has tre_id, tre_core_service_id, tre_workspace_id, tre_workspace_service_id, and tre_user_resource_id will get be summarized by all those tags. if filtered resources have more tags, those tags will appear in the result. To rollup untagged resources into workspace costs Azure TRE cost API first calls Azure Resource Manager to get all resource group names which are tagged with the workspace_id and passes those names into Azure Cost Management Query API as a filter and group by resource group along with the tag name. untagged costs results will apear in with an empty tag name and get aggregated using the resource group and relevent the workspace id. Azure TRE Cost API joins this response with the hierarchical structure of the requested report. Cost management query API Request example @SUBSCRIPTION = FILL_YOUR_SUBSCRIPTION_ID @COST_API_URI = https://management.azure.com/subscriptions/{{SUBSCRIPTION}}/providers/Microsoft.CostManagement @COST_API_VERSION = 2021-10-01 @TRE_ID = mytre @TIME_FROM = MM/DD/YYYY @TIME_TO = MM/DD/YYYY POST {{COST_API_URI}}/query?api-version={{COST_API_VERSION}}&$expand=properties/data Authorization: {{$aadToken $aadV2TenantId}} Content-Type: application/json Payload { \"type\" : \"ActualCost\" , \"timeframe\" : \"Custom\" , // can be also BillingMonthToDate|MonthToDate|TheLastBillingMonth|TheLastMonth|WeekToDate according to input \"timePeriod\" : { \"from\" : \"{{TIME_FROM}}\" , \"to\" : \"{{TIME_TO}}\" }, \"dataset\" : { \"granularity\" : \"None\" , // can be also \"Daily\" for total costs \"aggregation\" : { \"totalCost\" : { \"name\" : \"PreTaxCost\" , // can be also 'UsageQuantity','Cost','CostUSD','PreTaxCostUSD' (up to two aggregations) \"function\" : \"Sum\" } }, \"filter\" : { \"or\" : [ { \"dimensions\" : { \"name\" : \"ResourceGroup\" , \"operator\" : \"In\" , \"values\" : [ \"{{RG_NAME}}\" ] } }, { \"tags\" : { \"name\" : \"{{TAG_KEY}}\" , \"operator\" : \"In\" , \"values\" : [ \"{{TAG_VALUE}}\" , ] } } ] }, \"grouping\" : [ { \"type\" : \"Dimension\" , \"name\" : \"ResourceGroup\" }, { \"type\" : \"Tag\" , } ] } } Response { \"id\" : \"subscriptions/xxxxxxxxxxxxx/providers/Microsoft.CostManagement/query/ec1f0eae-9343-4f4e-a0c0-dd219a66efc4\" , \"name\" : \"ec1f0eae-9343-4f4e-a0c0-dd219a66efc4\" , \"type\" : \"Microsoft.CostManagement/query\" , \"location\" : null , \"sku\" : null , \"eTag\" : null , \"properties\" : { \"nextLink\" : null , \"columns\" : [ { \"name\" : \"PreTaxCost\" , \"type\" : \"Number\" }, { \"name\" : \"ResourceGroup\" , \"type\" : \"String\" }, { \"name\" : \"Tag\" , \"type\" : \"String\" }, { \"name\" : \"Currency\" , \"type\" : \"String\" } ], \"rows\" : [ [ 0.00055748658857886549 , \"rg-mytre\" , \"\" , \"USD\" ], [ 3.9306515711531222 , \"rg-mytre\" , \"\\\"tre_core_service\\\":\\\"mytre\\\"\" , \"USD\" ], [ 11.66335497490112 , \"rg-mytre\" , \"\\\"tre_id\\\":\\\"mytre\\\"\" , \"USD\" ], [ 0.033 , \"rg-mytre\" , \"\\\"tre_shared_service\\\":\\\"2fea\\\"\" , \"USD\" ], [ 3.62175702964083 , \"rg-mytre\" , \"\\\"tre_shared_service\\\":\\\"4a5b\\\"\" , \"USD\" ], [ 0.093523886643774659 , \"rg-mytre-ws-5e86\" , \"\\\"tre_user_resource_id\\\":\\\"126d\\\"\" , \"USD\" ], [ 0.078465743393993009 , \"rg-mytre-ws-5e86\" , \"\\\"tre_user_resource_id\\\":\\\"2627\\\"\" , \"USD\" ], [ 0.20275980676694544 , \"rg-mytre-ws-5e86\" , \"\\\"tre_user_resource_id\\\":\\\"319e\\\"\" , \"USD\" ], [ 0.17165788614506686 , \"rg-mytre-ws-af30\" , \"\\\"tre_user_resource_id\\\":\\\"3370\\\"\" , \"USD\" ], [ 0.17518017912599823 , \"rg-mytre-ws-af30\" , \"\\\"tre_user_resource_id\\\":\\\"b2be\\\"\" , \"USD\" ], [ 0.00015748658857886549 , \"rg-mytre-ws-5e86\" , \"\" , \"USD\" ], [ 0.39905729127776768 , \"rg-mytre-ws-5e86\" , \"\\\"tre_workspace_id\\\":\\\"5e86\\\"\" , \"USD\" ], [ 0.98272254462049369 , \"rg-mytre-ws-af30\" , \"\\\"tre_workspace_id\\\":\\\"af30\\\"\" , \"USD\" ], [ 0.17198963003776765 , \"rg-mytre-ws-5e86\" , \"\\\"tre_workspace_service\\\":\\\"8d0a\\\"\" , \"USD\" ], [ 0.54959787203801058 , \"rg-mytre-ws-af30\" , \"\\\"tre_workspace_service\\\":\\\"e70d\\\"\" , \"USD\" ] ] } }","title":"Cost Reporting"},{"location":"azure-tre-overview/cost-reporting/#cost-reporting","text":"The exact running costs will depend on the number of workspaces you have deployed, the workspace services you have enabled within them and the Azure Data center region. TRE users can use the Azure TRE cost API to get a report of the running costs of TRE resources according to their role. TRE provides a set of cost APIs which generates costs reports by custom timeframe, and level of details according to user's role. Cost APIs are based on Azure Cost Management and TRE Templates azure resource tagging , Azure resources must be tagged when authoring new template.","title":"Cost Reporting"},{"location":"azure-tre-overview/cost-reporting/#cost-apis","text":"Method Endpoint Description Allowed Roles Level of details GET /api/costs Get overall costs of a TRE Instance TRE Admin Core services, Shared services, workspaces GET /api/workspace/{workspace_id}/costs Get workspace costs TRE Admin, Workspace Owner Workspace, workspace services, user resources","title":"Cost APIs"},{"location":"azure-tre-overview/cost-reporting/#get-overall-cost-report","text":"Description Get overall cost report for TRE instance (core services), per shared services and per workspace Authorization Only TRE Admin can call this url, others will get unauthorized Endpoint GET /api/costs Query Parameters Parameter name Type Description Default Value from, to datetime Custom time period, up to 1 year timeframe, iso-8601 format Month to date period granularity Enum (Daily, None) The granularity of rows in the query. None Output { \"coreServices\" : [ { \"date\" : \"\" , \"cost\" : \"\" , \"currency\" : \"\" } ], \"sharedServices\" : [ { \"id\" : \"shared service id\" , \"name\" : \"shared service name\" , \"costs\" : [ { \"date\" : \"\" , \"cost\" : \"\" , \"currency\" : \"\" } ] }], \"workspaces\" : [ { \"id\" : \"workspace id\" , \"name\" : \"workspace name\" , \"costs\" :[ { \"date\" : \"\" , \"cost\" : \"\" , \"currency\" : \"\" } ]} ] }","title":"Get overall cost report"},{"location":"azure-tre-overview/cost-reporting/#get-workspace-cost-report","text":"Description Get overall cost report for a specific workspace Authorization Only TRE Admin and the workspace owner can call this url, others will get unauthorized Input GET /api/workspaces/{workspace_id}/costs Query Parameters Parameter name Type Description Default Value from, to datetime Custom time period, up to 1 year timeframe, iso-8601 format Month to date period granularity Enum (Daily, None) The granularity of rows in the query. None workspace_id Guid The workspace id to generate report for Required field for workspace and user resource level apis Output { \"id\" : \"workspace id\" , \"name\" : \"workspace name\" , \"workspaceServices\" :[{ \"id\" : \"workspace service id\" , \"name\" : \"workspace service name\" , \"costs\" :[{ \"date\" : \"\" , \"cost\" : \"\" , \"currency\" : \"\" }], \"userResources\" :[{ \"id\" : \"user resource id\" , \"name\" : \"user resource name\" , \"costs\" :[{ \"date\" : \"\" , \"cost\" : \"\" , \"currency\" : \"\" }], }] }] }","title":"Get workspace cost report"},{"location":"azure-tre-overview/cost-reporting/#sequence-diagram","text":"source","title":"Sequence Diagram"},{"location":"azure-tre-overview/cost-reporting/#limitations-and-notes","text":"Cost and usage data is typically available in Cost Management within 8-24 hours. Tags aren't applied to historical data, template authors need to make sure all relevant Azure resources of a TRE resource are tagged as instructed . Cost records might include multiple currencies for the same date and TRE resource. Once cost data becomes available in Cost Management, it will be retained for at least seven years. Only the last 13 months is available from the TRE Cost API and Azure Portal. For historical data before 13 months, please use Exports or the UsageDetails API . There are several Azure Offers that currently are not supported yet, Azure Offers are types of Azure subscriptions, for full list of supported and unspported Azure Offers please refer to Supported Microsoft Azure offers , Azure TRE will not display costs for unsupported Azure subscriptions. For more information please refer to Understand Cost Management data and Cost API swagger docs.","title":"Limitations and notes"},{"location":"azure-tre-overview/cost-reporting/#azure-resources-tagging","text":"TRE Cost Reporting is based on Azure tagging to be able to generate cost report for core services, shared services, workspace, workspace services and user resources. Templates authors need to make sure that underling Azure resources are tagged with the following tags: Tag Value Applies to tre_id Unique ID of the TRE instance All resources of a TRE instance tre_core_service_id Unique ID of the TRE instance All TRE core azure resources shared_service_id The shared service unique ID Shared Services workspace_id The workspace unique ID Workspaces, Workspace Services and User Resources workspace_service_id The workspace service unique ID Workspace Services and User Resources user_resource_id The user resoruce unique ID User Resources Notes Main Azure Container Registry and Storage Account are not be tagged as those resources are used to spin up more than one Azure TRE Instance. There are some cases in which azure resources cannot get tagged by template author due to different reasons, for example services get deployed outside of TRE (Example being Cyclecloud or Cromwell on Azure), or services which doesn't support tagging for cost management (for example Azure ML compute). for the full list of tag support of Azure see this article .","title":"Azure Resources Tagging"},{"location":"azure-tre-overview/cost-reporting/#tre-cost-api-logic","text":"Cost management query API, which Azure TRE Cost APIs are based upon, returns a flat result of all cost with every tag combination which exists on the filtered resources by the provided tag, meaning that a resource which has tre_id, tre_core_service_id, tre_workspace_id, tre_workspace_service_id, and tre_user_resource_id will get be summarized by all those tags. if filtered resources have more tags, those tags will appear in the result. To rollup untagged resources into workspace costs Azure TRE cost API first calls Azure Resource Manager to get all resource group names which are tagged with the workspace_id and passes those names into Azure Cost Management Query API as a filter and group by resource group along with the tag name. untagged costs results will apear in with an empty tag name and get aggregated using the resource group and relevent the workspace id. Azure TRE Cost API joins this response with the hierarchical structure of the requested report. Cost management query API Request example @SUBSCRIPTION = FILL_YOUR_SUBSCRIPTION_ID @COST_API_URI = https://management.azure.com/subscriptions/{{SUBSCRIPTION}}/providers/Microsoft.CostManagement @COST_API_VERSION = 2021-10-01 @TRE_ID = mytre @TIME_FROM = MM/DD/YYYY @TIME_TO = MM/DD/YYYY POST {{COST_API_URI}}/query?api-version={{COST_API_VERSION}}&$expand=properties/data Authorization: {{$aadToken $aadV2TenantId}} Content-Type: application/json Payload { \"type\" : \"ActualCost\" , \"timeframe\" : \"Custom\" , // can be also BillingMonthToDate|MonthToDate|TheLastBillingMonth|TheLastMonth|WeekToDate according to input \"timePeriod\" : { \"from\" : \"{{TIME_FROM}}\" , \"to\" : \"{{TIME_TO}}\" }, \"dataset\" : { \"granularity\" : \"None\" , // can be also \"Daily\" for total costs \"aggregation\" : { \"totalCost\" : { \"name\" : \"PreTaxCost\" , // can be also 'UsageQuantity','Cost','CostUSD','PreTaxCostUSD' (up to two aggregations) \"function\" : \"Sum\" } }, \"filter\" : { \"or\" : [ { \"dimensions\" : { \"name\" : \"ResourceGroup\" , \"operator\" : \"In\" , \"values\" : [ \"{{RG_NAME}}\" ] } }, { \"tags\" : { \"name\" : \"{{TAG_KEY}}\" , \"operator\" : \"In\" , \"values\" : [ \"{{TAG_VALUE}}\" , ] } } ] }, \"grouping\" : [ { \"type\" : \"Dimension\" , \"name\" : \"ResourceGroup\" }, { \"type\" : \"Tag\" , } ] } } Response { \"id\" : \"subscriptions/xxxxxxxxxxxxx/providers/Microsoft.CostManagement/query/ec1f0eae-9343-4f4e-a0c0-dd219a66efc4\" , \"name\" : \"ec1f0eae-9343-4f4e-a0c0-dd219a66efc4\" , \"type\" : \"Microsoft.CostManagement/query\" , \"location\" : null , \"sku\" : null , \"eTag\" : null , \"properties\" : { \"nextLink\" : null , \"columns\" : [ { \"name\" : \"PreTaxCost\" , \"type\" : \"Number\" }, { \"name\" : \"ResourceGroup\" , \"type\" : \"String\" }, { \"name\" : \"Tag\" , \"type\" : \"String\" }, { \"name\" : \"Currency\" , \"type\" : \"String\" } ], \"rows\" : [ [ 0.00055748658857886549 , \"rg-mytre\" , \"\" , \"USD\" ], [ 3.9306515711531222 , \"rg-mytre\" , \"\\\"tre_core_service\\\":\\\"mytre\\\"\" , \"USD\" ], [ 11.66335497490112 , \"rg-mytre\" , \"\\\"tre_id\\\":\\\"mytre\\\"\" , \"USD\" ], [ 0.033 , \"rg-mytre\" , \"\\\"tre_shared_service\\\":\\\"2fea\\\"\" , \"USD\" ], [ 3.62175702964083 , \"rg-mytre\" , \"\\\"tre_shared_service\\\":\\\"4a5b\\\"\" , \"USD\" ], [ 0.093523886643774659 , \"rg-mytre-ws-5e86\" , \"\\\"tre_user_resource_id\\\":\\\"126d\\\"\" , \"USD\" ], [ 0.078465743393993009 , \"rg-mytre-ws-5e86\" , \"\\\"tre_user_resource_id\\\":\\\"2627\\\"\" , \"USD\" ], [ 0.20275980676694544 , \"rg-mytre-ws-5e86\" , \"\\\"tre_user_resource_id\\\":\\\"319e\\\"\" , \"USD\" ], [ 0.17165788614506686 , \"rg-mytre-ws-af30\" , \"\\\"tre_user_resource_id\\\":\\\"3370\\\"\" , \"USD\" ], [ 0.17518017912599823 , \"rg-mytre-ws-af30\" , \"\\\"tre_user_resource_id\\\":\\\"b2be\\\"\" , \"USD\" ], [ 0.00015748658857886549 , \"rg-mytre-ws-5e86\" , \"\" , \"USD\" ], [ 0.39905729127776768 , \"rg-mytre-ws-5e86\" , \"\\\"tre_workspace_id\\\":\\\"5e86\\\"\" , \"USD\" ], [ 0.98272254462049369 , \"rg-mytre-ws-af30\" , \"\\\"tre_workspace_id\\\":\\\"af30\\\"\" , \"USD\" ], [ 0.17198963003776765 , \"rg-mytre-ws-5e86\" , \"\\\"tre_workspace_service\\\":\\\"8d0a\\\"\" , \"USD\" ], [ 0.54959787203801058 , \"rg-mytre-ws-af30\" , \"\\\"tre_workspace_service\\\":\\\"e70d\\\"\" , \"USD\" ] ] } }","title":"TRE Cost API Logic"},{"location":"azure-tre-overview/networking/","text":"Network Architecture The Trusted Research Environment (TRE) network topology is based on hub-spoke . The TRE Core VNET ( Azure Virtual Network ) is the central hub and each workspace is a spoke. Azure TRE VNETs are segregated allowing limited traffic between the TRE Core VNET and Workspace VNETs. The security rules are managed by nsg-ws network security group. See workspace network security groups (NSG) further down. The Core VNET is further divided into subnets. Subnet Description AzureBastionSubnet A dedicated subnet for Azure Bastion hosts. AppGwSubnet Subnet for Azure Application Gateway controlling ingress traffic. AzureFirewallSubnet Subnet for Azure Firewall controlling egress traffic. ResourceProcessorSubnet Subnet for VMSS used by the Composition Service to host Docker containers to execute Porter bundles that deploys Workspaces. WebAppSubnet Subnet for TRE API. SharedSubnet Shared Services subnet for all things shared by TRE Core and Workspaces. Such as Source Mirror Shared Service and Package Mirror Shared Service. All subnets (Core and Workspace subnets) have a default route which directs egress traffic to the Azure Firewall to ensure only explicitly allowed destinations on the Internet to be accessed. There are a couple of exceptions: AzureFirewallSubnet as it hosts the Azure Firewall which routes traffic to the Internet. AzureBastionSubnet as it hosts Azure Bastion which is the management jump box within the VNET with Internet access. AppGwSubnet as it hosts the Azure Application Gateway which has to be able to a ping the health endpoints e.g. TRE API. Ingress and egress Ingress traffic from the Internet is only allowed through the Application Gateway, which forwards HTTPS (port 443) call to the TRE API in the WebAppSubnet . Egress traffic is routed through the Azure Firewall with a few exceptions and by default all ingress and egress traffic is denied except explicitly allowed. The explicitly allowed egress traffic is described here: Resource Processor TRE API Gitea Shared Service Nexus Shared Service Azure Monitor Azure Monitor resources are secured using Azure Monitor Private Link Scope (AMPLS) keeping all traffic inside the Microsoft Azure backbone network. The Azure Monitor resources and their network configuration is defined in /templates/core/terraform/azure-monitor folder and the required private DNS zones in file /templates/core/terraform/network/dns_zones.tf . Network security groups TRE Core Network security groups (NSG), and their security rules for TRE core resources are defined in /templates/core/terraform/network/network_security_groups.tf . Network security group Associated subnet(s) nsg-bastion-subnet AzureBastionSubnet nsg-app-gw AppGwSubnet nsg-default-rules ResourceProcessorSubnet , SharedSubnet , WebAppSubnet Workspaces Azure TRE VNETs are segregated allowing limited traffic between the TRE Core VNET and Workspace VNETs. The rules to manage and limit the traffic between the TRE Core VNET and Workspace VNETs are defined by the nsg-ws network security group: Inbound traffic from TRE Core VNET to workspace allowed for Azure Bastion (22, 3389) - All other inbound traffic from Core to workspace denied. Outbound traffic to SharedSubnet from Workspace allowed. Outbound traffic to Internet allowed on HTTPS port 443 (next hop Azure Firewall). All other outbound traffic denied. Each of these rules can be managed per workspace. Caution In Azure, traffic between subnets are allowed except explicitly denied.","title":"Network Architecture"},{"location":"azure-tre-overview/networking/#network-architecture","text":"The Trusted Research Environment (TRE) network topology is based on hub-spoke . The TRE Core VNET ( Azure Virtual Network ) is the central hub and each workspace is a spoke. Azure TRE VNETs are segregated allowing limited traffic between the TRE Core VNET and Workspace VNETs. The security rules are managed by nsg-ws network security group. See workspace network security groups (NSG) further down. The Core VNET is further divided into subnets. Subnet Description AzureBastionSubnet A dedicated subnet for Azure Bastion hosts. AppGwSubnet Subnet for Azure Application Gateway controlling ingress traffic. AzureFirewallSubnet Subnet for Azure Firewall controlling egress traffic. ResourceProcessorSubnet Subnet for VMSS used by the Composition Service to host Docker containers to execute Porter bundles that deploys Workspaces. WebAppSubnet Subnet for TRE API. SharedSubnet Shared Services subnet for all things shared by TRE Core and Workspaces. Such as Source Mirror Shared Service and Package Mirror Shared Service. All subnets (Core and Workspace subnets) have a default route which directs egress traffic to the Azure Firewall to ensure only explicitly allowed destinations on the Internet to be accessed. There are a couple of exceptions: AzureFirewallSubnet as it hosts the Azure Firewall which routes traffic to the Internet. AzureBastionSubnet as it hosts Azure Bastion which is the management jump box within the VNET with Internet access. AppGwSubnet as it hosts the Azure Application Gateway which has to be able to a ping the health endpoints e.g. TRE API.","title":"Network Architecture"},{"location":"azure-tre-overview/networking/#ingress-and-egress","text":"Ingress traffic from the Internet is only allowed through the Application Gateway, which forwards HTTPS (port 443) call to the TRE API in the WebAppSubnet . Egress traffic is routed through the Azure Firewall with a few exceptions and by default all ingress and egress traffic is denied except explicitly allowed. The explicitly allowed egress traffic is described here: Resource Processor TRE API Gitea Shared Service Nexus Shared Service","title":"Ingress and egress"},{"location":"azure-tre-overview/networking/#azure-monitor","text":"Azure Monitor resources are secured using Azure Monitor Private Link Scope (AMPLS) keeping all traffic inside the Microsoft Azure backbone network. The Azure Monitor resources and their network configuration is defined in /templates/core/terraform/azure-monitor folder and the required private DNS zones in file /templates/core/terraform/network/dns_zones.tf .","title":"Azure Monitor"},{"location":"azure-tre-overview/networking/#network-security-groups","text":"","title":"Network security groups"},{"location":"azure-tre-overview/networking/#tre-core","text":"Network security groups (NSG), and their security rules for TRE core resources are defined in /templates/core/terraform/network/network_security_groups.tf . Network security group Associated subnet(s) nsg-bastion-subnet AzureBastionSubnet nsg-app-gw AppGwSubnet nsg-default-rules ResourceProcessorSubnet , SharedSubnet , WebAppSubnet","title":"TRE Core"},{"location":"azure-tre-overview/networking/#workspaces","text":"Azure TRE VNETs are segregated allowing limited traffic between the TRE Core VNET and Workspace VNETs. The rules to manage and limit the traffic between the TRE Core VNET and Workspace VNETs are defined by the nsg-ws network security group: Inbound traffic from TRE Core VNET to workspace allowed for Azure Bastion (22, 3389) - All other inbound traffic from Core to workspace denied. Outbound traffic to SharedSubnet from Workspace allowed. Outbound traffic to Internet allowed on HTTPS port 443 (next hop Azure Firewall). All other outbound traffic denied. Each of these rules can be managed per workspace. Caution In Azure, traffic between subnets are allowed except explicitly denied.","title":"Workspaces"},{"location":"azure-tre-overview/tre-resources-breakdown/","text":"Azure TRE Resource Breakdown The Azure services deployed within an Azure TRE are described below. Once an Azure TRE has been provisioned in an Azure Subscription, you will have two Resource Groups: Azure TRE Management Resource Group - Prerequisite for deploying an Azure TRE instance Azure TRE Resource Group - Core Azure TRE instance Azure TRE Management Resource Group Name Azure Service Description Additional links {MGMT_STORAGE_ACCOUNT_NAME} Storage Account Azure TRE Terraform and Porter state Storage Blobs {ACR_NAME} Container Registry Azure TRE container images (Porter bundles) Container Registry Azure TRE Resource Group Name Azure Service Description Additional links api-{TRE_ID} App Service Azure TRE Python API responsible for all operations on Workspaces and managing Workspace Templates built using the FastAPI framework FastAPI gitea-{TRE_ID} App Service Azure TRE Source Mirror - allows mirroring git repositories Gitea nexus-{TRE_ID} App Service Azure TRE Package Mirror - allows mirroring packages Sonatype Nexus plan-{TRE_ID} App Service Plan Compute resources in which the TRE app services run App Hosting plans agw-{TRE_ID} Azure Application Gateway Azure TRE App Gateway provides a single public IP address with SSL for accessing core TRE resources Azure Application Gateway appi-{TRE_ID} Application Insights Telemetry for all API invocations Application Insights cosmos-{TRE_ID} Azure Cosmos DB Account NoSQL state store of TRE resources, templates and operations Cosmos DB mysql-{TRE_ID} Azure Database for MySQL server SQL state store for Gitea Gitea Database ampls-{TRE_ID} Azure Monitor Private Link Scope Provides secure link between PaaS resources and the TRE vnet using private endpoints Azure Monitor Private Link Scope bas-{TRE_ID} Azure Bastion Provides secure access for RDP/SSH to TRE VM (jumpbox) Azure Bastion vm-dsk-{TRE_ID} Disk Managed storage disk for TRE VM (jumpbox) Managed Disks fw-dsk-{TRE_ID} Azure Firewall Azure TRE Firewall restricts external outbound traffic from all TRE resources Azure Firewall kv-{TRE_ID} Azure Key Vault Management of TRE secrets & certificates Azure Key Vault log-{TRE_ID} Log Analytics Workspace Azure Monitor Logs store for all TRE resources Log Analytics id-agw-{TRE_ID} Managed Identity User-managed identity for TRE Application Gateway Managed Identities id-api-{TRE_ID} Managed Identity User-managed identity for TRE API App Service Managed Identities id-gitea-{TRE_ID} Managed Identity User-managed identity for TRE Gitea App Service Managed Identities id-vmss-{TRE_ID} Managed Identity User-managed identity for TRE Resource Processer (VMSS) Managed Identities sb-{TRE_ID} Service Bus Namespace Messaging for TRE API Service Bus stappinsights{TRE_ID} Storage Account Storage for TRE Application Insights telemetry logs Storage Blobs stg{TRE_ID} Storage Account Files shares for TRE services such as Porter, Gitea, Nexus Storage Files stweb{TRE_ID} Storage Account Storage for Azure TRE Let's Encrypt Storage Blob vm-{TRE_ID} Virtual Machine Azure TRE VM (jumpbox) Windows Virtual Machine vm-{TRE_ID} Virtual Machine Scale Set Azure TRE Resource Processor Virtual Machine Scale Sets vnet-{TRE_ID} Virtual Network Azure TRE VNET central hub Virtual Networks rt-{TRE_ID} Route Table Azure TRE route table Route Tables Note Network resources such as Network Interfaces, Network Security Groups, Private Endpoints, Private DNS zones and Public IP addresses are not listed above. Azure TRE Workspace Resource Group A TRE Workspace will be provisioned in a separate Resource Group along with its own resources. An example TRE Workspace is shown and described here. Name Azure Service Description Additional links guacamole-{TRE_ID}-ws-XXXX-svc-XXXX App Service RDP for accessing workspace VMs Apache Guacamole kv-{TRE_ID}-ws-XXXX Azure Key Vault Management of TRE workspace secrets & certificates Azure Key Vault osdisk-windowsvm8f45 Disk Azure VM storage disk Managed Disks plan-09d0ba4f-f79f-4047-aa2c-03fc9df7b318 App Service plan Compute resources in which the workspace app services (Gitea) run App Hosting Plans stgwsb318 Storage account Workspace Storage account Storage Blobs vnet-{TRE_ID}-ws-XXXX Virtual Network Azure TRE VNET spoke Virtual Networks windowsvm8f45 Virtual Machine Windows VM instance for research Windows Virtual Machine Note Network resources such as Network Interfaces, Network Security Groups and Private Endpoints are not listed above.","title":"Azure Resources"},{"location":"azure-tre-overview/tre-resources-breakdown/#azure-tre-resource-breakdown","text":"The Azure services deployed within an Azure TRE are described below. Once an Azure TRE has been provisioned in an Azure Subscription, you will have two Resource Groups: Azure TRE Management Resource Group - Prerequisite for deploying an Azure TRE instance Azure TRE Resource Group - Core Azure TRE instance","title":"Azure TRE Resource Breakdown"},{"location":"azure-tre-overview/tre-resources-breakdown/#azure-tre-management-resource-group","text":"Name Azure Service Description Additional links {MGMT_STORAGE_ACCOUNT_NAME} Storage Account Azure TRE Terraform and Porter state Storage Blobs {ACR_NAME} Container Registry Azure TRE container images (Porter bundles) Container Registry","title":"Azure TRE Management Resource Group"},{"location":"azure-tre-overview/tre-resources-breakdown/#azure-tre-resource-group","text":"Name Azure Service Description Additional links api-{TRE_ID} App Service Azure TRE Python API responsible for all operations on Workspaces and managing Workspace Templates built using the FastAPI framework FastAPI gitea-{TRE_ID} App Service Azure TRE Source Mirror - allows mirroring git repositories Gitea nexus-{TRE_ID} App Service Azure TRE Package Mirror - allows mirroring packages Sonatype Nexus plan-{TRE_ID} App Service Plan Compute resources in which the TRE app services run App Hosting plans agw-{TRE_ID} Azure Application Gateway Azure TRE App Gateway provides a single public IP address with SSL for accessing core TRE resources Azure Application Gateway appi-{TRE_ID} Application Insights Telemetry for all API invocations Application Insights cosmos-{TRE_ID} Azure Cosmos DB Account NoSQL state store of TRE resources, templates and operations Cosmos DB mysql-{TRE_ID} Azure Database for MySQL server SQL state store for Gitea Gitea Database ampls-{TRE_ID} Azure Monitor Private Link Scope Provides secure link between PaaS resources and the TRE vnet using private endpoints Azure Monitor Private Link Scope bas-{TRE_ID} Azure Bastion Provides secure access for RDP/SSH to TRE VM (jumpbox) Azure Bastion vm-dsk-{TRE_ID} Disk Managed storage disk for TRE VM (jumpbox) Managed Disks fw-dsk-{TRE_ID} Azure Firewall Azure TRE Firewall restricts external outbound traffic from all TRE resources Azure Firewall kv-{TRE_ID} Azure Key Vault Management of TRE secrets & certificates Azure Key Vault log-{TRE_ID} Log Analytics Workspace Azure Monitor Logs store for all TRE resources Log Analytics id-agw-{TRE_ID} Managed Identity User-managed identity for TRE Application Gateway Managed Identities id-api-{TRE_ID} Managed Identity User-managed identity for TRE API App Service Managed Identities id-gitea-{TRE_ID} Managed Identity User-managed identity for TRE Gitea App Service Managed Identities id-vmss-{TRE_ID} Managed Identity User-managed identity for TRE Resource Processer (VMSS) Managed Identities sb-{TRE_ID} Service Bus Namespace Messaging for TRE API Service Bus stappinsights{TRE_ID} Storage Account Storage for TRE Application Insights telemetry logs Storage Blobs stg{TRE_ID} Storage Account Files shares for TRE services such as Porter, Gitea, Nexus Storage Files stweb{TRE_ID} Storage Account Storage for Azure TRE Let's Encrypt Storage Blob vm-{TRE_ID} Virtual Machine Azure TRE VM (jumpbox) Windows Virtual Machine vm-{TRE_ID} Virtual Machine Scale Set Azure TRE Resource Processor Virtual Machine Scale Sets vnet-{TRE_ID} Virtual Network Azure TRE VNET central hub Virtual Networks rt-{TRE_ID} Route Table Azure TRE route table Route Tables Note Network resources such as Network Interfaces, Network Security Groups, Private Endpoints, Private DNS zones and Public IP addresses are not listed above.","title":"Azure TRE Resource Group"},{"location":"azure-tre-overview/tre-resources-breakdown/#azure-tre-workspace-resource-group","text":"A TRE Workspace will be provisioned in a separate Resource Group along with its own resources. An example TRE Workspace is shown and described here. Name Azure Service Description Additional links guacamole-{TRE_ID}-ws-XXXX-svc-XXXX App Service RDP for accessing workspace VMs Apache Guacamole kv-{TRE_ID}-ws-XXXX Azure Key Vault Management of TRE workspace secrets & certificates Azure Key Vault osdisk-windowsvm8f45 Disk Azure VM storage disk Managed Disks plan-09d0ba4f-f79f-4047-aa2c-03fc9df7b318 App Service plan Compute resources in which the workspace app services (Gitea) run App Hosting Plans stgwsb318 Storage account Workspace Storage account Storage Blobs vnet-{TRE_ID}-ws-XXXX Virtual Network Azure TRE VNET spoke Virtual Networks windowsvm8f45 Virtual Machine Windows VM instance for research Windows Virtual Machine Note Network resources such as Network Interfaces, Network Security Groups and Private Endpoints are not listed above.","title":"Azure TRE Workspace Resource Group"},{"location":"azure-tre-overview/user-roles/","text":"User roles The Azure TRE solution has 8 different user roles defined. The roles are modeled around a set of tasks for each role. The roles are not mutually exclusive, and one person can have multiple roles assigned to be able to carry out a broader set of tasks. Before you deploy a Trusted Research Environment based on the Azure TRE solution, you should consider your scenario and have an understanding of which of these roles that needs to be staffed. Role overview While we have defined 8 different user roles for the Azure TRE solution, not all of them are required in all scenarios. Three of the roles support role-based access control (RBAC) within the TRE. Role Key task TRE RBAC Azure administrator Deploy the TRE TRE administrator Administer the TRE \u2714 TRE workspace owner Own a workspace \u2714 Researcher Perform research on the data \u2714 Airlock Manager Approves data import & export \u2714 TRE service integrator Integrate additional workspace services Azure TRE developer Extend the TRE OSS solution Data engineer Move data to and potentially from the TRE Information security officer Validate and sign-off TRE deployment Info More granular RBAC information is available here . Azure administrator Provisions the Azure TRE solution in an Azure subscription and performs tasks that require knowledge of Azure operations and has access to the Azure subscription. Example tasks: Provision Azure TRE solution instances. Second line support for TRE administrators, TRE workspace owners and Researchers when Azure TRE troubleshooting is required. Work with the data engineer to connect the Azure TRE with the data platform. Troubleshoot provisioning issues and failed deployments. Manage TRE administrator users. Manage data backups and restores. Update the Azure TRE instances. Configure log and metrics alerts. Expected skills: Azure administration and operations. Infrastructure as Code (Terraform, ARM, Git) PowerShell, Bash TRE administrator Day-to-day running and operations of the Azure TRE instance without touching Azure resources. Example tasks: Manage workspace owner users. Provision workspaces. Manage shared services e.g., available packages in package mirror shared service. Monitor workspace usage and billing. Set and manage quotas. Create and manage workspaces Expected skills: Limited or no Azure knowledge expected. TRE workspace owner Owns a specific workspace and has additional privileges than the researcher within the workspace. Is most likely also a Researcher . Example tasks: Manage Researcher users. Export data from workspace. Import data and make it available within the workspace. Enable services within the workspace. Monitor billing and usage of the workspace. Create and manage workspace services Expected skills: Limited or no Azure knowledge expected. Researcher Has access to one specific workspace and can use all the services provisioned within that workspace. Example tasks: Import software packages needed to conduct research (PyPi, Conda, Apt). Perform research using the services in the workspace. Create and manage user resources Expected skills: Python, R Git Linux Airlock Manager Approves (and reviews in some instances) the data that is being imported to and exported from a TRE Workspace Example tasks: Approve Airlock import requests Approve Airlock export requests Review the data being imported to and exported from a TRE Workspace TRE service integrator Integrates workspace service types with an Azure TRE instance. This involves extending the Azure Infrastructure as Code templates to make a workspace service available within an Azure TRE instance. Example tasks: Integrate a workspace service type with your Azure TRE instance. Implement Infrastructure as Code templates for new workspace service types. Expected skills: Infrastructure as Code (Terraform, ARM, Git) Python, Bash Azure administration Azure TRE developer Software developer who contributes to the development of the Azure TRE solution. Example tasks: Modify the deployment service, API and other components of the Azure TRE solution. Contribute to the Azure TRE OSS solution. Expected skills: Python, Bash Infrastructure as Code (Terraform, ARM, Git Azure administration Data engineer Supporting role that is expected to build data movement pipelines between the data platform (not part of the TRE), and the TRE instance. Example tasks: Transfer data from the data platform to the TRE and potentially back. Create data movement and transformation pipelines. Expected skills: Python, Bash, Linux Azure Data Factory, Other ETL tools. Information Security Officer Needs to understand the security posture of the TRE to ensure that the organization is compliant with the information governance framework and additional relevant regulations. Example tasks: Use the Azure TRE documentation to understand the security posture of the TRE. Work with Azure administrator and TRE administrator to enforce the required security and privacy controls on the TRE. Commission penetration testing. Work with organization Information Governance committee to validate and sign-off Azure TRE deployment","title":"User Roles"},{"location":"azure-tre-overview/user-roles/#user-roles","text":"The Azure TRE solution has 8 different user roles defined. The roles are modeled around a set of tasks for each role. The roles are not mutually exclusive, and one person can have multiple roles assigned to be able to carry out a broader set of tasks. Before you deploy a Trusted Research Environment based on the Azure TRE solution, you should consider your scenario and have an understanding of which of these roles that needs to be staffed.","title":"User roles"},{"location":"azure-tre-overview/user-roles/#role-overview","text":"While we have defined 8 different user roles for the Azure TRE solution, not all of them are required in all scenarios. Three of the roles support role-based access control (RBAC) within the TRE. Role Key task TRE RBAC Azure administrator Deploy the TRE TRE administrator Administer the TRE \u2714 TRE workspace owner Own a workspace \u2714 Researcher Perform research on the data \u2714 Airlock Manager Approves data import & export \u2714 TRE service integrator Integrate additional workspace services Azure TRE developer Extend the TRE OSS solution Data engineer Move data to and potentially from the TRE Information security officer Validate and sign-off TRE deployment Info More granular RBAC information is available here .","title":"Role overview"},{"location":"azure-tre-overview/user-roles/#azure-administrator","text":"Provisions the Azure TRE solution in an Azure subscription and performs tasks that require knowledge of Azure operations and has access to the Azure subscription. Example tasks: Provision Azure TRE solution instances. Second line support for TRE administrators, TRE workspace owners and Researchers when Azure TRE troubleshooting is required. Work with the data engineer to connect the Azure TRE with the data platform. Troubleshoot provisioning issues and failed deployments. Manage TRE administrator users. Manage data backups and restores. Update the Azure TRE instances. Configure log and metrics alerts. Expected skills: Azure administration and operations. Infrastructure as Code (Terraform, ARM, Git) PowerShell, Bash","title":"Azure administrator"},{"location":"azure-tre-overview/user-roles/#tre-administrator","text":"Day-to-day running and operations of the Azure TRE instance without touching Azure resources. Example tasks: Manage workspace owner users. Provision workspaces. Manage shared services e.g., available packages in package mirror shared service. Monitor workspace usage and billing. Set and manage quotas. Create and manage workspaces Expected skills: Limited or no Azure knowledge expected.","title":"TRE administrator"},{"location":"azure-tre-overview/user-roles/#tre-workspace-owner","text":"Owns a specific workspace and has additional privileges than the researcher within the workspace. Is most likely also a Researcher . Example tasks: Manage Researcher users. Export data from workspace. Import data and make it available within the workspace. Enable services within the workspace. Monitor billing and usage of the workspace. Create and manage workspace services Expected skills: Limited or no Azure knowledge expected.","title":"TRE workspace owner"},{"location":"azure-tre-overview/user-roles/#researcher","text":"Has access to one specific workspace and can use all the services provisioned within that workspace. Example tasks: Import software packages needed to conduct research (PyPi, Conda, Apt). Perform research using the services in the workspace. Create and manage user resources Expected skills: Python, R Git Linux","title":"Researcher"},{"location":"azure-tre-overview/user-roles/#airlock-manager","text":"Approves (and reviews in some instances) the data that is being imported to and exported from a TRE Workspace Example tasks: Approve Airlock import requests Approve Airlock export requests Review the data being imported to and exported from a TRE Workspace","title":"Airlock Manager"},{"location":"azure-tre-overview/user-roles/#tre-service-integrator","text":"Integrates workspace service types with an Azure TRE instance. This involves extending the Azure Infrastructure as Code templates to make a workspace service available within an Azure TRE instance. Example tasks: Integrate a workspace service type with your Azure TRE instance. Implement Infrastructure as Code templates for new workspace service types. Expected skills: Infrastructure as Code (Terraform, ARM, Git) Python, Bash Azure administration","title":"TRE service integrator"},{"location":"azure-tre-overview/user-roles/#azure-tre-developer","text":"Software developer who contributes to the development of the Azure TRE solution. Example tasks: Modify the deployment service, API and other components of the Azure TRE solution. Contribute to the Azure TRE OSS solution. Expected skills: Python, Bash Infrastructure as Code (Terraform, ARM, Git Azure administration","title":"Azure TRE developer"},{"location":"azure-tre-overview/user-roles/#data-engineer","text":"Supporting role that is expected to build data movement pipelines between the data platform (not part of the TRE), and the TRE instance. Example tasks: Transfer data from the data platform to the TRE and potentially back. Create data movement and transformation pipelines. Expected skills: Python, Bash, Linux Azure Data Factory, Other ETL tools.","title":"Data engineer"},{"location":"azure-tre-overview/user-roles/#information-security-officer","text":"Needs to understand the security posture of the TRE to ensure that the organization is compliant with the information governance framework and additional relevant regulations. Example tasks: Use the Azure TRE documentation to understand the security posture of the TRE. Work with Azure administrator and TRE administrator to enforce the required security and privacy controls on the TRE. Commission penetration testing. Work with organization Information Governance committee to validate and sign-off Azure TRE deployment","title":"Information Security Officer"},{"location":"tre-admins/auth/","text":"Introduction to Authentication and Authorization Azure Active Directory (AAD) is the backbone of Authentication and Authorization in the Trusted Research Environment. AAD holds the identities of all the TRE/workspace users, including administrators, and connects the identities with applications which define the permissions for each user role. It is common that the Azure Administrator is not necessarily the Azure Active Directory Administrator. Due to this, this step may have to be carried out by a different individual/team. We have automated this into a simple command, but should you wish, you can run these steps manually. This page describes the automated Auth setup for TRE. Pre-requisites The automation utilises a make command, which reads a few environment variables and creates the AAD assets. The following values are needed to be in place before you run the creation process. ( /config.yaml ) Key Description TRE_ID This is used to build up the name of the identities AAD_TENANT_ID The tenant id of where your AAD identities will be placed. This can be different to the tenant where your Azure resources are created. LOCATION Where your Azure assets will be provisioned (eg. westeurope). This is used to add a redirect URI from the Swagger UI to the API Application. AUTO_WORKSPACE_APP_REGISTRATION Default of false . Setting this to true grants the Application.ReadWrite.All and Directory.Read.All permission to the Application Admin identity. This identity is used to manage other AAD applications that it owns, e.g. Workspaces. If you do not set this, the identity will have Application.ReadWrite.OwnedBy . Further information can be found here . AUTO_WORKSPACE_GROUP_CREATION Default of false . Setting this to true grants the Group.ReadWrite.All permission to the Application Admin identity. This identity can then create security groups aligned to each applciation role. Active Directory licencing implications need to be considered as Group assignment is a premium feature . Create Authentication assets You can build all of the Identity assets by running the following at the command line make auth This will create five identities, and if successful will write the outputs to athentication section in config.yaml file. If you are building locally, these values will be used when building your TRE. If you are setting this up for CI/CD, then these values will be needed by your Build Orchestrator. The contents of your authentication section in config.yaml file should contain : Variable Description APPLICATION_ADMIN_CLIENT_ID This client will administer AAD Applications for TRE APPLICATION_ADMIN_CLIENT_SECRET This client will administer AAD Applications for TRE TEST_ACCOUNT_CLIENT_ID This will be created by default, but can be disabled by editing /devops/scripts/create_aad_assets.sh . This is the user that will run the tests for you TEST_ACCOUNT_CLIENT_SECRET This will be created by default, but can be disabled by editing /devops/scripts/create_aad_assets.sh . This is the user that will run the tests for you API_CLIENT_ID API application (client) ID. API_CLIENT_SECRET API application client secret. SWAGGER_UI_CLIENT_ID Swagger (OpenAPI) UI application (client) ID. WORKSPACE_API_CLIENT_ID Each workspace is secured behind it's own AD Application WORKSPACE_API_CLIENT_SECRET Each workspace is secured behind it's own AD Application. This is the secret for that application. Using a separate Azure Active Directory tenant Caution This section is only relevant it you are setting up a separate Azure Active Directory tenant for use. This is only recommended for development environments when you don't have the required permissions to register applications in Azure Active Directory. Using a separate Azure Active Directory tenant will prevent you from using certain Azure Active Directory integrated services. For production deployments, work with your Azure Active Directory administrator to perform the required registration Create an Azure Active Directory tenant To create a new Azure Active Directory tenant, follow the steps here Follow the steps outlined above. make auth should logon to the correct tenant. Make sure you logon back to the correct tenant before running make all . App registrations App registrations (represented by service principals) define the various access permissions to the TRE system. There are a total of five main Applications of interest. AAD Application Description TRE API application This is the main application and used to secure access to the TRE API . TRE UX This is the client application that will authenticate to the TRE/Workspace APIs. Application Admin There are times when workspace services need to update the AAD Application. For example, Guacamole needs to add a redirect URI to the Workspace AAD Application. This identity is used to manage AAD Applications. Automation App This application is created so that you can run the tests or any CI/CD capability without the need to divulge a user password. This is particularly important if your tenant is MFA enabled. Workspace API Typically you would have an application securing one or more workspaces that are created by TRE. Some of the applications require admin consent to allow them to validate users against the AAD. Check the Microsoft Docs on Configure the admin consent workflow on how to request admin consent and handle admin consent requests. We strongly recommend that you use make auth to create the AAD assets as this has been tested extensively. Should you wish to create these manually via the Azure Portal ; more information can be found here . Enabling users For a user to gain access to the system, they have to: Have an identity in Azure AD Be linked with an app registration and assigned a role When these requirements are met, the user can sign-in using their credentials and use their privileges to use the API, login to workspace environment etc. based on their specific roles. The users can also be linked via the Enterprise application view:","title":"Introduction"},{"location":"tre-admins/auth/#introduction-to-authentication-and-authorization","text":"Azure Active Directory (AAD) is the backbone of Authentication and Authorization in the Trusted Research Environment. AAD holds the identities of all the TRE/workspace users, including administrators, and connects the identities with applications which define the permissions for each user role. It is common that the Azure Administrator is not necessarily the Azure Active Directory Administrator. Due to this, this step may have to be carried out by a different individual/team. We have automated this into a simple command, but should you wish, you can run these steps manually. This page describes the automated Auth setup for TRE.","title":"Introduction to Authentication and Authorization"},{"location":"tre-admins/auth/#pre-requisites","text":"The automation utilises a make command, which reads a few environment variables and creates the AAD assets. The following values are needed to be in place before you run the creation process. ( /config.yaml ) Key Description TRE_ID This is used to build up the name of the identities AAD_TENANT_ID The tenant id of where your AAD identities will be placed. This can be different to the tenant where your Azure resources are created. LOCATION Where your Azure assets will be provisioned (eg. westeurope). This is used to add a redirect URI from the Swagger UI to the API Application. AUTO_WORKSPACE_APP_REGISTRATION Default of false . Setting this to true grants the Application.ReadWrite.All and Directory.Read.All permission to the Application Admin identity. This identity is used to manage other AAD applications that it owns, e.g. Workspaces. If you do not set this, the identity will have Application.ReadWrite.OwnedBy . Further information can be found here . AUTO_WORKSPACE_GROUP_CREATION Default of false . Setting this to true grants the Group.ReadWrite.All permission to the Application Admin identity. This identity can then create security groups aligned to each applciation role. Active Directory licencing implications need to be considered as Group assignment is a premium feature .","title":"Pre-requisites"},{"location":"tre-admins/auth/#create-authentication-assets","text":"You can build all of the Identity assets by running the following at the command line make auth This will create five identities, and if successful will write the outputs to athentication section in config.yaml file. If you are building locally, these values will be used when building your TRE. If you are setting this up for CI/CD, then these values will be needed by your Build Orchestrator. The contents of your authentication section in config.yaml file should contain : Variable Description APPLICATION_ADMIN_CLIENT_ID This client will administer AAD Applications for TRE APPLICATION_ADMIN_CLIENT_SECRET This client will administer AAD Applications for TRE TEST_ACCOUNT_CLIENT_ID This will be created by default, but can be disabled by editing /devops/scripts/create_aad_assets.sh . This is the user that will run the tests for you TEST_ACCOUNT_CLIENT_SECRET This will be created by default, but can be disabled by editing /devops/scripts/create_aad_assets.sh . This is the user that will run the tests for you API_CLIENT_ID API application (client) ID. API_CLIENT_SECRET API application client secret. SWAGGER_UI_CLIENT_ID Swagger (OpenAPI) UI application (client) ID. WORKSPACE_API_CLIENT_ID Each workspace is secured behind it's own AD Application WORKSPACE_API_CLIENT_SECRET Each workspace is secured behind it's own AD Application. This is the secret for that application.","title":"Create Authentication assets"},{"location":"tre-admins/auth/#using-a-separate-azure-active-directory-tenant","text":"Caution This section is only relevant it you are setting up a separate Azure Active Directory tenant for use. This is only recommended for development environments when you don't have the required permissions to register applications in Azure Active Directory. Using a separate Azure Active Directory tenant will prevent you from using certain Azure Active Directory integrated services. For production deployments, work with your Azure Active Directory administrator to perform the required registration Create an Azure Active Directory tenant To create a new Azure Active Directory tenant, follow the steps here Follow the steps outlined above. make auth should logon to the correct tenant. Make sure you logon back to the correct tenant before running make all .","title":"Using a separate Azure Active Directory tenant"},{"location":"tre-admins/auth/#app-registrations","text":"App registrations (represented by service principals) define the various access permissions to the TRE system. There are a total of five main Applications of interest. AAD Application Description TRE API application This is the main application and used to secure access to the TRE API . TRE UX This is the client application that will authenticate to the TRE/Workspace APIs. Application Admin There are times when workspace services need to update the AAD Application. For example, Guacamole needs to add a redirect URI to the Workspace AAD Application. This identity is used to manage AAD Applications. Automation App This application is created so that you can run the tests or any CI/CD capability without the need to divulge a user password. This is particularly important if your tenant is MFA enabled. Workspace API Typically you would have an application securing one or more workspaces that are created by TRE. Some of the applications require admin consent to allow them to validate users against the AAD. Check the Microsoft Docs on Configure the admin consent workflow on how to request admin consent and handle admin consent requests. We strongly recommend that you use make auth to create the AAD assets as this has been tested extensively. Should you wish to create these manually via the Azure Portal ; more information can be found here .","title":"App registrations"},{"location":"tre-admins/auth/#enabling-users","text":"For a user to gain access to the system, they have to: Have an identity in Azure AD Be linked with an app registration and assigned a role When these requirements are met, the user can sign-in using their credentials and use their privileges to use the API, login to workspace environment etc. based on their specific roles. The users can also be linked via the Enterprise application view:","title":"Enabling users"},{"location":"tre-admins/configure-airlock-review/","text":"Configuring Airlock Review feature Airlock Review feature allows to setup a process for manually reviewing Airlock requests. When using this feature, Airlock Manager (a role with privileges of reviewing Airlock requests) is able to create Review User Resource (VM) and use it to review the data from. For information on Airlock feature, please refer to the overview page . For documentation on how to review an Airlock request, please refer to the user guide . Pre-requisites The feature is configured on a per Research Workspace basis. Different Research Workspaces need to be configured separately, although a single Airlock Import Workspace can be reused for all of them. Research Workspace can only be configured after it has been deployed, and the template must be of version 0.5.0 or later. Airlock must be enabled in the Research Workspace. To configure the feature, the following prerequisites need to be fulfilled: Airlock Import Workspace need to be deployed (once per TRE). Guacamole Workspace Service need to be deployed in Airlock Import Workspace from the previous step. Template for import review VM needs to be installed in the TRE, or a custom template if used. Guacamole Workspace Service need to be deployed in Research Workspace. Template for export review VM needs to be installed in the TRE, or a custom template if used. Configuring Airlock VM for Research Workspace Navigate to Research Workspace in the UI, and click \"Update\". You will see a check box \"Configure Review VMs\". You then will be able to input the values as follows: For Import Review Workspace ID , use the GUID of the Import Review workspace from step 1. For Import Review Workspace Service ID , use the GUID of the Workspace Service from step 2. For Import Review VM User Resource Template Name , unless you have built a custom template for this, you should use tre-service-guacamole-import-reviewvm which is the name of the standard template used for Import Reviews from step 3. For Export Review Workspace Service ID , use the GUID of the Workspace Service deployed into the Research Workspace from step 4. For Export Review Vm User Resource Template Name , unless you have built a custom template for this, you should use tre-service-guacamole-export-reviewvm which is the name of the standard template used for Import Reviews from step 5. Once you're done, click Submit. Verify that the configuration is working by creating Review VMs for existing import export and export requests (configuration is not verified on update). Troubleshooting Users cannot create Review VMs If a user sees an error when creating Review VMs, this most likely means that the configuration isn't correct. Double-check that all GUIDs don't have any symbols missing, and the names of templates are correct.","title":"Configuring Airlock Reviews"},{"location":"tre-admins/configure-airlock-review/#configuring-airlock-review-feature","text":"Airlock Review feature allows to setup a process for manually reviewing Airlock requests. When using this feature, Airlock Manager (a role with privileges of reviewing Airlock requests) is able to create Review User Resource (VM) and use it to review the data from. For information on Airlock feature, please refer to the overview page . For documentation on how to review an Airlock request, please refer to the user guide .","title":"Configuring Airlock Review feature"},{"location":"tre-admins/configure-airlock-review/#pre-requisites","text":"The feature is configured on a per Research Workspace basis. Different Research Workspaces need to be configured separately, although a single Airlock Import Workspace can be reused for all of them. Research Workspace can only be configured after it has been deployed, and the template must be of version 0.5.0 or later. Airlock must be enabled in the Research Workspace. To configure the feature, the following prerequisites need to be fulfilled: Airlock Import Workspace need to be deployed (once per TRE). Guacamole Workspace Service need to be deployed in Airlock Import Workspace from the previous step. Template for import review VM needs to be installed in the TRE, or a custom template if used. Guacamole Workspace Service need to be deployed in Research Workspace. Template for export review VM needs to be installed in the TRE, or a custom template if used.","title":"Pre-requisites"},{"location":"tre-admins/configure-airlock-review/#configuring-airlock-vm-for-research-workspace","text":"Navigate to Research Workspace in the UI, and click \"Update\". You will see a check box \"Configure Review VMs\". You then will be able to input the values as follows: For Import Review Workspace ID , use the GUID of the Import Review workspace from step 1. For Import Review Workspace Service ID , use the GUID of the Workspace Service from step 2. For Import Review VM User Resource Template Name , unless you have built a custom template for this, you should use tre-service-guacamole-import-reviewvm which is the name of the standard template used for Import Reviews from step 3. For Export Review Workspace Service ID , use the GUID of the Workspace Service deployed into the Research Workspace from step 4. For Export Review Vm User Resource Template Name , unless you have built a custom template for this, you should use tre-service-guacamole-export-reviewvm which is the name of the standard template used for Import Reviews from step 5. Once you're done, click Submit. Verify that the configuration is working by creating Review VMs for existing import export and export requests (configuration is not verified on update).","title":"Configuring Airlock VM for Research Workspace"},{"location":"tre-admins/configure-airlock-review/#troubleshooting","text":"","title":"Troubleshooting"},{"location":"tre-admins/configure-airlock-review/#users-cannot-create-review-vms","text":"If a user sees an error when creating Review VMs, this most likely means that the configuration isn't correct. Double-check that all GUIDs don't have any symbols missing, and the names of templates are correct.","title":"Users cannot create Review VMs"},{"location":"tre-admins/environment-variables/","text":"Environment variables Info The .tfvars file is intentionally not used. The .env file format is easier to parse, meaning we can use the values for bash scripts and other purposes. For shared management resources in /config.yaml Environment variable name Description LOCATION The Azure location (region) for all resources. MGMT_RESOURCE_GROUP_NAME The shared resource group for all management resources, including the storage account. MGMT_STORAGE_ACCOUNT_NAME The name of the storage account to hold the Terraform state and other deployment artifacts. TERRAFORM_STATE_CONTAINER_NAME The name of the blob container to hold the Terraform state Default value is tfstate . ACR_NAME A globally unique name for the Azure Container Registry (ACR) that will be created to store deployment images. ARM_SUBSCRIPTION_ID Optional for manual deployment. If not specified the az cli selected subscription will be used. The Azure subscription ID for all resources. ARM_CLIENT_ID Optional for manual deployment without logged-in credentials. The client whose azure identity will be used to deploy the solution. ARM_CLIENT_SECRET Optional for manual deployment without logged-in credentials. The password of the client defined in ARM_CLIENT_ID . ARM_TENANT_ID Optional for manual deployment. If not specified the az cli selected subscription will be used. The AAD tenant of the client defined in ARM_CLIENT_ID . For Azure TRE instance in /config.yaml Environment variable name Description TRE_ID A globally unique identifier. TRE_ID can be found in the resource names of the Azure TRE instance; for example, a TRE_ID of mytre-dev will result in a resource group name for Azure TRE instance of rg-mytre-dev . This must be less than 12 characters. Allowed characters: Alphanumeric and underscores TRE_URL This will be generated for you by populating your TRE_ID . This is used so that you can automatically register bundles CORE_ADDRESS_SPACE The address space for the Azure TRE core virtual network. /22 or larger. TRE_ADDRESS_SPACE The address space for the whole TRE environment virtual network where workspaces networks will be created (can include the core network as well). E.g. 10.0.0.0/12 SWAGGER_UI_CLIENT_ID Generated when following pre-deployment steps guide. Client ID for swagger client to make requests. AAD_TENANT_ID Generated when following pre-deployment steps guide. Tenant id against which auth is performed. API_CLIENT_ID Generated when following pre-deployment steps guide. Client id of the \"TRE API\". API_CLIENT_SECRET Generated when following pre-deployment steps guide. Client secret of the \"TRE API\". STATEFUL_RESOURCES_LOCKED If set to false locks on stateful resources won't be created. A recommended setting for developers. ENABLE_AIRLOCK_MALWARE_SCANNING If False, Airlock requests will skip the malware scanning stage. If set to True, Setting up a scanner manually is required! ENABLE_LOCAL_DEBUGGING Set to false by default. Setting this to true will ensure that Azure resources are accessible from your local development machine. (e.g. ServiceBus and Cosmos) PUBLIC_DEPLOYMENT_IP_ADDRESS The public IP address of the machine that is deploying TRE. (Your desktop or the build agents). In certain locations a dynamic script to retrieve this from https://ipecho.net/plain does not work. If this is the case, then you can 'hardcode' your IP. RESOURCE_PROCESSOR_VMSS_SKU The SKU of the VMMS to use for the resource processing VM. CORE_APP_SERVICE_PLAN_SKU The SKU of AppService plans created for the core infrastructure. WORKSPACE_APP_SERVICE_PLAN_SKU Optional. The SKU used for AppService plan used in E2E tests unless otherwise specified. Default value is P1v2 . RESOURCE_PROCESSOR_NUMBER_PROCESSES_PER_INSTANCE Optional. The number of processes to instantiate when the Resource Processor starts. Equates to the number of parallel deployment operations possible in your TRE. Defaults to 5 . For authentication in /config.yaml Variable Description APPLICATION_ADMIN_CLIENT_ID This client will administer AAD Applications for TRE APPLICATION_ADMIN_CLIENT_SECRET This client will administer AAD Applications for TRE TEST_ACCOUNT_CLIENT_ID This will be created by default, but can be disabled by editing /devops/scripts/create_aad_assets.sh . This is the user that will run the tests for you TEST_ACCOUNT_CLIENT_SECRET This will be created by default, but can be disabled by editing /devops/scripts/create_aad_assets.sh . This is the user that will run the tests for you API_CLIENT_ID API application (client) ID. API_CLIENT_SECRET API application client secret. SWAGGER_UI_CLIENT_ID Swagger (OpenAPI) UI application (client) ID. WORKSPACE_API_CLIENT_ID Each workspace is secured behind it's own AD Application WORKSPACE_API_CLIENT_SECRET Each workspace is secured behind it's own AD Application. This is the secret for that application. For CI/CD pipelines in github environment secrets Variable Description AZURE_CREDENTIALS Credentials used to authorize CI/CD workflows to provision resources for the TRE workspaces and workspace services. This is basically your ARM client credentials in json format. Read more about how to create it and its format here MS_TEAMS_WEBHOOK_URI URI for the Teams channel webhook","title":"Environment Variables"},{"location":"tre-admins/environment-variables/#environment-variables","text":"Info The .tfvars file is intentionally not used. The .env file format is easier to parse, meaning we can use the values for bash scripts and other purposes.","title":"Environment variables"},{"location":"tre-admins/environment-variables/#for-shared-management-resources-in-configyaml","text":"Environment variable name Description LOCATION The Azure location (region) for all resources. MGMT_RESOURCE_GROUP_NAME The shared resource group for all management resources, including the storage account. MGMT_STORAGE_ACCOUNT_NAME The name of the storage account to hold the Terraform state and other deployment artifacts. TERRAFORM_STATE_CONTAINER_NAME The name of the blob container to hold the Terraform state Default value is tfstate . ACR_NAME A globally unique name for the Azure Container Registry (ACR) that will be created to store deployment images. ARM_SUBSCRIPTION_ID Optional for manual deployment. If not specified the az cli selected subscription will be used. The Azure subscription ID for all resources. ARM_CLIENT_ID Optional for manual deployment without logged-in credentials. The client whose azure identity will be used to deploy the solution. ARM_CLIENT_SECRET Optional for manual deployment without logged-in credentials. The password of the client defined in ARM_CLIENT_ID . ARM_TENANT_ID Optional for manual deployment. If not specified the az cli selected subscription will be used. The AAD tenant of the client defined in ARM_CLIENT_ID .","title":"For shared management resources in /config.yaml"},{"location":"tre-admins/environment-variables/#for-azure-tre-instance-in-configyaml","text":"Environment variable name Description TRE_ID A globally unique identifier. TRE_ID can be found in the resource names of the Azure TRE instance; for example, a TRE_ID of mytre-dev will result in a resource group name for Azure TRE instance of rg-mytre-dev . This must be less than 12 characters. Allowed characters: Alphanumeric and underscores TRE_URL This will be generated for you by populating your TRE_ID . This is used so that you can automatically register bundles CORE_ADDRESS_SPACE The address space for the Azure TRE core virtual network. /22 or larger. TRE_ADDRESS_SPACE The address space for the whole TRE environment virtual network where workspaces networks will be created (can include the core network as well). E.g. 10.0.0.0/12 SWAGGER_UI_CLIENT_ID Generated when following pre-deployment steps guide. Client ID for swagger client to make requests. AAD_TENANT_ID Generated when following pre-deployment steps guide. Tenant id against which auth is performed. API_CLIENT_ID Generated when following pre-deployment steps guide. Client id of the \"TRE API\". API_CLIENT_SECRET Generated when following pre-deployment steps guide. Client secret of the \"TRE API\". STATEFUL_RESOURCES_LOCKED If set to false locks on stateful resources won't be created. A recommended setting for developers. ENABLE_AIRLOCK_MALWARE_SCANNING If False, Airlock requests will skip the malware scanning stage. If set to True, Setting up a scanner manually is required! ENABLE_LOCAL_DEBUGGING Set to false by default. Setting this to true will ensure that Azure resources are accessible from your local development machine. (e.g. ServiceBus and Cosmos) PUBLIC_DEPLOYMENT_IP_ADDRESS The public IP address of the machine that is deploying TRE. (Your desktop or the build agents). In certain locations a dynamic script to retrieve this from https://ipecho.net/plain does not work. If this is the case, then you can 'hardcode' your IP. RESOURCE_PROCESSOR_VMSS_SKU The SKU of the VMMS to use for the resource processing VM. CORE_APP_SERVICE_PLAN_SKU The SKU of AppService plans created for the core infrastructure. WORKSPACE_APP_SERVICE_PLAN_SKU Optional. The SKU used for AppService plan used in E2E tests unless otherwise specified. Default value is P1v2 . RESOURCE_PROCESSOR_NUMBER_PROCESSES_PER_INSTANCE Optional. The number of processes to instantiate when the Resource Processor starts. Equates to the number of parallel deployment operations possible in your TRE. Defaults to 5 .","title":"For Azure TRE instance in /config.yaml"},{"location":"tre-admins/environment-variables/#for-authentication-in-configyaml","text":"Variable Description APPLICATION_ADMIN_CLIENT_ID This client will administer AAD Applications for TRE APPLICATION_ADMIN_CLIENT_SECRET This client will administer AAD Applications for TRE TEST_ACCOUNT_CLIENT_ID This will be created by default, but can be disabled by editing /devops/scripts/create_aad_assets.sh . This is the user that will run the tests for you TEST_ACCOUNT_CLIENT_SECRET This will be created by default, but can be disabled by editing /devops/scripts/create_aad_assets.sh . This is the user that will run the tests for you API_CLIENT_ID API application (client) ID. API_CLIENT_SECRET API application client secret. SWAGGER_UI_CLIENT_ID Swagger (OpenAPI) UI application (client) ID. WORKSPACE_API_CLIENT_ID Each workspace is secured behind it's own AD Application WORKSPACE_API_CLIENT_SECRET Each workspace is secured behind it's own AD Application. This is the secret for that application.","title":"For authentication in /config.yaml"},{"location":"tre-admins/environment-variables/#for-cicd-pipelines-in-github-environment-secrets","text":"Variable Description AZURE_CREDENTIALS Credentials used to authorize CI/CD workflows to provision resources for the TRE workspaces and workspace services. This is basically your ARM client credentials in json format. Read more about how to create it and its format here MS_TEAMS_WEBHOOK_URI URI for the Teams channel webhook","title":"For CI/CD pipelines in github environment secrets"},{"location":"tre-admins/registering-templates/","text":"Registering Templates To enable users to deploy Workspaces, Workspace Services or User Resources, we need to register their Templates. This can be done wither by running make commands; using the API or devops scripts. In this article both approaches are described. Info Templates are encapsulated in Porter bundles. Registration with make commands Porter bundles can be prepared and registered with make commands, which can be useful for CI/CD scenarios. Before registering, Porter bundles must be built ( make bundle-build ) and then published to the TRE registry ( make bundle publish ), before finally registering it for use with the TRE using make bundle-register . Here we use the Azure ML workspace service bundle as an example: make bundle-build DIR=templates/workspace_services/azureml make bundle-publish DIR=templates/workspace_services/azureml make bundle-register DIR=templates/workspace_services/azureml BUNDLE_TYPE=workspace_service If you're building, publishing and registering a lot of bundles, using three separate commands can be cumbersome, so there is a unifed command for each bundle type to make this easier: make workspace_service_bundle BUNDLE=azureml There are also make workspace_bundle , make shared_service_bundle and make user_resource_bundle commands for the corresponding bundle resource types. Tip The make user_resource_bundle also requires a WORKSPACE_SERVICE parameter to be passed alongside BUNDLE which specifies the workspace service that the user resource belongs to. Registration using Swagger UI Porter bundles can also be registered interactively using the Swagger UI. For that we need to build and publish the porter bundle Build the Porter bundle make bundle-build DIR=templates/workspace_services/azureml make bundle-publish DIR=templates/workspace_services/azureml Use the utility script to generate the payload. The script needs to be executed from within the bundle directory, for example /templates/workspaces/base/ ../../../devops/scripts/register_bundle_with_api.sh -r <acr_name> -t workspace --dry-run Copy the resulting JSON payload. Navigate to the Swagger UI at /api/docs Log into the Swagger UI using Authorize Click Try it out on the POST /api/workspace-templates operation: Paste the payload json generated earlier into the Request body field, then click Execute . Review the server response. Verify the template registration using the GET operation on /api/workspace-templates . The name of the template should now be listed. Registration using script To use the script to automatically register the template, you must create a user that does not require an interactive login per the e2e test user documentation here . The script needs to be executed from within the bundle directory, for example /templates/workspaces/base/ Usage: ../../../devops/scripts/register_bundle_with_api.sh [-c --current] Options: -r, --acr-name Azure Container Registry Name -t, --bundle-type Bundle type: workspace, workspace_service, user_resource or shared_service -w, --workspace-service-name The template name of the user resource (if registering a user_resource) -c, --current Make this the currently deployed version of this template -v, --verify Verify registration with the API In addition to generating the payload, the script posts the payload to the /api/workspace-templates endpoint. Once registered the template can be retrieved by a GET operation on /api/workspace-templates . Tip Follow the same procedure to register workspace service templates and user resource templates","title":"Registering Templates"},{"location":"tre-admins/registering-templates/#registering-templates","text":"To enable users to deploy Workspaces, Workspace Services or User Resources, we need to register their Templates. This can be done wither by running make commands; using the API or devops scripts. In this article both approaches are described. Info Templates are encapsulated in Porter bundles.","title":"Registering Templates"},{"location":"tre-admins/registering-templates/#registration-with-make-commands","text":"Porter bundles can be prepared and registered with make commands, which can be useful for CI/CD scenarios. Before registering, Porter bundles must be built ( make bundle-build ) and then published to the TRE registry ( make bundle publish ), before finally registering it for use with the TRE using make bundle-register . Here we use the Azure ML workspace service bundle as an example: make bundle-build DIR=templates/workspace_services/azureml make bundle-publish DIR=templates/workspace_services/azureml make bundle-register DIR=templates/workspace_services/azureml BUNDLE_TYPE=workspace_service If you're building, publishing and registering a lot of bundles, using three separate commands can be cumbersome, so there is a unifed command for each bundle type to make this easier: make workspace_service_bundle BUNDLE=azureml There are also make workspace_bundle , make shared_service_bundle and make user_resource_bundle commands for the corresponding bundle resource types. Tip The make user_resource_bundle also requires a WORKSPACE_SERVICE parameter to be passed alongside BUNDLE which specifies the workspace service that the user resource belongs to.","title":"Registration with make commands"},{"location":"tre-admins/registering-templates/#registration-using-swagger-ui","text":"Porter bundles can also be registered interactively using the Swagger UI. For that we need to build and publish the porter bundle Build the Porter bundle make bundle-build DIR=templates/workspace_services/azureml make bundle-publish DIR=templates/workspace_services/azureml Use the utility script to generate the payload. The script needs to be executed from within the bundle directory, for example /templates/workspaces/base/ ../../../devops/scripts/register_bundle_with_api.sh -r <acr_name> -t workspace --dry-run Copy the resulting JSON payload. Navigate to the Swagger UI at /api/docs Log into the Swagger UI using Authorize Click Try it out on the POST /api/workspace-templates operation: Paste the payload json generated earlier into the Request body field, then click Execute . Review the server response. Verify the template registration using the GET operation on /api/workspace-templates . The name of the template should now be listed.","title":"Registration using Swagger UI"},{"location":"tre-admins/registering-templates/#registration-using-script","text":"To use the script to automatically register the template, you must create a user that does not require an interactive login per the e2e test user documentation here . The script needs to be executed from within the bundle directory, for example /templates/workspaces/base/ Usage: ../../../devops/scripts/register_bundle_with_api.sh [-c --current] Options: -r, --acr-name Azure Container Registry Name -t, --bundle-type Bundle type: workspace, workspace_service, user_resource or shared_service -w, --workspace-service-name The template name of the user resource (if registering a user_resource) -c, --current Make this the currently deployed version of this template -v, --verify Verify registration with the API In addition to generating the payload, the script posts the payload to the /api/workspace-templates endpoint. Once registered the template can be retrieved by a GET operation on /api/workspace-templates . Tip Follow the same procedure to register workspace service templates and user resource templates","title":"Registration using script"},{"location":"tre-admins/start-stop/","text":"Start/Stop Azure TRE Once you've provisioned an Azure TRE instance it will begin to incurr running costs of the underlying Azure services. Within evaluation or development, you may want to \"pause\" the TRE environment during out of hours or weekends, to reduce costs without having to completely destroy the environment. The following make targets provide a simple way to start and stop both the Azure Firewall and Azure Application Gateway instances, considerably reducing the Azure TRE instance running costs. Info After running make all underlying Azure TRE services are automatically started, billing will start. Start Azure TRE This will allocate the Azure Firewall settings with a public IP and start the Azure Application Gateway service, starting billing of both services. make tre-start Stop Azure TRE This will deallocate the Azure Firewall public IP and stop the Azure Application Gateway service, stopping billing of both services. make tre-stop Automating stop In certain situations, you might want to stop any TRE running on a schedule to reduce costs in a wider way. We have this procedure setup in our development subscriptions where each night we stop all our environments after which each developer would need to manually start their TRE when they need it again. Requirements We use Azure Automation to run this procedure. Be sure to create a runbook with Powershell 7.1 enabled and an identity with contributor permissions on the subscription. Note that the script below uses a system managed identity and if you use something different then you might need to update the authentication part. If you create a new Automation account, you will have the required modules preinstalled. Finally, schedule it to run when it makes sense for you. Runbook Script try { \"Logging in to Azure...\" Connect-AzAccount -Identity } catch { Write-Error -Message $_ . Exception throw $_ . Exception } $azContext = Get-AzContext $azProfile = [Microsoft.Azure.Commands.Common.Authentication.Abstractions.AzureRmProfileProvider] :: Instance . Profile $profileClient = New-Object -TypeName Microsoft . Azure . Commands . ResourceManager . Common . RMProfileClient -ArgumentList ( $azProfile ) $token = $profileClient . AcquireAccessToken ( $azContext . Subscription . TenantId ) $authHeader = @{ 'Content-Type' = 'application/json' 'Authorization' = 'Bearer ' + $token . AccessToken } $ResourceGroups = Get-AzResourceGroup -Tag @{ 'project' = 'Azure Trusted Research Environment' } foreach ( $Group in $ResourceGroups ) { if ( $Group . ResourceGroupName -like '*-ws-*' ) { # we deal with the workspace resource groups separately. continue } $Firewall = Get-AzFirewall -ResourceGroupName $Group . ResourceGroupName if ( $Firewall -ne $null ) { $Firewall . Deallocate () Write-Output \"Deallocating $( $Firewall . Name ) \" Set-AzFirewall -AzureFirewall $Firewall } $Gateway = Get-AzApplicationGateway -ResourceGroupName $Group . ResourceGroupName if ( $Gateway -ne $null ) { Write-Output \"Stopping $( $Gateway . Name ) \" Stop-AzApplicationGateway -ApplicationGateway $Gateway } $MySQLServers = Get-AzResource -ResourceGroupName $Group . ResourceGroupName -ResourceType \"Microsoft.DBforMySQL/servers\" foreach ( $Server in $MySQLServers ) { # Invoke the REST API Write-Output \"Stopping $( $Server . Name ) \" $restUri = 'https://management.azure.com/subscriptions/' + $azContext . Subscription . Id + '/resourceGroups/' + $Group . ResourceGroupName + '/providers/Microsoft.DBForMySQL/servers/' + $Server . Name + '/stop?api-version=2020-01-01' $response = Invoke-RestMethod -Uri $restUri -Method POST -Headers $authHeader } $VMSS = Get-AzVMSS -ResourceGroupName $Group . ResourceGroupName foreach ( $item in $VMSS ) { Write-Output \"Stopping $( $item . Name ) \" Stop-AzVmss -ResourceGroupName $item . ResourceGroupName -VMScaleSetName $item . Name -Force } $VM = Get-AzVM -ResourceGroupName $Group . ResourceGroupName foreach ( $item in $VM ) { Write-Output \"Stopping $( $item . Name ) \" Stop-AzVm -ResourceGroupName $item . ResourceGroupName -Name $item . Name -Force } $WorkspaceResourceGroups = Get-AzResourceGroup -Name \" $( $Group . ResourceGroupName ) -ws-*\" foreach ( $wsrg in $WorkspaceResourceGroups ) { $VM = Get-AzVM -ResourceGroupName $wsrg . ResourceGroupName foreach ( $item in $VM ) { Write-Output \"Stopping $( $item . Name ) \" Stop-AzVm -ResourceGroupName $item . ResourceGroupName -Name $item . Name -Force } } }","title":"Starting and Stopping Azure TRE Services"},{"location":"tre-admins/start-stop/#startstop-azure-tre","text":"Once you've provisioned an Azure TRE instance it will begin to incurr running costs of the underlying Azure services. Within evaluation or development, you may want to \"pause\" the TRE environment during out of hours or weekends, to reduce costs without having to completely destroy the environment. The following make targets provide a simple way to start and stop both the Azure Firewall and Azure Application Gateway instances, considerably reducing the Azure TRE instance running costs. Info After running make all underlying Azure TRE services are automatically started, billing will start.","title":"Start/Stop Azure TRE"},{"location":"tre-admins/start-stop/#start-azure-tre","text":"This will allocate the Azure Firewall settings with a public IP and start the Azure Application Gateway service, starting billing of both services. make tre-start","title":"Start Azure TRE"},{"location":"tre-admins/start-stop/#stop-azure-tre","text":"This will deallocate the Azure Firewall public IP and stop the Azure Application Gateway service, stopping billing of both services. make tre-stop","title":"Stop Azure TRE"},{"location":"tre-admins/start-stop/#automating-stop","text":"In certain situations, you might want to stop any TRE running on a schedule to reduce costs in a wider way. We have this procedure setup in our development subscriptions where each night we stop all our environments after which each developer would need to manually start their TRE when they need it again.","title":"Automating stop"},{"location":"tre-admins/start-stop/#requirements","text":"We use Azure Automation to run this procedure. Be sure to create a runbook with Powershell 7.1 enabled and an identity with contributor permissions on the subscription. Note that the script below uses a system managed identity and if you use something different then you might need to update the authentication part. If you create a new Automation account, you will have the required modules preinstalled. Finally, schedule it to run when it makes sense for you.","title":"Requirements"},{"location":"tre-admins/start-stop/#runbook-script","text":"try { \"Logging in to Azure...\" Connect-AzAccount -Identity } catch { Write-Error -Message $_ . Exception throw $_ . Exception } $azContext = Get-AzContext $azProfile = [Microsoft.Azure.Commands.Common.Authentication.Abstractions.AzureRmProfileProvider] :: Instance . Profile $profileClient = New-Object -TypeName Microsoft . Azure . Commands . ResourceManager . Common . RMProfileClient -ArgumentList ( $azProfile ) $token = $profileClient . AcquireAccessToken ( $azContext . Subscription . TenantId ) $authHeader = @{ 'Content-Type' = 'application/json' 'Authorization' = 'Bearer ' + $token . AccessToken } $ResourceGroups = Get-AzResourceGroup -Tag @{ 'project' = 'Azure Trusted Research Environment' } foreach ( $Group in $ResourceGroups ) { if ( $Group . ResourceGroupName -like '*-ws-*' ) { # we deal with the workspace resource groups separately. continue } $Firewall = Get-AzFirewall -ResourceGroupName $Group . ResourceGroupName if ( $Firewall -ne $null ) { $Firewall . Deallocate () Write-Output \"Deallocating $( $Firewall . Name ) \" Set-AzFirewall -AzureFirewall $Firewall } $Gateway = Get-AzApplicationGateway -ResourceGroupName $Group . ResourceGroupName if ( $Gateway -ne $null ) { Write-Output \"Stopping $( $Gateway . Name ) \" Stop-AzApplicationGateway -ApplicationGateway $Gateway } $MySQLServers = Get-AzResource -ResourceGroupName $Group . ResourceGroupName -ResourceType \"Microsoft.DBforMySQL/servers\" foreach ( $Server in $MySQLServers ) { # Invoke the REST API Write-Output \"Stopping $( $Server . Name ) \" $restUri = 'https://management.azure.com/subscriptions/' + $azContext . Subscription . Id + '/resourceGroups/' + $Group . ResourceGroupName + '/providers/Microsoft.DBForMySQL/servers/' + $Server . Name + '/stop?api-version=2020-01-01' $response = Invoke-RestMethod -Uri $restUri -Method POST -Headers $authHeader } $VMSS = Get-AzVMSS -ResourceGroupName $Group . ResourceGroupName foreach ( $item in $VMSS ) { Write-Output \"Stopping $( $item . Name ) \" Stop-AzVmss -ResourceGroupName $item . ResourceGroupName -VMScaleSetName $item . Name -Force } $VM = Get-AzVM -ResourceGroupName $Group . ResourceGroupName foreach ( $item in $VM ) { Write-Output \"Stopping $( $item . Name ) \" Stop-AzVm -ResourceGroupName $item . ResourceGroupName -Name $item . Name -Force } $WorkspaceResourceGroups = Get-AzResourceGroup -Name \" $( $Group . ResourceGroupName ) -ws-*\" foreach ( $wsrg in $WorkspaceResourceGroups ) { $VM = Get-AzVM -ResourceGroupName $wsrg . ResourceGroupName foreach ( $item in $VM ) { Write-Output \"Stopping $( $item . Name ) \" Stop-AzVm -ResourceGroupName $item . ResourceGroupName -Name $item . Name -Force } } }","title":"Runbook Script"},{"location":"tre-admins/tear-down/","text":"Tear-down To remove the Azure TRE and its resources from your Azure subscription run: make tre-destroy Alternatively, you can delete the resource groups in Azure Portal or using the CLI: az group delete --name <resource group name> Finally, delete the app registrations in Azure Portal or using the CLI: az ad app delete --id <application client ID>","title":"Tear-down"},{"location":"tre-admins/tear-down/#tear-down","text":"To remove the Azure TRE and its resources from your Azure subscription run: make tre-destroy Alternatively, you can delete the resource groups in Azure Portal or using the CLI: az group delete --name <resource group name> Finally, delete the app registrations in Azure Portal or using the CLI: az ad app delete --id <application client ID>","title":"Tear-down"},{"location":"tre-admins/upgrading-resources/","text":"Upgrading Resources Version Azure TRE workspaces, workspace services, workspace shared services, and user resources are Porter bundles. Porter bundles are based on Cloud Native Application Bundles (CNAB) . When a new bundle version becomes available, users can upgrade their resources to a newer version after building, publishing and registering the bundle template. Upgrades (and downgrades) are based on CNAB bundle upgrade action . Bundle template versions follow semantic versioning rules . Note Only minor and patch version upgrades are automatically allowed within the Azure TRE upgrade mechanism. Major versions upgrades and any version downgrades are blocked as they are assumed to contain breaking changes or changes that require additional consideration. For users who wish to upgrade a major version, we highly recommend to read the changelog, review what has changed and take some appropriate action before upgrading using force version update . How to upgrade a resource using Swagger UI Resources can be upgrade using Swagger UI, in the following example we show how to upgrade a workspace version from 1.0.0 to 1.0.1, other resources upgrades are similar. First make sure the desired template version is registered, follow these steps if not . Navigate to the Swagger UI at /api/docs . Log into the Swagger UI using Authorize . Click Try it out on the GET /api/workspace/{workspace_id} operation. Provide your workspace_id in the parameters section and click Execute . Copy the _etag property from the response body. Click Try it out on the PATCH /api/workspace/{workspace_id} operation. Provide your workspace_id and _etag parameters which you've just copied. Provide the following payload with the desired version in the Request body parameter and click Execute . { \"templateVersion\" : \"1.0.1\" , } 1. Review server response, it should include a new operation document with upgrade as an action and updating as status for upgrading the workspace and a message states that the Job is starting. Once the upgrade is complete another operation will be created and can be viewed by executing GET /api/workspace/{workspace_id}/operations , review it and make sure its status is updated . Force version update If you wish to upgrade a major version, or downgrade to any version, you can override the blocking in the upgrade mechanism by passing force_version_update=true query parameter to the resource Patch action. For example force version patching a workspace:","title":"Upgrading Resources Version"},{"location":"tre-admins/upgrading-resources/#upgrading-resources-version","text":"Azure TRE workspaces, workspace services, workspace shared services, and user resources are Porter bundles. Porter bundles are based on Cloud Native Application Bundles (CNAB) . When a new bundle version becomes available, users can upgrade their resources to a newer version after building, publishing and registering the bundle template. Upgrades (and downgrades) are based on CNAB bundle upgrade action . Bundle template versions follow semantic versioning rules . Note Only minor and patch version upgrades are automatically allowed within the Azure TRE upgrade mechanism. Major versions upgrades and any version downgrades are blocked as they are assumed to contain breaking changes or changes that require additional consideration. For users who wish to upgrade a major version, we highly recommend to read the changelog, review what has changed and take some appropriate action before upgrading using force version update .","title":"Upgrading Resources Version"},{"location":"tre-admins/upgrading-resources/#how-to-upgrade-a-resource-using-swagger-ui","text":"Resources can be upgrade using Swagger UI, in the following example we show how to upgrade a workspace version from 1.0.0 to 1.0.1, other resources upgrades are similar. First make sure the desired template version is registered, follow these steps if not . Navigate to the Swagger UI at /api/docs . Log into the Swagger UI using Authorize . Click Try it out on the GET /api/workspace/{workspace_id} operation. Provide your workspace_id in the parameters section and click Execute . Copy the _etag property from the response body. Click Try it out on the PATCH /api/workspace/{workspace_id} operation. Provide your workspace_id and _etag parameters which you've just copied. Provide the following payload with the desired version in the Request body parameter and click Execute . { \"templateVersion\" : \"1.0.1\" , } 1. Review server response, it should include a new operation document with upgrade as an action and updating as status for upgrading the workspace and a message states that the Job is starting. Once the upgrade is complete another operation will be created and can be viewed by executing GET /api/workspace/{workspace_id}/operations , review it and make sure its status is updated .","title":"How to upgrade a resource using Swagger UI"},{"location":"tre-admins/upgrading-resources/#force-version-update","text":"If you wish to upgrade a major version, or downgrade to any version, you can override the blocking in the upgrade mechanism by passing force_version_update=true query parameter to the resource Patch action. For example force version patching a workspace:","title":"Force version update"},{"location":"tre-admins/upgrading-tre/","text":"Upgrading AzureTRE version This document will cover how AzureTRE is referenced and how to upgrade its version in the AzureTRE deployment repository Introduction AzureTRE referenced as an external folder in AzureTRE deployment repository (which is used as a template for your project in the quick start guide). A specific version of AzureTRE is downloaded as part of devcontainer setup. A symlink is then created making it available to reference in the directory itself (it is available only for reference, any changes to it are gitignored) How to upgrade AzureTRE version Select AzureTRE version: 1. In AzureTRE go to releases: 1. Choose a release version To upgrade AzureTRE version inside AzureTRE deployment repository : 1. Go to devcontainer.json file 1. Update the OSS_VERSION param to the desired version. ![Upgrade TRE Version](../../assets/using-tre/upgrade_tre_version.png) How to Contribute to our Documentation If you have any comments or suggestions about our documentation then you can visit our GitHub project and either raise a new issue, or comment on one of the existing ones. You can find our existing documentation issues on GitHub by clicking on the link below: Existing Documentation Issues Or, you can raise a new issue by clicking on this link: Report an Issue or Make a Suggestion Thank you for your patience and support!","title":"Upgrading AzureTRE Version"},{"location":"tre-admins/upgrading-tre/#upgrading-azuretre-version","text":"This document will cover how AzureTRE is referenced and how to upgrade its version in the AzureTRE deployment repository","title":"Upgrading AzureTRE version"},{"location":"tre-admins/upgrading-tre/#introduction","text":"AzureTRE referenced as an external folder in AzureTRE deployment repository (which is used as a template for your project in the quick start guide). A specific version of AzureTRE is downloaded as part of devcontainer setup. A symlink is then created making it available to reference in the directory itself (it is available only for reference, any changes to it are gitignored)","title":"Introduction"},{"location":"tre-admins/upgrading-tre/#how-to-upgrade-azuretre-version","text":"Select AzureTRE version: 1. In AzureTRE go to releases: 1. Choose a release version To upgrade AzureTRE version inside AzureTRE deployment repository : 1. Go to devcontainer.json file 1. Update the OSS_VERSION param to the desired version. ![Upgrade TRE Version](../../assets/using-tre/upgrade_tre_version.png)","title":"How to upgrade AzureTRE version"},{"location":"tre-admins/upgrading-tre/#how-to-contribute-to-our-documentation","text":"If you have any comments or suggestions about our documentation then you can visit our GitHub project and either raise a new issue, or comment on one of the existing ones. You can find our existing documentation issues on GitHub by clicking on the link below: Existing Documentation Issues Or, you can raise a new issue by clicking on this link: Report an Issue or Make a Suggestion Thank you for your patience and support!","title":"How to Contribute to our Documentation"},{"location":"tre-admins/identities/api/","text":"The API Identity Name The API Identity is typically called <TRE_ID> API within the AAD Portal. Purpose This identity's credentials are stored in the core Key Vault and mandatory for the running of the Trusted Research Environment (TRE). It is required for the API Application, hosted in Azure App Service, to authenticate to Azure Active Directory and authorize the various operations. Application Roles Display name Description Allowed member types Value TRE Administrators Provides resource administrator access to the TRE. Users/Groups,Applications TREAdmin TRE Users Provides access to the TRE application. Users/Groups,Applications TREUser Microsoft Graph Permissions Name Type* Admin consent required TRE usage Directory.Read.All Application Yes Allows the app to read directory objects (roles/permissions) in your organization's directory, such as roles and permissions, without a signed-in user. User.Read.All Application Yes Allows the app to read user profiles without a signed in user to check that the user has permissions to execute an action e.g., to view workspaces. See /api_app/services/aad_authentication.py . email Delegated No Used to read the user's email address when creating TRE resources openid Delegated No Allows users to sign in to the app with their work or school accounts and allows the app to see basic user profile information. profile Delegated No Used to read the user's profile when creating TRE resources '*' See the difference between delegated and application permission types. See Microsoft Graph permissions reference for more details. Clients This identity should only be used by the API Application. How to create Example on how to run the script: ./devops/scripts/aad/create_api_application.sh \\ --name <TRE_ID> \\ --tre-url \"https://<TRE_ID>.<LOCATION>.cloudapp.azure.com\" \\ --admin-consent \\ --automation-clientid <TEST_ACCOUNT_CLIENT_ID> Below is a sample where TRE_ID has value mytre : ./devops/scripts/aad/create_api_application.sh --name mytre --admin-consent \\ --tre-url \"https://mytre_6.westeurope.cloudapp.azure.com\" --automation-clientid 176c2f5d-xxxx-xxxx-xxxx-68a5c30f354d Argument Description --name The prefix of the name of the app registrations. TRE will give you TRE API . --tre-url Used to construct auth redirection URLs for the UI and Swagger app. Use the values of the environment variables TRE_ID and LOCATION in the URL. Reply URL for the localhost, http://localhost:8000/api/docs/oauth2-redirect , will be added by default. --admin-consent Grants admin consent for the app registrations. This is required for them to function properly, but requires AAD admin privileges. --automation-clientid This is an optional parameter but will grant TREAdmin permission to the Service Principal of the Automation Admin. --reset-password Optional, default is 0. When run in a headless fashion, 1 is passed in to always reset the password. Caution The script will create an app password (client secret) for the TRE API app and the Automation App and write them to /config.yaml file. These values are only shown once, if you lose them, the script will create new secrets if run again. You can create an automation account which will aid your development flow, if you don't want to do this you can omit the --automation-clientid switch. You can run the script without the --admin-consent and ask your admin to grant consent. If you don't have permissions and just want to create a development environment then skip this step and see the steps in the \"Using a separate Azure Active Directory tenant) below. Environment Variables Variable Description Location API_CLIENT_ID The Client Id ./config.yaml API_CLIENT_SECRET The client secret ./config.yaml Comments The TRE API app registration requires no redirect URLs defined. From a security standpoint, public client flows should not be allowed. As the identity of the client application cannot be verified (see the image below taken from app registration authentication blade in Azure Portal).","title":"API"},{"location":"tre-admins/identities/api/#the-api-identity","text":"","title":"The API Identity"},{"location":"tre-admins/identities/api/#name","text":"The API Identity is typically called <TRE_ID> API within the AAD Portal.","title":"Name"},{"location":"tre-admins/identities/api/#purpose","text":"This identity's credentials are stored in the core Key Vault and mandatory for the running of the Trusted Research Environment (TRE). It is required for the API Application, hosted in Azure App Service, to authenticate to Azure Active Directory and authorize the various operations.","title":"Purpose"},{"location":"tre-admins/identities/api/#application-roles","text":"Display name Description Allowed member types Value TRE Administrators Provides resource administrator access to the TRE. Users/Groups,Applications TREAdmin TRE Users Provides access to the TRE application. Users/Groups,Applications TREUser","title":"Application Roles"},{"location":"tre-admins/identities/api/#microsoft-graph-permissions","text":"Name Type* Admin consent required TRE usage Directory.Read.All Application Yes Allows the app to read directory objects (roles/permissions) in your organization's directory, such as roles and permissions, without a signed-in user. User.Read.All Application Yes Allows the app to read user profiles without a signed in user to check that the user has permissions to execute an action e.g., to view workspaces. See /api_app/services/aad_authentication.py . email Delegated No Used to read the user's email address when creating TRE resources openid Delegated No Allows users to sign in to the app with their work or school accounts and allows the app to see basic user profile information. profile Delegated No Used to read the user's profile when creating TRE resources '*' See the difference between delegated and application permission types. See Microsoft Graph permissions reference for more details.","title":"Microsoft Graph Permissions"},{"location":"tre-admins/identities/api/#clients","text":"This identity should only be used by the API Application.","title":"Clients"},{"location":"tre-admins/identities/api/#how-to-create","text":"Example on how to run the script: ./devops/scripts/aad/create_api_application.sh \\ --name <TRE_ID> \\ --tre-url \"https://<TRE_ID>.<LOCATION>.cloudapp.azure.com\" \\ --admin-consent \\ --automation-clientid <TEST_ACCOUNT_CLIENT_ID> Below is a sample where TRE_ID has value mytre : ./devops/scripts/aad/create_api_application.sh --name mytre --admin-consent \\ --tre-url \"https://mytre_6.westeurope.cloudapp.azure.com\" --automation-clientid 176c2f5d-xxxx-xxxx-xxxx-68a5c30f354d Argument Description --name The prefix of the name of the app registrations. TRE will give you TRE API . --tre-url Used to construct auth redirection URLs for the UI and Swagger app. Use the values of the environment variables TRE_ID and LOCATION in the URL. Reply URL for the localhost, http://localhost:8000/api/docs/oauth2-redirect , will be added by default. --admin-consent Grants admin consent for the app registrations. This is required for them to function properly, but requires AAD admin privileges. --automation-clientid This is an optional parameter but will grant TREAdmin permission to the Service Principal of the Automation Admin. --reset-password Optional, default is 0. When run in a headless fashion, 1 is passed in to always reset the password. Caution The script will create an app password (client secret) for the TRE API app and the Automation App and write them to /config.yaml file. These values are only shown once, if you lose them, the script will create new secrets if run again. You can create an automation account which will aid your development flow, if you don't want to do this you can omit the --automation-clientid switch. You can run the script without the --admin-consent and ask your admin to grant consent. If you don't have permissions and just want to create a development environment then skip this step and see the steps in the \"Using a separate Azure Active Directory tenant) below.","title":"How to create"},{"location":"tre-admins/identities/api/#environment-variables","text":"Variable Description Location API_CLIENT_ID The Client Id ./config.yaml API_CLIENT_SECRET The client secret ./config.yaml","title":"Environment Variables"},{"location":"tre-admins/identities/api/#comments","text":"The TRE API app registration requires no redirect URLs defined. From a security standpoint, public client flows should not be allowed. As the identity of the client application cannot be verified (see the image below taken from app registration authentication blade in Azure Portal).","title":"Comments"},{"location":"tre-admins/identities/application_admin/","text":"The Application Administrator Identity Purpose This identity's credentials are stored in the core key vault and are used when you wish to update AAD Applications. For instance, when you add Guacamole as a Workspace Service, you would need to add the URI of the Guacamole Service as a Redirect URI to the Workspace App to complete the login flow. Application Roles This application does not have any roles defined. Microsoft Graph Permissions Name Type* Admin consent required TRE usage Application.ReadWrite.OwnedBy Application Yes This user has Application.ReadWrite.OwnedBy as a minimum permission for it to function. If the tenant is managed by a customer administrator, then this user must be added to the Owners of every workspace that is created. This will allow TRE to manage the AAD Application. This will be a manual process for the Tenant Admin. Application.ReadWrite.All Application Yes This permission is required to create workspace applications and administer any applications in the tenant. This is needed if the AAD Administrator has delegated AAD administrative operations to the TRE. There will be no need for the Tenant Admin to manually create workspace applications in the Tenant. Directory.Read.All Application Yes This permission is required to read User details from Azure Active Directory. This is needed if the AAD Administrator has delegated AAD administrative operations to the TRE. Group.ReadWrite.All Application Yes This permission is required to create and update Azure AD groups. This is requried if Azure AD groups are to be created automatically by the TRE. '*' See the difference between delegated and application permission types. See Microsoft Graph permissions reference for more details. Clients This user is currently only used from the Porter bundles hosted on the Resource Processor Virtual Machine Scale Set. How to create ./scripts/aad/create_application_administrator.sh \\ --name \" ${ TRE_ID } \" --admin-consent --application-permission \" ${ APPLICATION_PERMISSION } \" | Argument | Description | | -------- | ----------- | | --name | This is used to put a friendly name to the Application that can be seen in the portal. It is typical to use the name of your TRE instance. | | --admin-consent | If you have the appropriate permission to grant admin consent, then pass in this argument. If you do not, you will have to ask an AAD Admin to consent after you have created the identity. Consent is required for this permission. | --application-permission | This is a comma seperated list of the permissions that need to be assigned. For exampler Application.ReadWrite.All,Directory.Read.All,Group.ReadWrite.All | | --reset-password | Optional, default is 0. When run in a headless fashion, 1 is passed in to always reset the password. | Environment Variables Variable Description Location APPLICATION_ADMIN_CLIENT_ID The Client Id ./config.yaml APPLICATION_ADMIN_CLIENT_SECRET The client secret ./config.yaml","title":"Application Admin"},{"location":"tre-admins/identities/application_admin/#the-application-administrator-identity","text":"","title":"The Application Administrator Identity"},{"location":"tre-admins/identities/application_admin/#purpose","text":"This identity's credentials are stored in the core key vault and are used when you wish to update AAD Applications. For instance, when you add Guacamole as a Workspace Service, you would need to add the URI of the Guacamole Service as a Redirect URI to the Workspace App to complete the login flow.","title":"Purpose"},{"location":"tre-admins/identities/application_admin/#application-roles","text":"This application does not have any roles defined.","title":"Application Roles"},{"location":"tre-admins/identities/application_admin/#microsoft-graph-permissions","text":"Name Type* Admin consent required TRE usage Application.ReadWrite.OwnedBy Application Yes This user has Application.ReadWrite.OwnedBy as a minimum permission for it to function. If the tenant is managed by a customer administrator, then this user must be added to the Owners of every workspace that is created. This will allow TRE to manage the AAD Application. This will be a manual process for the Tenant Admin. Application.ReadWrite.All Application Yes This permission is required to create workspace applications and administer any applications in the tenant. This is needed if the AAD Administrator has delegated AAD administrative operations to the TRE. There will be no need for the Tenant Admin to manually create workspace applications in the Tenant. Directory.Read.All Application Yes This permission is required to read User details from Azure Active Directory. This is needed if the AAD Administrator has delegated AAD administrative operations to the TRE. Group.ReadWrite.All Application Yes This permission is required to create and update Azure AD groups. This is requried if Azure AD groups are to be created automatically by the TRE. '*' See the difference between delegated and application permission types. See Microsoft Graph permissions reference for more details.","title":"Microsoft Graph Permissions"},{"location":"tre-admins/identities/application_admin/#clients","text":"This user is currently only used from the Porter bundles hosted on the Resource Processor Virtual Machine Scale Set.","title":"Clients"},{"location":"tre-admins/identities/application_admin/#how-to-create","text":"./scripts/aad/create_application_administrator.sh \\ --name \" ${ TRE_ID } \" --admin-consent --application-permission \" ${ APPLICATION_PERMISSION } \" | Argument | Description | | -------- | ----------- | | --name | This is used to put a friendly name to the Application that can be seen in the portal. It is typical to use the name of your TRE instance. | | --admin-consent | If you have the appropriate permission to grant admin consent, then pass in this argument. If you do not, you will have to ask an AAD Admin to consent after you have created the identity. Consent is required for this permission. | --application-permission | This is a comma seperated list of the permissions that need to be assigned. For exampler Application.ReadWrite.All,Directory.Read.All,Group.ReadWrite.All | | --reset-password | Optional, default is 0. When run in a headless fashion, 1 is passed in to always reset the password. |","title":"How to create"},{"location":"tre-admins/identities/application_admin/#environment-variables","text":"Variable Description Location APPLICATION_ADMIN_CLIENT_ID The Client Id ./config.yaml APPLICATION_ADMIN_CLIENT_SECRET The client secret ./config.yaml","title":"Environment Variables"},{"location":"tre-admins/identities/auth-manual/","text":"Manually creating AAD identities This guide is here if you wanted to create these Application Registrations manually. These should be created in order (if applicable) as some applications are then granted permission to other applications. Manual Creation Guides Application Comments Application Admin This is required TRE API This is required UI Client This is created when you create the TRE API. Automation Account This is optional Workspace You need one of these per Workspace if you wish to have different users in each workspace.","title":"Manual Setup"},{"location":"tre-admins/identities/auth-manual/#manually-creating-aad-identities","text":"This guide is here if you wanted to create these Application Registrations manually. These should be created in order (if applicable) as some applications are then granted permission to other applications.","title":"Manually creating AAD identities"},{"location":"tre-admins/identities/auth-manual/#manual-creation-guides","text":"Application Comments Application Admin This is required TRE API This is required UI Client This is created when you create the TRE API. Automation Account This is optional Workspace You need one of these per Workspace if you wish to have different users in each workspace.","title":"Manual Creation Guides"},{"location":"tre-admins/identities/client/","text":"TRE Client UX Name The Client Identity is typically called <TRE_ID> UX within the AAD Portal. Purpose This identity is used by any public facing client application so that user impersonation can occur to the Core API and any Workspace Applications. Application Roles This application does not have any roles defined. Permissions Name Type* Admin consent required TRE usage offline_access Delegated No Allows the app to see and update the data you gave it access to, even when users are not currently using the app. openid Delegated No Allows users to sign in to the app with their work or school accounts and allows the app to see basic user profile information. TRE API/user_impersonation Delegated No Flow the authenticated user to the TRE API when needed. Workspace API/user_impersonation Delegated No Flow the authenticated user to the Workspace API when needed. '*' See the difference between delegated and application permission types. See Microsoft Graph permissions reference for more details. Clients This identity should only be used by client applications. Currently this is the React UI and the Swagger UI. How to create This identity is created when you create the API. For completeness, you can run the following script Example on how to run the script: ./devops/scripts/aad/create_api_application.sh \\ --name <TRE_ID> \\ --tre-url \"https://<TRE_ID>.<LOCATION>.cloudapp.azure.com\" \\ --admin-consent \\ --automation-clientid <TEST_ACCOUNT_CLIENT_ID> Argument Description --name The prefix of the name of the app registrations. TRE will give you TRE API . --tre-url Used to construct auth redirection URLs for the UI and Swagger app. Use the values of the environment variables TRE_ID and LOCATION in the URL. Reply URL for the localhost, http://localhost:8000/api/docs/oauth2-redirect , will be added by default. --admin-consent Grants admin consent for the app registrations. This is required for them to function properly, but requires AAD admin privileges. --automation-clientid This is an optional parameter but will create an application with test users with permission to use the TRE API and TRE Swagger UI --reset-password Optional, default is 0. This flag has no relevance when creating the UX as there is no password for the AAD Application. Redirect URLs The following Redirect URIs will be added to the application * https://<TRE ID>.<Azure location>.cloudapp.azure.com * http://localhost:8000/docs/oauth2-redirect - For local testing Environment Variables Variable Description Location SWAGGER_UI_CLIENT_ID The Client Id ./config.yaml","title":"Client"},{"location":"tre-admins/identities/client/#tre-client-ux","text":"","title":"TRE Client UX"},{"location":"tre-admins/identities/client/#name","text":"The Client Identity is typically called <TRE_ID> UX within the AAD Portal.","title":"Name"},{"location":"tre-admins/identities/client/#purpose","text":"This identity is used by any public facing client application so that user impersonation can occur to the Core API and any Workspace Applications.","title":"Purpose"},{"location":"tre-admins/identities/client/#application-roles","text":"This application does not have any roles defined.","title":"Application Roles"},{"location":"tre-admins/identities/client/#permissions","text":"Name Type* Admin consent required TRE usage offline_access Delegated No Allows the app to see and update the data you gave it access to, even when users are not currently using the app. openid Delegated No Allows users to sign in to the app with their work or school accounts and allows the app to see basic user profile information. TRE API/user_impersonation Delegated No Flow the authenticated user to the TRE API when needed. Workspace API/user_impersonation Delegated No Flow the authenticated user to the Workspace API when needed. '*' See the difference between delegated and application permission types. See Microsoft Graph permissions reference for more details.","title":"Permissions"},{"location":"tre-admins/identities/client/#clients","text":"This identity should only be used by client applications. Currently this is the React UI and the Swagger UI.","title":"Clients"},{"location":"tre-admins/identities/client/#how-to-create","text":"This identity is created when you create the API. For completeness, you can run the following script Example on how to run the script: ./devops/scripts/aad/create_api_application.sh \\ --name <TRE_ID> \\ --tre-url \"https://<TRE_ID>.<LOCATION>.cloudapp.azure.com\" \\ --admin-consent \\ --automation-clientid <TEST_ACCOUNT_CLIENT_ID> Argument Description --name The prefix of the name of the app registrations. TRE will give you TRE API . --tre-url Used to construct auth redirection URLs for the UI and Swagger app. Use the values of the environment variables TRE_ID and LOCATION in the URL. Reply URL for the localhost, http://localhost:8000/api/docs/oauth2-redirect , will be added by default. --admin-consent Grants admin consent for the app registrations. This is required for them to function properly, but requires AAD admin privileges. --automation-clientid This is an optional parameter but will create an application with test users with permission to use the TRE API and TRE Swagger UI --reset-password Optional, default is 0. This flag has no relevance when creating the UX as there is no password for the AAD Application.","title":"How to create"},{"location":"tre-admins/identities/client/#redirect-urls","text":"The following Redirect URIs will be added to the application * https://<TRE ID>.<Azure location>.cloudapp.azure.com * http://localhost:8000/docs/oauth2-redirect - For local testing","title":"Redirect URLs"},{"location":"tre-admins/identities/client/#environment-variables","text":"Variable Description Location SWAGGER_UI_CLIENT_ID The Client Id ./config.yaml","title":"Environment Variables"},{"location":"tre-admins/identities/test-account/","text":"TRE Automation Admin Application Name The Automation Application is typically called <TRE_ID> Automation Admin within the AAD Portal. Purpose This application is used to authorize end-to-end test scenarios. Note This app registration is only needed and used for testing Application Roles This application does not have any roles defined. Permissions Name Type* Admin consent required TRE usage TRE API / TREAdmin Application Yes This allows this application to authenticate as a TRE Admin for running the tests locally and the E2E in the build. TRE API / user_impersonation Delegated No This allows the application to impersonate the logged in user. TRE - workspace x API / WorkspaceOwner Application Yes This allows this application to authenticate as a Workspace Owner for running the tests locally and the E2E in the build. TRE - workspace x API / user_impersonation Delegated No This allows the application to impersonate the logged in user. '*' See the difference between delegated and application permission types. See Microsoft Graph permissions reference for more details. Clients This application is used locally to automatically register bundles against the API and is the user that runs the E2E locally and in the Build. Environment Variables Variable Description Location TEST_ACCOUNT_CLIENT_ID The Client Id ./config.yaml TEST_ACCOUNT_CLIENT_SECRET The client secret ./config.yaml How to create Example on how to run the script: ./devops/scripts/aad/create_automation_administrator.sh \\ --name \" ${ TRE_ID } \" Argument Description --name The prefix of the name of the app registrations. TRE123 will give you TRE123 Automation Admin . --reset-password Optional, default is 0. When run in a headless fashion, 1 is passed in to always reset the password. Create this application from the portal (optional) To create an application registration for automation, open the Azure Active Directory tenant for your TRE in the portal and navigate to \"App Registrations\". Click \"New registration\" as shown in the image below. Enter a name for the application registration and click \"Register\". On the app registration \"Overview\" page, copy the \"Application (client) ID\" value and save it for later. Under \"Manage\", click on \"Certificates & secrets\" and then \"New client secret\" Add a description and create the client secret. Once done, the secret value will be displayed (as shown below). Copy this value and save it for later as you cannot retrieve it again after closing this page. Add API Permissions After creating the automation application registration, it needs to be granted permissions to access the TRE API. Navigate to the API permissions page for the application registration and click \"Add a permission\" Next, click on the \"My APIs\" tab, and then on \"TRE API\" On the \"Delegated permissions\" section, select \"user_impersonation\". On the \"Application permissions\" section, select \"TRE Administrators\". Back on the main permissions page, click on \"Grant admin consent\". Once done, you should see \"Granted\" in the \"Status\" column, as shown below.","title":"Automation Test Account"},{"location":"tre-admins/identities/test-account/#tre-automation-admin-application","text":"","title":"TRE Automation Admin Application"},{"location":"tre-admins/identities/test-account/#name","text":"The Automation Application is typically called <TRE_ID> Automation Admin within the AAD Portal.","title":"Name"},{"location":"tre-admins/identities/test-account/#purpose","text":"This application is used to authorize end-to-end test scenarios. Note This app registration is only needed and used for testing","title":"Purpose"},{"location":"tre-admins/identities/test-account/#application-roles","text":"This application does not have any roles defined.","title":"Application Roles"},{"location":"tre-admins/identities/test-account/#permissions","text":"Name Type* Admin consent required TRE usage TRE API / TREAdmin Application Yes This allows this application to authenticate as a TRE Admin for running the tests locally and the E2E in the build. TRE API / user_impersonation Delegated No This allows the application to impersonate the logged in user. TRE - workspace x API / WorkspaceOwner Application Yes This allows this application to authenticate as a Workspace Owner for running the tests locally and the E2E in the build. TRE - workspace x API / user_impersonation Delegated No This allows the application to impersonate the logged in user. '*' See the difference between delegated and application permission types. See Microsoft Graph permissions reference for more details.","title":"Permissions"},{"location":"tre-admins/identities/test-account/#clients","text":"This application is used locally to automatically register bundles against the API and is the user that runs the E2E locally and in the Build.","title":"Clients"},{"location":"tre-admins/identities/test-account/#environment-variables","text":"Variable Description Location TEST_ACCOUNT_CLIENT_ID The Client Id ./config.yaml TEST_ACCOUNT_CLIENT_SECRET The client secret ./config.yaml","title":"Environment Variables"},{"location":"tre-admins/identities/test-account/#how-to-create","text":"Example on how to run the script: ./devops/scripts/aad/create_automation_administrator.sh \\ --name \" ${ TRE_ID } \" Argument Description --name The prefix of the name of the app registrations. TRE123 will give you TRE123 Automation Admin . --reset-password Optional, default is 0. When run in a headless fashion, 1 is passed in to always reset the password.","title":"How to create"},{"location":"tre-admins/identities/test-account/#create-this-application-from-the-portal-optional","text":"To create an application registration for automation, open the Azure Active Directory tenant for your TRE in the portal and navigate to \"App Registrations\". Click \"New registration\" as shown in the image below. Enter a name for the application registration and click \"Register\". On the app registration \"Overview\" page, copy the \"Application (client) ID\" value and save it for later. Under \"Manage\", click on \"Certificates & secrets\" and then \"New client secret\" Add a description and create the client secret. Once done, the secret value will be displayed (as shown below). Copy this value and save it for later as you cannot retrieve it again after closing this page.","title":"Create this application from the portal (optional)"},{"location":"tre-admins/identities/test-account/#add-api-permissions","text":"After creating the automation application registration, it needs to be granted permissions to access the TRE API. Navigate to the API permissions page for the application registration and click \"Add a permission\" Next, click on the \"My APIs\" tab, and then on \"TRE API\" On the \"Delegated permissions\" section, select \"user_impersonation\". On the \"Application permissions\" section, select \"TRE Administrators\". Back on the main permissions page, click on \"Grant admin consent\". Once done, you should see \"Granted\" in the \"Status\" column, as shown below.","title":"Add API Permissions"},{"location":"tre-admins/identities/workspace/","text":"Workspace Applications Purpose Access to workspaces is also controlled using app registrations - one per workspace. The configuration of the app registration depends on the nature of the workspace, but this section covers the typical minimum settings. Application Roles Display name Description Allowed member types Value Workspace Owner Provides workspace owners access to the Workspace. Users/Groups,Applications WorkspaceOwner Workspace Researcher Provides researchers access to the Workspace. Users/Groups,Applications WorkspaceResearcher Airlock Manager Provides airlock managers access to the Workspace and ability to review airlock requests. Users/Groups,Applications AirlockManager Microsoft Graph Permissions Name Type* Admin consent required TRE usage email Delegated No Used to read the user's email address when creating TRE resources openid Delegated No Allows users to sign in to the app with their work or school accounts and allows the app to see basic user profile information. profile Delegated No Used to read the user's profile when creating TRE resources '*' See the difference between delegated and application permission types. See Microsoft Graph permissions reference for more details. Clients This identity should only be used by the API Application. How to create There are two mechanisms for creating Workspace Applications - Manually by your AAD Tenant Admin (default) - Automatically by TRE. Please see this guide if you wish this to be automatic. Caution By default, the app registration for a workspace is not created by the API . One needs to be present before using the API to provision a new workspace. If you ran make auth , a workspace AD application was created for you. If you wish to create another, the same script can be used to create the Workspace Application . Example on how to run the script: ./devops/scripts/aad/create_workspace_application.sh \\ --name \" ${ TRE_ID } - workspace 11\" \\ --admin-consent \\ --ux-clientid \" ${ SWAGGER_UI_CLIENT_ID } \" \\ --automation-clientid \" ${ TEST_ACCOUNT_CLIENT_ID } \" \\ --application-admin-clientid \" ${ APPLICATION_ADMIN_CLIENT_ID } \" Argument Description --name The name of the application. This will be suffixed with 'API' by the script. --ux-clientid This value is one of the outputs when you first ran the script. It is mandatory if you use admin-consent. --admin-consent Grants admin consent for the app registrations. This is required for them to function properly, but requires AAD admin privileges. --automation-clientid This is an optional parameter but will grant the Automation App (created in step 1) permission to the new workspace app. --application-admin-clientid This is a required parameter , and should be a client id that will be added to the Owners of the AAD Application so that it can be administered within TRE. --reset-password Optional, default is 0. When run in a headless fashion, 1 is passed in to always reset the password. Caution The script will create an app password (client secret) for the workspace and write to /config.yaml under the authentication section. These values are only shown once, if you lose them, the script will create new secrets if run again. If you do not wish to grant the Automation App permission to your workspace, just remove the --automation-clientid from the command. Environment Variables Variable Description Location WORKSPACE_API_CLIENT_ID The Client Id ./config.yaml WORKSPACE_API_CLIENT_SECRET The client secret ./config.yaml Comments When the Workspace AAD app is registered by running make auth , the Workspace Scope Id is the same as the Client Id. When the Workspace AAD app is created by the base workspace, the Workspace Scope Id will be in this format api://<TRE_ID>_ws_<WORKSPACE_SHORT_IDENTIFIER>","title":"Workspaces"},{"location":"tre-admins/identities/workspace/#workspace-applications","text":"","title":"Workspace Applications"},{"location":"tre-admins/identities/workspace/#purpose","text":"Access to workspaces is also controlled using app registrations - one per workspace. The configuration of the app registration depends on the nature of the workspace, but this section covers the typical minimum settings.","title":"Purpose"},{"location":"tre-admins/identities/workspace/#application-roles","text":"Display name Description Allowed member types Value Workspace Owner Provides workspace owners access to the Workspace. Users/Groups,Applications WorkspaceOwner Workspace Researcher Provides researchers access to the Workspace. Users/Groups,Applications WorkspaceResearcher Airlock Manager Provides airlock managers access to the Workspace and ability to review airlock requests. Users/Groups,Applications AirlockManager","title":"Application Roles"},{"location":"tre-admins/identities/workspace/#microsoft-graph-permissions","text":"Name Type* Admin consent required TRE usage email Delegated No Used to read the user's email address when creating TRE resources openid Delegated No Allows users to sign in to the app with their work or school accounts and allows the app to see basic user profile information. profile Delegated No Used to read the user's profile when creating TRE resources '*' See the difference between delegated and application permission types. See Microsoft Graph permissions reference for more details.","title":"Microsoft Graph Permissions"},{"location":"tre-admins/identities/workspace/#clients","text":"This identity should only be used by the API Application.","title":"Clients"},{"location":"tre-admins/identities/workspace/#how-to-create","text":"There are two mechanisms for creating Workspace Applications - Manually by your AAD Tenant Admin (default) - Automatically by TRE. Please see this guide if you wish this to be automatic. Caution By default, the app registration for a workspace is not created by the API . One needs to be present before using the API to provision a new workspace. If you ran make auth , a workspace AD application was created for you. If you wish to create another, the same script can be used to create the Workspace Application . Example on how to run the script: ./devops/scripts/aad/create_workspace_application.sh \\ --name \" ${ TRE_ID } - workspace 11\" \\ --admin-consent \\ --ux-clientid \" ${ SWAGGER_UI_CLIENT_ID } \" \\ --automation-clientid \" ${ TEST_ACCOUNT_CLIENT_ID } \" \\ --application-admin-clientid \" ${ APPLICATION_ADMIN_CLIENT_ID } \" Argument Description --name The name of the application. This will be suffixed with 'API' by the script. --ux-clientid This value is one of the outputs when you first ran the script. It is mandatory if you use admin-consent. --admin-consent Grants admin consent for the app registrations. This is required for them to function properly, but requires AAD admin privileges. --automation-clientid This is an optional parameter but will grant the Automation App (created in step 1) permission to the new workspace app. --application-admin-clientid This is a required parameter , and should be a client id that will be added to the Owners of the AAD Application so that it can be administered within TRE. --reset-password Optional, default is 0. When run in a headless fashion, 1 is passed in to always reset the password. Caution The script will create an app password (client secret) for the workspace and write to /config.yaml under the authentication section. These values are only shown once, if you lose them, the script will create new secrets if run again. If you do not wish to grant the Automation App permission to your workspace, just remove the --automation-clientid from the command.","title":"How to create"},{"location":"tre-admins/identities/workspace/#environment-variables","text":"Variable Description Location WORKSPACE_API_CLIENT_ID The Client Id ./config.yaml WORKSPACE_API_CLIENT_SECRET The client secret ./config.yaml","title":"Environment Variables"},{"location":"tre-admins/identities/workspace/#comments","text":"When the Workspace AAD app is registered by running make auth , the Workspace Scope Id is the same as the Client Id. When the Workspace AAD app is created by the base workspace, the Workspace Scope Id will be in this format api://<TRE_ID>_ws_<WORKSPACE_SHORT_IDENTIFIER>","title":"Comments"},{"location":"tre-admins/setup-instructions/","text":"Getting Started This section provide the guidelines for any engineer to deploy AzureTRE. This how-to will enable one to get familiar with a TRE deployment and its concepts. Tip For troubleshooting purpose make sure to check the Troubleshooting FAQ .","title":"Getting Started"},{"location":"tre-admins/setup-instructions/#getting-started","text":"This section provide the guidelines for any engineer to deploy AzureTRE. This how-to will enable one to get familiar with a TRE deployment and its concepts. Tip For troubleshooting purpose make sure to check the Troubleshooting FAQ .","title":"Getting Started"},{"location":"tre-admins/setup-instructions/ad-tenant-choices/","text":"Azure Active Directory Tenant Choices Dedicated Tenant for TRE We recommend that you have a dedicated Tenant for your TRE rather than using your corporate tenant. This is because TRE is able to automate some of the AD Tenant Admin tasks for you. In order to do this, there is an Admin User that has the ability to create AD Applications. This would not be normal for a Corporate Tenant. Users from your corporate tenant can be guested into this new TRE tenant. Corporate Tenant It is possible to use your corporate tenant for TRE. This does have the advantage of only managing a single tenant, but your AAD Tenant Admin must be aware of what TRE brings to your organization and must be prepared to carry out some admin tasks, like creating an AAD Application every time a new Workspace is created. Create Dedicated Azure Active Directory Tenant Follow this guide to create new dedicated tenant. Next steps Setup Auth configuration","title":"3. AD Tenant"},{"location":"tre-admins/setup-instructions/ad-tenant-choices/#azure-active-directory-tenant-choices","text":"","title":"Azure Active Directory Tenant Choices"},{"location":"tre-admins/setup-instructions/ad-tenant-choices/#dedicated-tenant-for-tre","text":"We recommend that you have a dedicated Tenant for your TRE rather than using your corporate tenant. This is because TRE is able to automate some of the AD Tenant Admin tasks for you. In order to do this, there is an Admin User that has the ability to create AD Applications. This would not be normal for a Corporate Tenant. Users from your corporate tenant can be guested into this new TRE tenant.","title":"Dedicated Tenant for TRE"},{"location":"tre-admins/setup-instructions/ad-tenant-choices/#corporate-tenant","text":"It is possible to use your corporate tenant for TRE. This does have the advantage of only managing a single tenant, but your AAD Tenant Admin must be aware of what TRE brings to your organization and must be prepared to carry out some admin tasks, like creating an AAD Application every time a new Workspace is created.","title":"Corporate Tenant"},{"location":"tre-admins/setup-instructions/ad-tenant-choices/#create-dedicated-azure-active-directory-tenant","text":"Follow this guide to create new dedicated tenant.","title":"Create Dedicated Azure Active Directory Tenant"},{"location":"tre-admins/setup-instructions/ad-tenant-choices/#next-steps","text":"Setup Auth configuration","title":"Next steps"},{"location":"tre-admins/setup-instructions/cicd-deplyment/","text":"Pipelines The AzureTRE deployment repository contains the following github workflows: Build Validation - validates the code by running linter and terraform validation. Clean Validation Environments - a periodical workflow to clean unused AzureTRE environments. Deploy Azure TRE (branch) - This workflow is intended to be used to test workflow changes. It deploys AzureTRE using the workflows defined on the branch Deploy Azure TRE - This workflow is the integration build run for pushes to the main branch. It also runs on a schedule, serving as the nightly build to keep the main AzureTRE env in sync. Deploy Azure TRE Reusable - responsible to deploy AzureTRE. It is referenced in other Azure TRE deployment workflows. Setup Github Environment The workflows are using Github environment to source its environment variables. Follow this guide to define it in your github repository and provide it as an input for the workflows. The following environment variables should be defined in your github environment: Auth env vars Core and Devops env vars Having all the environment variables set in the Github environment the next step will be to use it in your pipelines: In AzureTRE deployment repository You will find all the pipelines under the folder .github/workflows on top of each workflow there is the workflow inputs part where the used Github environment name is set, make sure to update it with yours, for example: Publish Custom Templates in Pipelines If you have created custom AzureTRE templates you can publish and register them as part of the CI/CD pipelines. To do so follow the next steps: 1. Go to .github/workflows/deploy_tre_reusable.yml workflow. Add your template under the following jobs: - publish_bundles: - register_bundles: - If it is a user resource add it also under register_user_resource_bundles: How to Contribute to our Documentation If you have any comments or suggestions about our documentation then you can visit our GitHub project and either raise a new issue, or comment on one of the existing ones. You can find our existing documentation issues on GitHub by clicking on the link below: Existing Documentation Issues Or, you can raise a new issue by clicking on this link: Report an Issue or Make a Suggestion Thank you for your patience and support!","title":"Deployment Steps"},{"location":"tre-admins/setup-instructions/cicd-deplyment/#pipelines","text":"The AzureTRE deployment repository contains the following github workflows: Build Validation - validates the code by running linter and terraform validation. Clean Validation Environments - a periodical workflow to clean unused AzureTRE environments. Deploy Azure TRE (branch) - This workflow is intended to be used to test workflow changes. It deploys AzureTRE using the workflows defined on the branch Deploy Azure TRE - This workflow is the integration build run for pushes to the main branch. It also runs on a schedule, serving as the nightly build to keep the main AzureTRE env in sync. Deploy Azure TRE Reusable - responsible to deploy AzureTRE. It is referenced in other Azure TRE deployment workflows.","title":"Pipelines"},{"location":"tre-admins/setup-instructions/cicd-deplyment/#setup-github-environment","text":"The workflows are using Github environment to source its environment variables. Follow this guide to define it in your github repository and provide it as an input for the workflows. The following environment variables should be defined in your github environment: Auth env vars Core and Devops env vars Having all the environment variables set in the Github environment the next step will be to use it in your pipelines: In AzureTRE deployment repository You will find all the pipelines under the folder .github/workflows on top of each workflow there is the workflow inputs part where the used Github environment name is set, make sure to update it with yours, for example:","title":"Setup Github Environment"},{"location":"tre-admins/setup-instructions/cicd-deplyment/#publish-custom-templates-in-pipelines","text":"If you have created custom AzureTRE templates you can publish and register them as part of the CI/CD pipelines. To do so follow the next steps: 1. Go to .github/workflows/deploy_tre_reusable.yml workflow. Add your template under the following jobs: - publish_bundles: - register_bundles: - If it is a user resource add it also under register_user_resource_bundles:","title":"Publish Custom Templates in Pipelines"},{"location":"tre-admins/setup-instructions/cicd-deplyment/#how-to-contribute-to-our-documentation","text":"If you have any comments or suggestions about our documentation then you can visit our GitHub project and either raise a new issue, or comment on one of the existing ones. You can find our existing documentation issues on GitHub by clicking on the link below: Existing Documentation Issues Or, you can raise a new issue by clicking on this link: Report an Issue or Make a Suggestion Thank you for your patience and support!","title":"How to Contribute to our Documentation"},{"location":"tre-admins/setup-instructions/cicd-pre-deployment-steps/","text":"Pre-deployment steps Setup Github Environment The workflows are using Github environment to source its environment variables. Follow this guide to define it in your github repository and provide it as an input for the workflows. GitHub Actions workflows (CI/CD) Deployment is done using the /.github/workflows/deploy_tre.yml workflow. This method is also used to deploy the dev/test environment for the original Azure TRE repository. Setup instructions Before you can run the deploy_tre.yml workflow there are some one-time configuration steps that we need to do, similar to the Pre-deployment steps for manual deployment. Create a service principal for the subscription so that the workflow can provision Azure resources. Decide on a TRE ID and the location for the Azure resources Create a Teams WebHook for deployment notifications Configure repository secrets Deploy the TRE using the workflow Create a service principal for provisioning resources Login to Azure Log in to Azure using az login and select the Azure subscription you wish to deploy Azure TRE to: az login az account list az account set --subscription <subscription ID> See Sign in with Azure CLI for more details. Create a service principal A service principal needs to be created to authorize CI/CD workflows to provision resources for the TRE workspaces and workspace services. Create a main service principal with \" Owner \" role: az ad sp create-for-rbac --name \"sp-aztre-cicd\" --role Owner --scopes /subscriptions/<subscription_id> --sdk-auth Caution Save the JSON output locally - as you will need it later for setting secrets in the build Create a secret in your github environment named AZURE_CREDENTIALS and use the JSON output from the previous step as its value. Note it should look similar to this: { \"clientId\" : \"\" , \"clientSecret\" : \"\" , \"subscriptionId\" : \"\" , \"tenantId\" : \"\" } Configure Core Secrets Configure the following secrets in your github environment - Secret name Description TRE_ID A globally unique identifier. TRE_ID can be found in the resource names of the Azure TRE instance; for example, a TRE_ID of tre-dev-42 will result in a resource group name for Azure TRE instance of rg-tre-dev-42 . This must be less than 12 characters. Allowed characters: Alphanumeric, underscores, and hyphens. LOCATION The Azure location (region) for all resources. E.g. westeurope MGMT_RESOURCE_GROUP_NAME The name of the shared resource group for all Azure TRE core resources. MGMT_STORAGE_ACCOUNT_NAME The name of the storage account to hold the Terraform state and other deployment artifacts. E.g. mystorageaccount . ACR_NAME A globally unique name for the Azure Container Registry (ACR) that will be created to store deployment images. CORE_ADDRESS_SPACE The address space for the Azure TRE core virtual network. E.g. 10.1.0.0/22 . Recommended /22 or larger. TRE_ADDRESS_SPACE The address space for the whole TRE environment virtual network where workspaces networks will be created (can include the core network as well). E.g. 10.0.0.0/12 TERRAFORM_STATE_CONTAINER_NAME Optional. The name of the blob container to hold the Terraform state. Default value is tfstate . CORE_APP_SERVICE_PLAN_SKU Optional. The SKU used for AppService plan for core infrastructure. Default value is P1v2 . WORKSPACE_APP_SERVICE_PLAN_SKU Optional. The SKU used for AppService plan used in E2E tests. Default value is P1v2 . RESOURCE_PROCESSOR_NUMBER_PROCESSES_PER_INSTANCE Optional. The number of processes to instantiate when the Resource Processor starts. Equates to the number of parallel deployment operations possible in your TRE. Defaults to 5 . Configure Authentication Secrets In a previous Setup Auth configuration step authentication configuration was added in config.yaml file. Go to this file and add those env vars to your github environment: Variable Description AAD_TENANT_ID Tenant id against which auth is performed. APPLICATION_ADMIN_CLIENT_ID This client will administer AAD Applications for TRE APPLICATION_ADMIN_CLIENT_SECRET This client will administer AAD Applications for TRE TEST_ACCOUNT_CLIENT_ID This will be created by default, but can be disabled by editing /devops/scripts/create_aad_assets.sh . This is the user that will run the tests for you TEST_ACCOUNT_CLIENT_SECRET This will be created by default, but can be disabled by editing /devops/scripts/create_aad_assets.sh . This is the user that will run the tests for you API_CLIENT_ID API application (client) ID. API_CLIENT_SECRET API application client secret. SWAGGER_UI_CLIENT_ID Swagger (OpenAPI) UI application (client) ID. TEST_WORKSPACE_APP_ID Each workspace is secured behind it's own AD Application. Use the value of WORKSPACE_API_CLIENT_ID created in the /config.yaml env file TEST_WORKSPACE_APP_SECRET Each workspace is secured behind it's own AD Application. This is the secret for that application. Use the value of WORKSPACE_API_CLIENT_SECRET created in the /config.yaml env file Create a Teams Webhook for deployment notifications The deploy_tre.yml workflow sends a notification to a Microsoft Teams channel when it finishes running. Note If you don't want to notify a channel, you can also remove the Notify dedicated teams channel steps in the workflow Follow the Microsoft Docs to create a webhook for your channel Configure the MS_TEAMS_WEBHOOK_URI repository secret Secret name Description MS_TEAMS_WEBHOOK_URI URI for the Teams channel webhook Info See Environment variables for full details of the deployment related variables. Setup Github env in workflow In your repository you will find that the pipelines under the folder .github/workflows on top of each workflow there is the workflow inputs part where the used Github environment name is set, make sure to update it with yours, for example: Deploy the TRE using the workflow With all the repository secrets set, you can trigger a workflow run by pushing to develop/main of your repo, or by dispatching the workflow manually. Next steps Deploying Azure TRE in Pipelines","title":"Pre-deployment Steps"},{"location":"tre-admins/setup-instructions/cicd-pre-deployment-steps/#pre-deployment-steps","text":"","title":"Pre-deployment steps"},{"location":"tre-admins/setup-instructions/cicd-pre-deployment-steps/#setup-github-environment","text":"The workflows are using Github environment to source its environment variables. Follow this guide to define it in your github repository and provide it as an input for the workflows.","title":"Setup Github Environment"},{"location":"tre-admins/setup-instructions/cicd-pre-deployment-steps/#github-actions-workflows-cicd","text":"Deployment is done using the /.github/workflows/deploy_tre.yml workflow. This method is also used to deploy the dev/test environment for the original Azure TRE repository.","title":"GitHub Actions workflows (CI/CD)"},{"location":"tre-admins/setup-instructions/cicd-pre-deployment-steps/#setup-instructions","text":"Before you can run the deploy_tre.yml workflow there are some one-time configuration steps that we need to do, similar to the Pre-deployment steps for manual deployment. Create a service principal for the subscription so that the workflow can provision Azure resources. Decide on a TRE ID and the location for the Azure resources Create a Teams WebHook for deployment notifications Configure repository secrets Deploy the TRE using the workflow","title":"Setup instructions"},{"location":"tre-admins/setup-instructions/cicd-pre-deployment-steps/#create-a-service-principal-for-provisioning-resources","text":"Login to Azure Log in to Azure using az login and select the Azure subscription you wish to deploy Azure TRE to: az login az account list az account set --subscription <subscription ID> See Sign in with Azure CLI for more details. Create a service principal A service principal needs to be created to authorize CI/CD workflows to provision resources for the TRE workspaces and workspace services. Create a main service principal with \" Owner \" role: az ad sp create-for-rbac --name \"sp-aztre-cicd\" --role Owner --scopes /subscriptions/<subscription_id> --sdk-auth Caution Save the JSON output locally - as you will need it later for setting secrets in the build Create a secret in your github environment named AZURE_CREDENTIALS and use the JSON output from the previous step as its value. Note it should look similar to this: { \"clientId\" : \"\" , \"clientSecret\" : \"\" , \"subscriptionId\" : \"\" , \"tenantId\" : \"\" }","title":"Create a service principal for provisioning resources"},{"location":"tre-admins/setup-instructions/cicd-pre-deployment-steps/#configure-core-secrets","text":"Configure the following secrets in your github environment - Secret name Description TRE_ID A globally unique identifier. TRE_ID can be found in the resource names of the Azure TRE instance; for example, a TRE_ID of tre-dev-42 will result in a resource group name for Azure TRE instance of rg-tre-dev-42 . This must be less than 12 characters. Allowed characters: Alphanumeric, underscores, and hyphens. LOCATION The Azure location (region) for all resources. E.g. westeurope MGMT_RESOURCE_GROUP_NAME The name of the shared resource group for all Azure TRE core resources. MGMT_STORAGE_ACCOUNT_NAME The name of the storage account to hold the Terraform state and other deployment artifacts. E.g. mystorageaccount . ACR_NAME A globally unique name for the Azure Container Registry (ACR) that will be created to store deployment images. CORE_ADDRESS_SPACE The address space for the Azure TRE core virtual network. E.g. 10.1.0.0/22 . Recommended /22 or larger. TRE_ADDRESS_SPACE The address space for the whole TRE environment virtual network where workspaces networks will be created (can include the core network as well). E.g. 10.0.0.0/12 TERRAFORM_STATE_CONTAINER_NAME Optional. The name of the blob container to hold the Terraform state. Default value is tfstate . CORE_APP_SERVICE_PLAN_SKU Optional. The SKU used for AppService plan for core infrastructure. Default value is P1v2 . WORKSPACE_APP_SERVICE_PLAN_SKU Optional. The SKU used for AppService plan used in E2E tests. Default value is P1v2 . RESOURCE_PROCESSOR_NUMBER_PROCESSES_PER_INSTANCE Optional. The number of processes to instantiate when the Resource Processor starts. Equates to the number of parallel deployment operations possible in your TRE. Defaults to 5 .","title":"Configure Core Secrets"},{"location":"tre-admins/setup-instructions/cicd-pre-deployment-steps/#configure-authentication-secrets","text":"In a previous Setup Auth configuration step authentication configuration was added in config.yaml file. Go to this file and add those env vars to your github environment: Variable Description AAD_TENANT_ID Tenant id against which auth is performed. APPLICATION_ADMIN_CLIENT_ID This client will administer AAD Applications for TRE APPLICATION_ADMIN_CLIENT_SECRET This client will administer AAD Applications for TRE TEST_ACCOUNT_CLIENT_ID This will be created by default, but can be disabled by editing /devops/scripts/create_aad_assets.sh . This is the user that will run the tests for you TEST_ACCOUNT_CLIENT_SECRET This will be created by default, but can be disabled by editing /devops/scripts/create_aad_assets.sh . This is the user that will run the tests for you API_CLIENT_ID API application (client) ID. API_CLIENT_SECRET API application client secret. SWAGGER_UI_CLIENT_ID Swagger (OpenAPI) UI application (client) ID. TEST_WORKSPACE_APP_ID Each workspace is secured behind it's own AD Application. Use the value of WORKSPACE_API_CLIENT_ID created in the /config.yaml env file TEST_WORKSPACE_APP_SECRET Each workspace is secured behind it's own AD Application. This is the secret for that application. Use the value of WORKSPACE_API_CLIENT_SECRET created in the /config.yaml env file","title":"Configure Authentication Secrets"},{"location":"tre-admins/setup-instructions/cicd-pre-deployment-steps/#create-a-teams-webhook-for-deployment-notifications","text":"The deploy_tre.yml workflow sends a notification to a Microsoft Teams channel when it finishes running. Note If you don't want to notify a channel, you can also remove the Notify dedicated teams channel steps in the workflow Follow the Microsoft Docs to create a webhook for your channel Configure the MS_TEAMS_WEBHOOK_URI repository secret Secret name Description MS_TEAMS_WEBHOOK_URI URI for the Teams channel webhook Info See Environment variables for full details of the deployment related variables.","title":"Create a Teams Webhook for deployment notifications"},{"location":"tre-admins/setup-instructions/cicd-pre-deployment-steps/#setup-github-env-in-workflow","text":"In your repository you will find that the pipelines under the folder .github/workflows on top of each workflow there is the workflow inputs part where the used Github environment name is set, make sure to update it with yours, for example:","title":"Setup Github env in workflow"},{"location":"tre-admins/setup-instructions/cicd-pre-deployment-steps/#deploy-the-tre-using-the-workflow","text":"With all the repository secrets set, you can trigger a workflow run by pushing to develop/main of your repo, or by dispatching the workflow manually.","title":"Deploy the TRE using the workflow"},{"location":"tre-admins/setup-instructions/cicd-pre-deployment-steps/#next-steps","text":"Deploying Azure TRE in Pipelines","title":"Next steps"},{"location":"tre-admins/setup-instructions/configuring-shared-services/","text":"Configuring Shared Services In general, a shared service should be installed by using the UI or API directly once its bundle has been registered on the system. Deploy & configure V2 Nexus service (hosted on VM) Caution Before deploying the V2 Nexus service, you will need workspaces of version 0.3.2 or above due to a dependency on a DNS zone link for the workspace(s) to connect to the Nexus VM. Before deploying the Nexus shared service, you need to make sure that it will have access to a certificate to configure serving secure proxies. By default, the Nexus service will serve proxies from https://nexus-{TRE_ID}.{LOCATION}.cloudapp.azure.com/ , and thus it requires a certificate that validates ownership of this domain to use for SSL. You can use the Certs Shared Service to set one up by following these steps: Run the below command in your terminal to build, publish and register the certs bundle: make shared_service_bundle BUNDLE=certs Navigate to the TRE UI, click on Shared Services in the navigation menu and click Create new . Select the Certs template, then fill in the required details. Domain prefix should be set to nexus and Cert name should be nexus-ssl . Caution If you have KeyVault Purge Protection enabled and are re-deploying your environment using the same cert_name , you may encounter this: Status=409 Code=\\\"Conflict\\\" Message=\\\"Certificate nexus-ssl is currently in a deleted but recoverable state . You need to either manually recover the certificate or purge it before redeploying. Once deployed, the certs service will use Letsencrypt to generate a certificate for the specified domain prefix followed by -{TRE_ID}.{LOCATION}.cloudapp.azure.com , so in our case, having entered nexus , this will be nexus-{TRE_ID}.{LOCATION}.cloudapp.azure.com , which will be the public domain for our Nexus service. You can verify whether this has been successful by navigating to your core keyvault ( kv-{TRE_ID} ) and looking for a certificate called nexus-ssl (or whatever you called it). After verifying the certificate has been generated, you can deploy Nexus: Run the below command in your terminal to build, publish and register the Nexus shared service bundle: make shared_service_bundle BUNDLE=sonatype-nexus-vm Navigate back to the TRE UI, and click Create new again within the Shared Services page. Select the Nexus template then fill in the required details. The SSL certificate name should default to nexus-ssl , so there's no need to change it unless you gave it a different name in the previous step. This will deploy the infrastructure required for Nexus, then start the service and configure it with the repository configurations located in the ./templates/shared_services/sonatype-nexus-vm/scripts/nexus_repos_config folder. It will also set up HTTPS using the certificate you generated in the previous section, so proxies can be served at https://nexus-{TRE_ID}.{LOCATION}.cloudapp.azure.com . You can optionally go to the Nexus web interface by visiting https://nexus-{TRE_ID}.{LOCATION}.cloudapp.azure.com/ in the jumpbox and signing in with the username admin and the password secret located in your core keyvault, with the key nexus-admin-password . Here you should be able to see all of the configured repositories and you can use the UI to manage settings etc. Just bear in mind that if this service is redeployed any changes made in the Nexus UI won't be persisted. If you wish to permanently add new repositories or alter existing ones, modify the JSON files within the ./nexus_repos_config directory and redeploy. Migrate from an existing V1 Nexus service (hosted on App Service) Once you've created the new V2 (VM-based) Nexus service by following the previous section, you can migrate from the V1 Nexus service by following these steps: Identify any existing Guacamole user resources that are using the old proxy URL ( https://nexus-{TRE_ID}.azurewebsites.net/ ). These will be any VMs with bundle versions < 0.3.2 . These will need to be either re-deployed with the new template versions 0.3.2 or later and specifying an additional template parameter \"nexus_version\" with the value of \"V2\" , or manually have their proxy URLs updated by remoting into the VMs and updating the various configuration files of required package managers with the new URL ( https://nexus-{TRE_ID}.{LOCATION}.cloudapp.azure.com/ ). For example, pip will need the index , index-url and trusted-host values in the global pip.conf file to be modified to use the new URL. Once you've confirmed there are no dependencies on the old Nexus shared service, you can delete it using the API. Upgrade notes The new V2 Nexus shared service can be located in the ./templates/shared_services/sonatype-nexus-vm directory, with the bundle name tre-shared-service-sonatype-nexus , which is now hosted using a VM to enable additional configuration required for proxying certain repositories. This has been created as a separate service as the domain name exposed for proxies will be different to the one used by the original Nexus service and thus will break any user resources configured with the old proxy URL. The original Nexus service that runs on App Service (located in ./templates/shared_services/sonatype-nexus ) has the bundle name tre-shared-service-nexus so can co-exist with the new VM-based shared service to enable smoother upgrading of existing resources. Renewing certificates for Nexus The Nexus V2 service checks Keyvault regularly for the latest certificate matching the name you passed on deploy ( nexus-ssl by default). When approaching expiry, you can either provide an updated certificate if you brought your own, or if you used the certs shared service to generate one, just call the renew custom action on that service. This will generate a new certificate and persist it to the Keyvault. Configure Gitea repositories Note : This is a Gitea shared service which will be accessible from all workspaces intended for mirroring external Git repositories. A Gitea workspace service can also be deployed per workspace to enable Gitea to be used within a specific workspace. By default, this Gitea instance does not have any repositories configured. You can add repositories to Gitea either by using the command line or by using the Gitea web interface. Command Line Make sure you run the following commands using git bash and set your current directory as C:/AzureTRE. On the jumbox, run: ./templates/workspace_services/gitea/gitea_migrate_repo.sh -t <tre_id> -g <URL_of_github_repo_to_migrate> If you have issues with token or token doesn't work, you can reset the token by setting it's value to null in Key Vault: az keyvault secret set --name gitea-<tre-id>-admin-token --vault-name kv-<tre-id> --value null Gitea Web Interface on the jumbox, open Edge and go to: https://gitea-<TRE_ID>.azurewebsites.net/ Authenticate yourself using username giteaadmin and the secret <gitea-TRE_ID-administrator-password> stored in the keyvault, Add the repository of your choice Verify can access the mirrored repository From a virtual machine within a workspace: - Command line: git clone https://gitea-<TRE_ID>.azurewebsites.net/giteaadmin/<NameOfrepository> - Gitea Web Interface: https://gitea-<TRE_ID>.azurewebsites.net/ Next steps Install Base Workspace","title":"6. Configure Shared Services"},{"location":"tre-admins/setup-instructions/configuring-shared-services/#configuring-shared-services","text":"In general, a shared service should be installed by using the UI or API directly once its bundle has been registered on the system.","title":"Configuring Shared Services"},{"location":"tre-admins/setup-instructions/configuring-shared-services/#deploy-configure-v2-nexus-service-hosted-on-vm","text":"Caution Before deploying the V2 Nexus service, you will need workspaces of version 0.3.2 or above due to a dependency on a DNS zone link for the workspace(s) to connect to the Nexus VM. Before deploying the Nexus shared service, you need to make sure that it will have access to a certificate to configure serving secure proxies. By default, the Nexus service will serve proxies from https://nexus-{TRE_ID}.{LOCATION}.cloudapp.azure.com/ , and thus it requires a certificate that validates ownership of this domain to use for SSL. You can use the Certs Shared Service to set one up by following these steps: Run the below command in your terminal to build, publish and register the certs bundle: make shared_service_bundle BUNDLE=certs Navigate to the TRE UI, click on Shared Services in the navigation menu and click Create new . Select the Certs template, then fill in the required details. Domain prefix should be set to nexus and Cert name should be nexus-ssl . Caution If you have KeyVault Purge Protection enabled and are re-deploying your environment using the same cert_name , you may encounter this: Status=409 Code=\\\"Conflict\\\" Message=\\\"Certificate nexus-ssl is currently in a deleted but recoverable state . You need to either manually recover the certificate or purge it before redeploying. Once deployed, the certs service will use Letsencrypt to generate a certificate for the specified domain prefix followed by -{TRE_ID}.{LOCATION}.cloudapp.azure.com , so in our case, having entered nexus , this will be nexus-{TRE_ID}.{LOCATION}.cloudapp.azure.com , which will be the public domain for our Nexus service. You can verify whether this has been successful by navigating to your core keyvault ( kv-{TRE_ID} ) and looking for a certificate called nexus-ssl (or whatever you called it). After verifying the certificate has been generated, you can deploy Nexus: Run the below command in your terminal to build, publish and register the Nexus shared service bundle: make shared_service_bundle BUNDLE=sonatype-nexus-vm Navigate back to the TRE UI, and click Create new again within the Shared Services page. Select the Nexus template then fill in the required details. The SSL certificate name should default to nexus-ssl , so there's no need to change it unless you gave it a different name in the previous step. This will deploy the infrastructure required for Nexus, then start the service and configure it with the repository configurations located in the ./templates/shared_services/sonatype-nexus-vm/scripts/nexus_repos_config folder. It will also set up HTTPS using the certificate you generated in the previous section, so proxies can be served at https://nexus-{TRE_ID}.{LOCATION}.cloudapp.azure.com . You can optionally go to the Nexus web interface by visiting https://nexus-{TRE_ID}.{LOCATION}.cloudapp.azure.com/ in the jumpbox and signing in with the username admin and the password secret located in your core keyvault, with the key nexus-admin-password . Here you should be able to see all of the configured repositories and you can use the UI to manage settings etc. Just bear in mind that if this service is redeployed any changes made in the Nexus UI won't be persisted. If you wish to permanently add new repositories or alter existing ones, modify the JSON files within the ./nexus_repos_config directory and redeploy.","title":"Deploy &amp; configure V2 Nexus service (hosted on VM)"},{"location":"tre-admins/setup-instructions/configuring-shared-services/#migrate-from-an-existing-v1-nexus-service-hosted-on-app-service","text":"Once you've created the new V2 (VM-based) Nexus service by following the previous section, you can migrate from the V1 Nexus service by following these steps: Identify any existing Guacamole user resources that are using the old proxy URL ( https://nexus-{TRE_ID}.azurewebsites.net/ ). These will be any VMs with bundle versions < 0.3.2 . These will need to be either re-deployed with the new template versions 0.3.2 or later and specifying an additional template parameter \"nexus_version\" with the value of \"V2\" , or manually have their proxy URLs updated by remoting into the VMs and updating the various configuration files of required package managers with the new URL ( https://nexus-{TRE_ID}.{LOCATION}.cloudapp.azure.com/ ). For example, pip will need the index , index-url and trusted-host values in the global pip.conf file to be modified to use the new URL. Once you've confirmed there are no dependencies on the old Nexus shared service, you can delete it using the API.","title":"Migrate from an existing V1 Nexus service (hosted on App Service)"},{"location":"tre-admins/setup-instructions/configuring-shared-services/#upgrade-notes","text":"The new V2 Nexus shared service can be located in the ./templates/shared_services/sonatype-nexus-vm directory, with the bundle name tre-shared-service-sonatype-nexus , which is now hosted using a VM to enable additional configuration required for proxying certain repositories. This has been created as a separate service as the domain name exposed for proxies will be different to the one used by the original Nexus service and thus will break any user resources configured with the old proxy URL. The original Nexus service that runs on App Service (located in ./templates/shared_services/sonatype-nexus ) has the bundle name tre-shared-service-nexus so can co-exist with the new VM-based shared service to enable smoother upgrading of existing resources.","title":"Upgrade notes"},{"location":"tre-admins/setup-instructions/configuring-shared-services/#renewing-certificates-for-nexus","text":"The Nexus V2 service checks Keyvault regularly for the latest certificate matching the name you passed on deploy ( nexus-ssl by default). When approaching expiry, you can either provide an updated certificate if you brought your own, or if you used the certs shared service to generate one, just call the renew custom action on that service. This will generate a new certificate and persist it to the Keyvault.","title":"Renewing certificates for Nexus"},{"location":"tre-admins/setup-instructions/configuring-shared-services/#configure-gitea-repositories","text":"Note : This is a Gitea shared service which will be accessible from all workspaces intended for mirroring external Git repositories. A Gitea workspace service can also be deployed per workspace to enable Gitea to be used within a specific workspace. By default, this Gitea instance does not have any repositories configured. You can add repositories to Gitea either by using the command line or by using the Gitea web interface.","title":"Configure Gitea repositories"},{"location":"tre-admins/setup-instructions/configuring-shared-services/#command-line","text":"Make sure you run the following commands using git bash and set your current directory as C:/AzureTRE. On the jumbox, run: ./templates/workspace_services/gitea/gitea_migrate_repo.sh -t <tre_id> -g <URL_of_github_repo_to_migrate> If you have issues with token or token doesn't work, you can reset the token by setting it's value to null in Key Vault: az keyvault secret set --name gitea-<tre-id>-admin-token --vault-name kv-<tre-id> --value null","title":"Command Line"},{"location":"tre-admins/setup-instructions/configuring-shared-services/#gitea-web-interface","text":"on the jumbox, open Edge and go to: https://gitea-<TRE_ID>.azurewebsites.net/ Authenticate yourself using username giteaadmin and the secret <gitea-TRE_ID-administrator-password> stored in the keyvault, Add the repository of your choice","title":"Gitea Web Interface"},{"location":"tre-admins/setup-instructions/configuring-shared-services/#verify-can-access-the-mirrored-repository","text":"From a virtual machine within a workspace: - Command line: git clone https://gitea-<TRE_ID>.azurewebsites.net/giteaadmin/<NameOfrepository> - Gitea Web Interface: https://gitea-<TRE_ID>.azurewebsites.net/","title":"Verify can access the mirrored repository"},{"location":"tre-admins/setup-instructions/configuring-shared-services/#next-steps","text":"Install Base Workspace","title":"Next steps"},{"location":"tre-admins/setup-instructions/deployment-repo/","text":"AzureTRE Deployment repo AzureTRE has an OSS deployment repository which you can find here. It contains all the required tooling to develop your custom templates and deploy the Azure TRE: Github Actions implementing AzureTRE automation, including running deployments to Azure Configuration specific to deployment Directories setup for: workspace, workspace service and user resource template definitions Devcontainer setup Getting Started To get started with AzureTRE follow the next steps: Go to AzureTRE Deployment repository Click on use this template to set up your project from this template: Follow the steps in this Github templates guide to set up the repo. Note The following steps in this guide should be done using the deployment repo. Next steps AD Tenant Choices","title":"2. Deployment Repository"},{"location":"tre-admins/setup-instructions/deployment-repo/#azuretre-deployment-repo","text":"AzureTRE has an OSS deployment repository which you can find here. It contains all the required tooling to develop your custom templates and deploy the Azure TRE: Github Actions implementing AzureTRE automation, including running deployments to Azure Configuration specific to deployment Directories setup for: workspace, workspace service and user resource template definitions Devcontainer setup","title":"AzureTRE Deployment repo"},{"location":"tre-admins/setup-instructions/deployment-repo/#getting-started","text":"To get started with AzureTRE follow the next steps: Go to AzureTRE Deployment repository Click on use this template to set up your project from this template: Follow the steps in this Github templates guide to set up the repo. Note The following steps in this guide should be done using the deployment repo.","title":"Getting Started"},{"location":"tre-admins/setup-instructions/deployment-repo/#next-steps","text":"AD Tenant Choices","title":"Next steps"},{"location":"tre-admins/setup-instructions/installing-base-workspace/","text":"Installing base workspace Publishing and registering the base workspace bundle Run the following in a terminal to build, publish and register the base workpace bundle: make workspace_bundle BUNDLE=base This will prepare the template for use with your TRE. Creating a base workspace Now that we have published and registered a base workspace bundle we can use the deployed API to create a base workspace. Info All routes are auth protected. Click the green Authorize button to receive a token for Swagger client. As explained in the auth guide , every workspace has a corresponding app registration which if you haven't run make auth ; can be created using the helper script ./devops/scripts/aad/create_workspace_application.sh . For example: ./devops/scripts/aad/create_workspace_application.sh \\ --name \" ${ TRE_ID } - workspace 1\" \\ --admin-consent \\ --ux-clientid \" ${ SWAGGER_UI_CLIENT_ID } \" \\ --automation-clientid \" ${ TEST_ACCOUNT_CLIENT_ID } \" \\ --application-admin-clientid \" ${ APPLICATION_ADMIN_CLIENT_ID } \" Caution If you're using a separate tenant for AAD app registrations to the one where you've deployed the TRE infrastructure resources, ensure you've signed into that tenant in the az cli before running the above command. See Using a separate Azure Active Directory tenant in Setup Auth configuration for more details. Running the script will report workspace_api_client_id and workspace_api_client_secret for the generated app. Add these under the authenrication section in /config.yaml so that automated testing will work. You also need to use workspace_api_client_id in the POST body below. Create workspace using the API Go to https://<azure_tre_fqdn>/api/docs and use POST /api/workspaces with the sample body to create a base workspace. { \"templateName\" : \"tre-workspace-base\" , \"properties\" : { \"display_name\" : \"manual-from-swagger\" , \"description\" : \"workspace for team X\" , \"client_id\" : \"<WORKSPACE_API_CLIENT_ID>\" , \"client_secret\" : \"<WORKSPACE_API_CLIENT_SECRET>\" , \"address_space_size\" : \"medium\" } } The API will return an operation object with a Location header to query the operation status, as well as the resourceId and resourcePath properties to query the resource under creation. You can also follow the progress in Azure portal as various resources come up. Workspace level operations can now be carried out using the workspace API, at /api/workspaces/<workspace_id>/docs/ . Next steps Installing a workspace service & user resources","title":"Install Base Workspace"},{"location":"tre-admins/setup-instructions/installing-base-workspace/#installing-base-workspace","text":"","title":"Installing base workspace"},{"location":"tre-admins/setup-instructions/installing-base-workspace/#publishing-and-registering-the-base-workspace-bundle","text":"Run the following in a terminal to build, publish and register the base workpace bundle: make workspace_bundle BUNDLE=base This will prepare the template for use with your TRE.","title":"Publishing and registering the base workspace bundle"},{"location":"tre-admins/setup-instructions/installing-base-workspace/#creating-a-base-workspace","text":"Now that we have published and registered a base workspace bundle we can use the deployed API to create a base workspace. Info All routes are auth protected. Click the green Authorize button to receive a token for Swagger client. As explained in the auth guide , every workspace has a corresponding app registration which if you haven't run make auth ; can be created using the helper script ./devops/scripts/aad/create_workspace_application.sh . For example: ./devops/scripts/aad/create_workspace_application.sh \\ --name \" ${ TRE_ID } - workspace 1\" \\ --admin-consent \\ --ux-clientid \" ${ SWAGGER_UI_CLIENT_ID } \" \\ --automation-clientid \" ${ TEST_ACCOUNT_CLIENT_ID } \" \\ --application-admin-clientid \" ${ APPLICATION_ADMIN_CLIENT_ID } \" Caution If you're using a separate tenant for AAD app registrations to the one where you've deployed the TRE infrastructure resources, ensure you've signed into that tenant in the az cli before running the above command. See Using a separate Azure Active Directory tenant in Setup Auth configuration for more details. Running the script will report workspace_api_client_id and workspace_api_client_secret for the generated app. Add these under the authenrication section in /config.yaml so that automated testing will work. You also need to use workspace_api_client_id in the POST body below.","title":"Creating a base workspace"},{"location":"tre-admins/setup-instructions/installing-base-workspace/#create-workspace-using-the-api","text":"Go to https://<azure_tre_fqdn>/api/docs and use POST /api/workspaces with the sample body to create a base workspace. { \"templateName\" : \"tre-workspace-base\" , \"properties\" : { \"display_name\" : \"manual-from-swagger\" , \"description\" : \"workspace for team X\" , \"client_id\" : \"<WORKSPACE_API_CLIENT_ID>\" , \"client_secret\" : \"<WORKSPACE_API_CLIENT_SECRET>\" , \"address_space_size\" : \"medium\" } } The API will return an operation object with a Location header to query the operation status, as well as the resourceId and resourcePath properties to query the resource under creation. You can also follow the progress in Azure portal as various resources come up. Workspace level operations can now be carried out using the workspace API, at /api/workspaces/<workspace_id>/docs/ .","title":"Create workspace using the API"},{"location":"tre-admins/setup-instructions/installing-base-workspace/#next-steps","text":"Installing a workspace service & user resources","title":"Next steps"},{"location":"tre-admins/setup-instructions/installing-workspace-service-and-user-resource/","text":"Installing workspace service and user resource Publish and register a workspace service template We will use the Guacamole workspace service bundle for the purposes of this tutorial; a template that provides Virtual Desktop functionality allowing the deployment of VMs for users. These steps can be repeated for any workspace service template depending on the functionalities required. Run: make workspace_service_bundle BUNDLE=guacamole Publish and register a user resource template The Guacamole workspace service also has user resources: the VMs that researchers will deploy. These steps can be repeated for any user resource template. Run: make user_resource_bundle BUNDLE=guacamole-azure-windowsvm WORKSPACE_SERVICE=guacamole Creating a workspace service Now that we have published and registered both workspace service and user resource bundles we can use the workspace API to create a workspace service in our workspace. Navigate to the Swagger UI at https://<azure_tre_fqdn>/api/workspaces/<workspace_id>/docs . Where <workspace_id> is the workspace ID of the workspace created in the previous step. Info All routes are auth protected. Click the green Authorize button to receive a token for Swagger client. Log into the Swagger UI by clicking Authorize , then Authorize again. You will be redirected to the login page. Info You need to log in with a user with assigned the WorkspaceOwner role in the app regsitration used when deploying your workspace. Once logged in, click Try it out on the POST /api/workspaces/<workspace_id>/workspace-services operation. Enter the workspace_id in the workspace_id field. Paste the following payload json into the Request body field. Then click Execute . Review the server response. { \"templateName\" : \"tre-service-guacamole\" , \"properties\" : { \"display_name\" : \"Virtual Desktop\" , \"description\" : \"Create virtual desktops for running research workloads\" , \"is_exposed_externally\" : true , \"guac_disable_copy\" : true , \"guac_disable_paste\" : true } } The API will return an operation object with a Location header to query the operation status, as well as the resourceId and resourcePath properties to query the resource under creation. Record this ID for later use. You can also follow the progress in Azure portal as various resources come up. Info There is currently a bug where the redirect URI isn't automatically set up correctly in the Workspace API app registration. Until this is fixed, you need to head to the app registration in the Azure portal, click on Add a redirect URI > Add a platform > Web > then paste in the Guacamole URI in the redirect URI box. You can find this in the Guacamole app service properties and append /oauth2/callback to the end - it should look like this: https://guacamole-{TRE_ID}-ws-XXXX-svc-XXXX.azurewebsites.net/oauth2/callback/ ). Finally, make sure you check the ID tokens checkbox and click Configure . Creating a user resource Once the workspace service has been created, we can use the workspace API to create a user resource in our workspace. Caution Before deploying Guacamole user resources, you will want to make sure you have a Nexus shared service deployed in the workspace so that your VMs can access package repositories through a proxy (as they can't access public repositories directly). See Configuring shared services . Navigate to the Swagger UI at https://<azure_tre_fqdn>/api/workspaces/<workspace_id>/docs . Where <workspace_id> is the workspace ID of your workspace. Click Try it out on the POST /api/workspaces/<workspace_id>/workspace-services/<service_id>/user_resources operation. Where <workspace_id> and <service_id> are the workspace ID of your workspace and workspace service ID of your workspace service. Enter the workspace ID and workspace service id in the workspace_id and service_id fields. Paste the following payload json into the Request body field, then click Execute . Review the server response. { \"templateName\" : \"tre-service-guacamole-windowsvm\" , \"properties\" : { \"display_name\" : \"My VM\" , \"description\" : \"Will be using this VM for my research\" , \"os_image\" : \"Server 2019 Data Science VM\" , \"nexus_version\" : \"V2\" } } Note: You can also specify \"Windows 10\" in \"os_image\" for a standard Windows 10 image. The API will return an operation object with a Location header to query the operation status, as well as the resourceId and resourcePath properties to query the resource under creation. You can also follow the progress in Azure portal as various resources come up. Once deployment has completed you can connect to the user resource using the connection_uri property returned by the API.","title":"Install Workspace Service and User Resource"},{"location":"tre-admins/setup-instructions/installing-workspace-service-and-user-resource/#installing-workspace-service-and-user-resource","text":"","title":"Installing workspace service and user resource"},{"location":"tre-admins/setup-instructions/installing-workspace-service-and-user-resource/#publish-and-register-a-workspace-service-template","text":"We will use the Guacamole workspace service bundle for the purposes of this tutorial; a template that provides Virtual Desktop functionality allowing the deployment of VMs for users. These steps can be repeated for any workspace service template depending on the functionalities required. Run: make workspace_service_bundle BUNDLE=guacamole","title":"Publish and register a workspace service template"},{"location":"tre-admins/setup-instructions/installing-workspace-service-and-user-resource/#publish-and-register-a-user-resource-template","text":"The Guacamole workspace service also has user resources: the VMs that researchers will deploy. These steps can be repeated for any user resource template. Run: make user_resource_bundle BUNDLE=guacamole-azure-windowsvm WORKSPACE_SERVICE=guacamole","title":"Publish and register a user resource template"},{"location":"tre-admins/setup-instructions/installing-workspace-service-and-user-resource/#creating-a-workspace-service","text":"Now that we have published and registered both workspace service and user resource bundles we can use the workspace API to create a workspace service in our workspace. Navigate to the Swagger UI at https://<azure_tre_fqdn>/api/workspaces/<workspace_id>/docs . Where <workspace_id> is the workspace ID of the workspace created in the previous step. Info All routes are auth protected. Click the green Authorize button to receive a token for Swagger client. Log into the Swagger UI by clicking Authorize , then Authorize again. You will be redirected to the login page. Info You need to log in with a user with assigned the WorkspaceOwner role in the app regsitration used when deploying your workspace. Once logged in, click Try it out on the POST /api/workspaces/<workspace_id>/workspace-services operation. Enter the workspace_id in the workspace_id field. Paste the following payload json into the Request body field. Then click Execute . Review the server response. { \"templateName\" : \"tre-service-guacamole\" , \"properties\" : { \"display_name\" : \"Virtual Desktop\" , \"description\" : \"Create virtual desktops for running research workloads\" , \"is_exposed_externally\" : true , \"guac_disable_copy\" : true , \"guac_disable_paste\" : true } } The API will return an operation object with a Location header to query the operation status, as well as the resourceId and resourcePath properties to query the resource under creation. Record this ID for later use. You can also follow the progress in Azure portal as various resources come up. Info There is currently a bug where the redirect URI isn't automatically set up correctly in the Workspace API app registration. Until this is fixed, you need to head to the app registration in the Azure portal, click on Add a redirect URI > Add a platform > Web > then paste in the Guacamole URI in the redirect URI box. You can find this in the Guacamole app service properties and append /oauth2/callback to the end - it should look like this: https://guacamole-{TRE_ID}-ws-XXXX-svc-XXXX.azurewebsites.net/oauth2/callback/ ). Finally, make sure you check the ID tokens checkbox and click Configure .","title":"Creating a workspace service"},{"location":"tre-admins/setup-instructions/installing-workspace-service-and-user-resource/#creating-a-user-resource","text":"Once the workspace service has been created, we can use the workspace API to create a user resource in our workspace. Caution Before deploying Guacamole user resources, you will want to make sure you have a Nexus shared service deployed in the workspace so that your VMs can access package repositories through a proxy (as they can't access public repositories directly). See Configuring shared services . Navigate to the Swagger UI at https://<azure_tre_fqdn>/api/workspaces/<workspace_id>/docs . Where <workspace_id> is the workspace ID of your workspace. Click Try it out on the POST /api/workspaces/<workspace_id>/workspace-services/<service_id>/user_resources operation. Where <workspace_id> and <service_id> are the workspace ID of your workspace and workspace service ID of your workspace service. Enter the workspace ID and workspace service id in the workspace_id and service_id fields. Paste the following payload json into the Request body field, then click Execute . Review the server response. { \"templateName\" : \"tre-service-guacamole-windowsvm\" , \"properties\" : { \"display_name\" : \"My VM\" , \"description\" : \"Will be using this VM for my research\" , \"os_image\" : \"Server 2019 Data Science VM\" , \"nexus_version\" : \"V2\" } } Note: You can also specify \"Windows 10\" in \"os_image\" for a standard Windows 10 image. The API will return an operation object with a Location header to query the operation status, as well as the resourceId and resourcePath properties to query the resource under creation. You can also follow the progress in Azure portal as various resources come up. Once deployment has completed you can connect to the user resource using the connection_uri property returned by the API.","title":"Creating a user resource"},{"location":"tre-admins/setup-instructions/manual-deployment/","text":"Deploying Azure TRE You are now ready to deploy the Azure TRE instance. Execute the all action of the makefile using make : make all Deploying a new Azure TRE instance takes approximately 30 minutes. Once the deployment is completed, you will be presented with a few output variables similar to the ones below: app_gateway_name = \"agw-mytre\" azure_tre_fqdn = \"mytre.westeurope.cloudapp.azure.com\" core_resource_group_name = \"rg-mytre\" keyvault_name = \"kv-mytre\" log_analytics_name = \"log-mytre\" static_web_storage = \"stwebmytre\" The Azure TRE instance is initially deployed with an invalid self-signed SSL certificate. This certificate needs to be replaced with one valid for your configured domain name. To use a certificate from Let's Encrypt , run the command: make letsencrypt Caution There are rate limits with Let's Encrypt, so this should not be run when not needed. Info If you're using Codespaces, you'll encounter a bug when trying to run make letsencrypt where the incorrect IP will be whitelisted on the storage account and Codespaces won't be able to upload the test file due to a 403 error. The workaround until this is fixed is to temporarily disable the firewall on your stweb{TRE_ID} storage account before running the script, then re-enable afterwards. Validate the deployment Using curl Use curl to make a simple request to the health endpoint of the API: curl https://<azure_tre_fqdn>/api/health The expected response is: { \"services\" : [ { \"service\" : \"Cosmos DB\" , \"status\" : \"OK\" , \"message\" : \"\" }, { \"service\" : \"Service Bus\" , \"status\" : \"OK\" , \"message\" : \"\" }, { \"service\" : \"Resource Processor\" , \"status\" : \"OK\" , \"message\" : \"\" } ] } Using the API docs Open your browser and navigate to the /api/docs route of the API: https://<azure_tre_fqdn>/api/docs and click Try it out on the operation of choice. Next steps Configure Shared Services Enable users to access the Azure TRE instance","title":"Deployment Steps"},{"location":"tre-admins/setup-instructions/manual-deployment/#deploying-azure-tre","text":"You are now ready to deploy the Azure TRE instance. Execute the all action of the makefile using make : make all Deploying a new Azure TRE instance takes approximately 30 minutes. Once the deployment is completed, you will be presented with a few output variables similar to the ones below: app_gateway_name = \"agw-mytre\" azure_tre_fqdn = \"mytre.westeurope.cloudapp.azure.com\" core_resource_group_name = \"rg-mytre\" keyvault_name = \"kv-mytre\" log_analytics_name = \"log-mytre\" static_web_storage = \"stwebmytre\" The Azure TRE instance is initially deployed with an invalid self-signed SSL certificate. This certificate needs to be replaced with one valid for your configured domain name. To use a certificate from Let's Encrypt , run the command: make letsencrypt Caution There are rate limits with Let's Encrypt, so this should not be run when not needed. Info If you're using Codespaces, you'll encounter a bug when trying to run make letsencrypt where the incorrect IP will be whitelisted on the storage account and Codespaces won't be able to upload the test file due to a 403 error. The workaround until this is fixed is to temporarily disable the firewall on your stweb{TRE_ID} storage account before running the script, then re-enable afterwards.","title":"Deploying Azure TRE"},{"location":"tre-admins/setup-instructions/manual-deployment/#validate-the-deployment","text":"","title":"Validate the deployment"},{"location":"tre-admins/setup-instructions/manual-deployment/#using-curl","text":"Use curl to make a simple request to the health endpoint of the API: curl https://<azure_tre_fqdn>/api/health The expected response is: { \"services\" : [ { \"service\" : \"Cosmos DB\" , \"status\" : \"OK\" , \"message\" : \"\" }, { \"service\" : \"Service Bus\" , \"status\" : \"OK\" , \"message\" : \"\" }, { \"service\" : \"Resource Processor\" , \"status\" : \"OK\" , \"message\" : \"\" } ] }","title":"Using curl"},{"location":"tre-admins/setup-instructions/manual-deployment/#using-the-api-docs","text":"Open your browser and navigate to the /api/docs route of the API: https://<azure_tre_fqdn>/api/docs and click Try it out on the operation of choice.","title":"Using the API docs"},{"location":"tre-admins/setup-instructions/manual-deployment/#next-steps","text":"Configure Shared Services Enable users to access the Azure TRE instance","title":"Next steps"},{"location":"tre-admins/setup-instructions/manual-pre-deployment-steps/","text":"Pre-deployment steps Info See Environment variables for full details of the deployment related variables. Set environment configuration variables of shared management resources In this part we will setup configuration variables in config.yaml file for the shared management infrastructure which is used to support the deployment of one or more Azure TRE instances. Provide the values for the following variables: Variable Description location The Azure location (region) for all resources. E.g., westeurope mgmt_resource_group_name The shared resource group for all management resources, including the storage account. mgmt_storage_account_name The name of the storage account to hold the Terraform state and other deployment artifacts. acr_name A globally unique name for the Azure Container Registry (ACR) that will be created to store deployment images. arm_subscription_id The Azure subscription ID for all resources. Tip To retrieve your Azure subscription ID, use the az command line interface available in the development container. In the terminal window in Visual Studio Code, type az login followed by az account show to see your default subscription. Please refer to az account -help for further details on how to change your active subscription. The rest of the variables can have their default values. You should now have a management section in the config.yaml file that looks similar to the one below: management: location: westeurope mgmt_resource_group_name: aztremgmt mgmt_storage_account_name: aztremgmt terraform_state_container_name: tfstate acr_name: aztreacr # Azure Resource Manager credentials used for CI/CD pipelines arm_subscription_id: 12...54e # If you want to override the currently signed in credentials # You would do this if running commands like `make terraform-install DIR=./templates/workspaces/base` # arm_tenant_id: __CHANGE_ME__ # arm_client_id: __CHANGE_ME__ # arm_client_secret: __CHANGE_ME__ 3. If you want to disable the built-in web UI ( ./ui ) ensure you set deploy_ui=false under tre defaults section in the config.yaml file. Next steps Deploying Azure TRE","title":"Pre-deployment Steps"},{"location":"tre-admins/setup-instructions/manual-pre-deployment-steps/#pre-deployment-steps","text":"Info See Environment variables for full details of the deployment related variables.","title":"Pre-deployment steps"},{"location":"tre-admins/setup-instructions/manual-pre-deployment-steps/#set-environment-configuration-variables-of-shared-management-resources","text":"In this part we will setup configuration variables in config.yaml file for the shared management infrastructure which is used to support the deployment of one or more Azure TRE instances. Provide the values for the following variables: Variable Description location The Azure location (region) for all resources. E.g., westeurope mgmt_resource_group_name The shared resource group for all management resources, including the storage account. mgmt_storage_account_name The name of the storage account to hold the Terraform state and other deployment artifacts. acr_name A globally unique name for the Azure Container Registry (ACR) that will be created to store deployment images. arm_subscription_id The Azure subscription ID for all resources. Tip To retrieve your Azure subscription ID, use the az command line interface available in the development container. In the terminal window in Visual Studio Code, type az login followed by az account show to see your default subscription. Please refer to az account -help for further details on how to change your active subscription. The rest of the variables can have their default values. You should now have a management section in the config.yaml file that looks similar to the one below: management: location: westeurope mgmt_resource_group_name: aztremgmt mgmt_storage_account_name: aztremgmt terraform_state_container_name: tfstate acr_name: aztreacr # Azure Resource Manager credentials used for CI/CD pipelines arm_subscription_id: 12...54e # If you want to override the currently signed in credentials # You would do this if running commands like `make terraform-install DIR=./templates/workspaces/base` # arm_tenant_id: __CHANGE_ME__ # arm_client_id: __CHANGE_ME__ # arm_client_secret: __CHANGE_ME__ 3. If you want to disable the built-in web UI ( ./ui ) ensure you set deploy_ui=false under tre defaults section in the config.yaml file.","title":"Set environment configuration variables of shared management resources"},{"location":"tre-admins/setup-instructions/manual-pre-deployment-steps/#next-steps","text":"Deploying Azure TRE","title":"Next steps"},{"location":"tre-admins/setup-instructions/prerequisites/","text":"Prerequisites To deploy an Azure TRE instance, the following assets and tools are required: Azure subscription Azure Active Directory (AAD) tenant in which you can create application registrations Git client such as Git or GitHub Desktop Docker Desktop Development container The Azure TRE solution contains a development container with all the required tooling to develop and deploy the Azure TRE. To deploy an Azure TRE instance using the provided development container you will also need: Visual Studio Code Remote containers extension for Visual Studio Code The files for the dev container are located in /.devcontainer/ folder. Tip An alternative of running the development container locally is to use GitHub Codespaces . Next steps AzureTRE Deployment Repository","title":"1. Prerequisites"},{"location":"tre-admins/setup-instructions/prerequisites/#prerequisites","text":"To deploy an Azure TRE instance, the following assets and tools are required: Azure subscription Azure Active Directory (AAD) tenant in which you can create application registrations Git client such as Git or GitHub Desktop Docker Desktop","title":"Prerequisites"},{"location":"tre-admins/setup-instructions/prerequisites/#development-container","text":"The Azure TRE solution contains a development container with all the required tooling to develop and deploy the Azure TRE. To deploy an Azure TRE instance using the provided development container you will also need: Visual Studio Code Remote containers extension for Visual Studio Code The files for the dev container are located in /.devcontainer/ folder. Tip An alternative of running the development container locally is to use GitHub Codespaces .","title":"Development container"},{"location":"tre-admins/setup-instructions/prerequisites/#next-steps","text":"AzureTRE Deployment Repository","title":"Next steps"},{"location":"tre-admins/setup-instructions/setup-auth-entities/","text":"Setup Auth configuration Next, you will set the configuration variables for the specific Azure TRE instance: Open the /config.sample.yaml file and then save it without the .sample extension. You should now have a file called config.yaml located in the root folder. The file contains configuration variables. In this part you will add the configuration required for the shared management infrastructure which is used to support the deployment of one or more Azure TRE instances. Provide the values for the following variables under management section in your config.yaml file: Variable Description location The Azure location (region) for all resources. E.g., westeurope mgmt_resource_group_name The shared resource group for all management resources, including the storage account. mgmt_storage_account_name The name of the storage account to hold the Terraform state and other deployment artifacts. acr_name A globally unique name for the Azure Container Registry (ACR) that will be created to store deployment images. arm_subscription_id The Azure subscription ID for all resources. !!! tip To retrieve your Azure subscription ID, use the az command line interface available in the development container. In the terminal window in Visual Studio Code, type az login followed by az account show to see your default subscription. Please refer to az account -help for further details on how to change your active subscription. The rest of the variables can have their default values. Decide on a name for your tre_id , which is an alphanumeric (with underscores allowed) ID for the Azure TRE instance. The value will be used in various Azure resources and AAD application names. It needs to be globally unique and less than 12 characters in length . Use only lowercase letters. Choose wisely! Once you have decided on which AD Tenant paradigm, then you should be able to set aad_tenant_id in the authentication section in your config.yaml file. Your AAD Tenant Admin can now use the terminal window in Visual Studio Code to execute the following script from within the development container to create all the AAD Applications that are used for TRE. The details of the script are covered in the auth document . make auth Note Credentials created by the make auth command will be added under the authentication section in your config.yaml file Note In case you have several subscriptions and would like to change your default subscription use az account set --subscription <desired subscription ID> Note The full functionality of the script requires directory admin privileges. You may need to contact your friendly Azure Active Directory admin to complete this step. The app registrations can be created manually in Azure Portal too. For more information, see Authentication and authorization . All other variables can have their default values for now. Add admin user Make sure the TRE Administrators and TRE Users roles, defined by the API app registration, are assigned to your user and others as required. See Enabling users for instructions.","title":"4. Setup Auth"},{"location":"tre-admins/setup-instructions/setup-auth-entities/#setup-auth-configuration","text":"Next, you will set the configuration variables for the specific Azure TRE instance: Open the /config.sample.yaml file and then save it without the .sample extension. You should now have a file called config.yaml located in the root folder. The file contains configuration variables. In this part you will add the configuration required for the shared management infrastructure which is used to support the deployment of one or more Azure TRE instances. Provide the values for the following variables under management section in your config.yaml file: Variable Description location The Azure location (region) for all resources. E.g., westeurope mgmt_resource_group_name The shared resource group for all management resources, including the storage account. mgmt_storage_account_name The name of the storage account to hold the Terraform state and other deployment artifacts. acr_name A globally unique name for the Azure Container Registry (ACR) that will be created to store deployment images. arm_subscription_id The Azure subscription ID for all resources. !!! tip To retrieve your Azure subscription ID, use the az command line interface available in the development container. In the terminal window in Visual Studio Code, type az login followed by az account show to see your default subscription. Please refer to az account -help for further details on how to change your active subscription. The rest of the variables can have their default values. Decide on a name for your tre_id , which is an alphanumeric (with underscores allowed) ID for the Azure TRE instance. The value will be used in various Azure resources and AAD application names. It needs to be globally unique and less than 12 characters in length . Use only lowercase letters. Choose wisely! Once you have decided on which AD Tenant paradigm, then you should be able to set aad_tenant_id in the authentication section in your config.yaml file. Your AAD Tenant Admin can now use the terminal window in Visual Studio Code to execute the following script from within the development container to create all the AAD Applications that are used for TRE. The details of the script are covered in the auth document . make auth Note Credentials created by the make auth command will be added under the authentication section in your config.yaml file Note In case you have several subscriptions and would like to change your default subscription use az account set --subscription <desired subscription ID> Note The full functionality of the script requires directory admin privileges. You may need to contact your friendly Azure Active Directory admin to complete this step. The app registrations can be created manually in Azure Portal too. For more information, see Authentication and authorization . All other variables can have their default values for now.","title":"Setup Auth configuration"},{"location":"tre-admins/setup-instructions/setup-auth-entities/#add-admin-user","text":"Make sure the TRE Administrators and TRE Users roles, defined by the API app registration, are assigned to your user and others as required. See Enabling users for instructions.","title":"Add admin user"},{"location":"tre-admins/setup-instructions/ui-install-base-workspace/","text":"Installing base workspace Publishing and registering the base workspace bundle Run the following in a terminal to build, publish and register the base workpace bundle: make workspace_bundle BUNDLE=base This will prepare the template for use with your TRE. Create Base Workspace Workspace can be easily created via AzureTRE UI. Open a browser and navigate to: https://<TRE_ID>.<LOCATION>.cloudapp.azure.com/ (replace TRE_ID and LOCATION with values from previous steps). It will require you to log in, make sure you login with a user who is a TREAdmin. Select Workspaces -> Create New: Click on Create under Base Workspace: Fill in the details for your workspace: - Fill in general information such as name and description - [Optional] Update values for Shared Storage Quota, App Service Plan (SKU) and Address space if needed - Workspace Authentication Type - this determines whether you'd like TRE to create an app registration for the workspace automatically, or whether you with to provide an existing one that you've created manually. To read about how to create it manually read the Creating an Application Client for base workspace section below. After filling the details press submit. Select go to resource to see its status: Navigate to Operation and wait till changed to deployed: Workspace is now ready to use. Creating an Application Client for base workspace As explained in the auth guide , every workspace has a corresponding app registration which if you haven't run make auth ; can be created using the helper script ./devops/scripts/aad/create_workspace_application.sh . For example: ./devops/scripts/aad/create_workspace_application.sh \\ --name \" ${ TRE_ID } - workspace 1\" \\ --admin-consent \\ --ux-clientid \" ${ SWAGGER_UI_CLIENT_ID } \" \\ --automation-clientid \" ${ TEST_ACCOUNT_CLIENT_ID } \" \\ --application-admin-clientid \" ${ APPLICATION_ADMIN_CLIENT_ID } \" Caution If you're using a separate tenant for AAD app registrations to the one where you've deployed the TRE infrastructure resources, ensure you've signed into that tenant in the az cli before running the above command. See Using a separate Azure Active Directory tenant in Setup Auth configuration for more details. Running the script will report WORKSPACE_API_CLIENT_ID and WORKSPACE_API_CLIENT_SECRET for the generated app. Set these under authentication section in config.yaml so that automated testing will work. You also need to use WORKSPACE_API_CLIENT_ID and WORKSPACE_API_CLIENT_SECRET in the form. Next steps Installing a workspace service & user resources","title":"7. Install Base Workspace"},{"location":"tre-admins/setup-instructions/ui-install-base-workspace/#installing-base-workspace","text":"","title":"Installing base workspace"},{"location":"tre-admins/setup-instructions/ui-install-base-workspace/#publishing-and-registering-the-base-workspace-bundle","text":"Run the following in a terminal to build, publish and register the base workpace bundle: make workspace_bundle BUNDLE=base This will prepare the template for use with your TRE.","title":"Publishing and registering the base workspace bundle"},{"location":"tre-admins/setup-instructions/ui-install-base-workspace/#create-base-workspace","text":"Workspace can be easily created via AzureTRE UI. Open a browser and navigate to: https://<TRE_ID>.<LOCATION>.cloudapp.azure.com/ (replace TRE_ID and LOCATION with values from previous steps). It will require you to log in, make sure you login with a user who is a TREAdmin. Select Workspaces -> Create New: Click on Create under Base Workspace: Fill in the details for your workspace: - Fill in general information such as name and description - [Optional] Update values for Shared Storage Quota, App Service Plan (SKU) and Address space if needed - Workspace Authentication Type - this determines whether you'd like TRE to create an app registration for the workspace automatically, or whether you with to provide an existing one that you've created manually. To read about how to create it manually read the Creating an Application Client for base workspace section below. After filling the details press submit. Select go to resource to see its status: Navigate to Operation and wait till changed to deployed: Workspace is now ready to use.","title":"Create Base Workspace"},{"location":"tre-admins/setup-instructions/ui-install-base-workspace/#creating-an-application-client-for-base-workspace","text":"As explained in the auth guide , every workspace has a corresponding app registration which if you haven't run make auth ; can be created using the helper script ./devops/scripts/aad/create_workspace_application.sh . For example: ./devops/scripts/aad/create_workspace_application.sh \\ --name \" ${ TRE_ID } - workspace 1\" \\ --admin-consent \\ --ux-clientid \" ${ SWAGGER_UI_CLIENT_ID } \" \\ --automation-clientid \" ${ TEST_ACCOUNT_CLIENT_ID } \" \\ --application-admin-clientid \" ${ APPLICATION_ADMIN_CLIENT_ID } \" Caution If you're using a separate tenant for AAD app registrations to the one where you've deployed the TRE infrastructure resources, ensure you've signed into that tenant in the az cli before running the above command. See Using a separate Azure Active Directory tenant in Setup Auth configuration for more details. Running the script will report WORKSPACE_API_CLIENT_ID and WORKSPACE_API_CLIENT_SECRET for the generated app. Set these under authentication section in config.yaml so that automated testing will work. You also need to use WORKSPACE_API_CLIENT_ID and WORKSPACE_API_CLIENT_SECRET in the form.","title":"Creating an Application Client for base workspace"},{"location":"tre-admins/setup-instructions/ui-install-base-workspace/#next-steps","text":"Installing a workspace service & user resources","title":"Next steps"},{"location":"tre-admins/setup-instructions/ui-install-ws-and-ur/","text":"Installing workspace service and user resource Publish and register a workspace service template We will use the Guacamole workspace service bundle for the purposes of this tutorial; a template that provides Virtual Desktop functionality allowing the deployment of VMs for users. These steps can be repeated for any workspace service template depending on the functionalities required. Run: make workspace_service_bundle BUNDLE=guacamole Publish and register a user resource template The Guacamole workspace service also has user resources: the VMs that researchers will deploy. These steps can be repeated for any user resource template. Run: make user_resource_bundle BUNDLE=guacamole-azure-windowsvm WORKSPACE_SERVICE=guacamole Creating a workspace service Now that we have published and registered both workspace service and user resource bundles we can use the UI to create a workspace service in our workspace. In the UI go to the workspace you have created in the previous step and click on Create New under Workspace Services: 2. Choose the Guacamole (Vurtual Desktop) template: 3. Fill in the details: 4. Go to operations tab and wait till the status is deployed: Creating a user resource Having published and registered the user resource bundles and a Guacamole workspace service is deployed we can now create the VM user resource the researcher can connect and work on. To create a VM user resource follow the next steps: Inside the Guacamole workspace service created in a previous step, go to Resources and click on Create New : Select the VM template and click on Create : Fill in the details and click on Submit : Go to the reource: Wait until the status is deployed. Once deployed you can connect to the VM:","title":"8. Install Workspace Service and User Resource"},{"location":"tre-admins/setup-instructions/ui-install-ws-and-ur/#installing-workspace-service-and-user-resource","text":"","title":"Installing workspace service and user resource"},{"location":"tre-admins/setup-instructions/ui-install-ws-and-ur/#publish-and-register-a-workspace-service-template","text":"We will use the Guacamole workspace service bundle for the purposes of this tutorial; a template that provides Virtual Desktop functionality allowing the deployment of VMs for users. These steps can be repeated for any workspace service template depending on the functionalities required. Run: make workspace_service_bundle BUNDLE=guacamole","title":"Publish and register a workspace service template"},{"location":"tre-admins/setup-instructions/ui-install-ws-and-ur/#publish-and-register-a-user-resource-template","text":"The Guacamole workspace service also has user resources: the VMs that researchers will deploy. These steps can be repeated for any user resource template. Run: make user_resource_bundle BUNDLE=guacamole-azure-windowsvm WORKSPACE_SERVICE=guacamole","title":"Publish and register a user resource template"},{"location":"tre-admins/setup-instructions/ui-install-ws-and-ur/#creating-a-workspace-service","text":"Now that we have published and registered both workspace service and user resource bundles we can use the UI to create a workspace service in our workspace. In the UI go to the workspace you have created in the previous step and click on Create New under Workspace Services: 2. Choose the Guacamole (Vurtual Desktop) template: 3. Fill in the details: 4. Go to operations tab and wait till the status is deployed:","title":"Creating a workspace service"},{"location":"tre-admins/setup-instructions/ui-install-ws-and-ur/#creating-a-user-resource","text":"Having published and registered the user resource bundles and a Guacamole workspace service is deployed we can now create the VM user resource the researcher can connect and work on. To create a VM user resource follow the next steps: Inside the Guacamole workspace service created in a previous step, go to Resources and click on Create New : Select the VM template and click on Create : Fill in the details and click on Submit : Go to the reource: Wait until the status is deployed. Once deployed you can connect to the VM:","title":"Creating a user resource"},{"location":"tre-admins/setup-instructions/workflows/","text":"GitHub Actions workflows (CI/CD) To deploy the Azure TRE using GitHub workflows, create a fork of the repository. Deployment is done using the /.github/workflows/deploy_tre.yml workflow. This method is also used to deploy the dev/test environment for the original Azure TRE repository. Setup instructions Before you can run the deploy_tre.yml workflow there are some one-time configuration steps that we need to do, similar to the Pre-deployment steps for manual deployment. Tip In some of the steps below, you are asked to configure repository secrets. Follow the GitHub guide on creating repository secrets if you are unfamiliar with this step. Create a service principal for the subscription so that the workflow can provision Azure resources. Decide on a TRE ID and the location for the Azure resources Create app registrations for API authentication Create app registrations and a user for the E2E tests Create a workspace app registration for setting up workspaces (for the E2E tests) Create a Teams WebHook for deployment notifications Configure repository secrets Deploy the TRE using the workflow Create a service principal for provisioning resources Login to Azure Log in to Azure using az login and select the Azure subscription you wish to deploy Azure TRE to: az login az account list az account set --subscription <subscription ID> See Sign in with Azure CLI for more details. Create a service principal A service principal needs to be created to authorize CI/CD workflows to provision resources for the TRE workspaces and workspace services. Create a main service principal with \" Owner \" role: az ad sp create-for-rbac --name \"sp-aztre-cicd\" --role Owner --scopes /subscriptions/<subscription_id> --sdk-auth Caution Save the JSON output locally - as you will need it later for setting secrets in the build Create a repository secret named AZURE_CREDENTIALS and use the JSON output from the previous step as its value. Note it should look similar to this: { \"clientId\" : \"\" , \"clientSecret\" : \"\" , \"subscriptionId\" : \"\" , \"tenantId\" : \"\" } Decide on a TRE ID and Azure resources location Configure the TRE ID and LOCATION repository secrets Secret name Description TRE_ID A globally unique identifier. TRE_ID can be found in the resource names of the Azure TRE instance; for example, a TRE_ID of tre-dev-42 will result in a resource group name for Azure TRE instance of rg-tre-dev-42 . This must be less than 12 characters. Allowed characters: Alphanumeric and underscores. LOCATION The Azure location (region) for all resources. E.g. westeurope Create app registrations for API authentication Follow the instructions to run the app registration script in the Authentication and Authorization document . Use the values for TRE ID and LOCATION from above. Configure the TRE API and Swagger UI repository secrets Secret name Description AAD_TENANT_ID The tenant ID of the Azure AD. SWAGGER_UI_CLIENT_ID The application (client) ID of the TRE Swagger UI app. API_CLIENT_ID The application (client) ID of the TRE API app. API_CLIENT_SECRET The application password (client secret) of the TRE API app. Create an app registration and a user for the E2E tests Follow the instructions to create an app registration and a test user for the E2E tests in the Authentication and Authorization document. Configure the E2E Test repository secrets Secret name Description TEST_APP_ID The application (client) ID of the E2E Test app TEST_USER_NAME The username of the E2E Test User TEST_USER_PASSWORD The password of the E2E Test User Create a workspace app registration for setting up workspaces (for the E2E tests) Follow the instructions to create a workspace app registration (used for the E2E tests) - and make the E2E test user a WorkspaceOwner for the app registration. Configure the TEST_WORKSPACE_APP_ID repository secret Secret name Description TEST_WORKSPACE_APP_ID The application (client) ID of the Workspaces app. TEST_WORKSPACE_APP_SECRET The application (client) secret of the Workspaces app. Create a Teams Webhook for deployment notifications The deploy_tre.yml workflow sends a notification to a Microsoft Teams channel when it finishes running. Note If you don't want to notify a channel, you can also remove the Notify dedicated teams channel steps in the workflow Follow the Microsoft Docs to create a webhook for your channel Configure the MS_TEAMS_WEBHOOK_URI repository secret Secret name Description MS_TEAMS_WEBHOOK_URI URI for the Teams channel webhook Configure repository secrets Configure additional repository secrets used in the deployment workflow Secret name Description MGMT_RESOURCE_GROUP_NAME The name of the shared resource group for all Azure TRE core resources. MGMT_STORAGE_ACCOUNT_NAME The name of the storage account to hold the Terraform state and other deployment artifacts. E.g. mystorageaccount . ACR_NAME A globally unique name for the Azure Container Registry (ACR) that will be created to store deployment images. CORE_ADDRESS_SPACE The address space for the Azure TRE core virtual network. E.g. 10.1.0.0/22 . Recommended /22 or larger. TRE_ADDRESS_SPACE The address space for the whole TRE environment virtual network where workspaces networks will be created (can include the core network as well). E.g. 10.0.0.0/12 TERRAFORM_STATE_CONTAINER_NAME Optional. The name of the blob container to hold the Terraform state. Default value is tfstate . CORE_APP_SERVICE_PLAN_SKU Optional. The SKU used for AppService plan for core infrastructure. Default value is P1v2 . WORKSPACE_APP_SERVICE_PLAN_SKU Optional. The SKU used for AppService plan used in E2E tests. Default value is P1v2 . Deploy the TRE using the workflow With all the repository secrets set, you can trigger a workflow run by pushing to develop/main of your fork, or by dispatching the workflow manually.","title":"GitHub Actions"},{"location":"tre-admins/setup-instructions/workflows/#github-actions-workflows-cicd","text":"To deploy the Azure TRE using GitHub workflows, create a fork of the repository. Deployment is done using the /.github/workflows/deploy_tre.yml workflow. This method is also used to deploy the dev/test environment for the original Azure TRE repository.","title":"GitHub Actions workflows (CI/CD)"},{"location":"tre-admins/setup-instructions/workflows/#setup-instructions","text":"Before you can run the deploy_tre.yml workflow there are some one-time configuration steps that we need to do, similar to the Pre-deployment steps for manual deployment. Tip In some of the steps below, you are asked to configure repository secrets. Follow the GitHub guide on creating repository secrets if you are unfamiliar with this step. Create a service principal for the subscription so that the workflow can provision Azure resources. Decide on a TRE ID and the location for the Azure resources Create app registrations for API authentication Create app registrations and a user for the E2E tests Create a workspace app registration for setting up workspaces (for the E2E tests) Create a Teams WebHook for deployment notifications Configure repository secrets Deploy the TRE using the workflow","title":"Setup instructions"},{"location":"tre-admins/setup-instructions/workflows/#create-a-service-principal-for-provisioning-resources","text":"Login to Azure Log in to Azure using az login and select the Azure subscription you wish to deploy Azure TRE to: az login az account list az account set --subscription <subscription ID> See Sign in with Azure CLI for more details. Create a service principal A service principal needs to be created to authorize CI/CD workflows to provision resources for the TRE workspaces and workspace services. Create a main service principal with \" Owner \" role: az ad sp create-for-rbac --name \"sp-aztre-cicd\" --role Owner --scopes /subscriptions/<subscription_id> --sdk-auth Caution Save the JSON output locally - as you will need it later for setting secrets in the build Create a repository secret named AZURE_CREDENTIALS and use the JSON output from the previous step as its value. Note it should look similar to this: { \"clientId\" : \"\" , \"clientSecret\" : \"\" , \"subscriptionId\" : \"\" , \"tenantId\" : \"\" }","title":"Create a service principal for provisioning resources"},{"location":"tre-admins/setup-instructions/workflows/#decide-on-a-tre-id-and-azure-resources-location","text":"Configure the TRE ID and LOCATION repository secrets Secret name Description TRE_ID A globally unique identifier. TRE_ID can be found in the resource names of the Azure TRE instance; for example, a TRE_ID of tre-dev-42 will result in a resource group name for Azure TRE instance of rg-tre-dev-42 . This must be less than 12 characters. Allowed characters: Alphanumeric and underscores. LOCATION The Azure location (region) for all resources. E.g. westeurope","title":"Decide on a TRE ID and Azure resources location"},{"location":"tre-admins/setup-instructions/workflows/#create-app-registrations-for-api-authentication","text":"Follow the instructions to run the app registration script in the Authentication and Authorization document . Use the values for TRE ID and LOCATION from above. Configure the TRE API and Swagger UI repository secrets Secret name Description AAD_TENANT_ID The tenant ID of the Azure AD. SWAGGER_UI_CLIENT_ID The application (client) ID of the TRE Swagger UI app. API_CLIENT_ID The application (client) ID of the TRE API app. API_CLIENT_SECRET The application password (client secret) of the TRE API app.","title":"Create app registrations for API authentication"},{"location":"tre-admins/setup-instructions/workflows/#create-an-app-registration-and-a-user-for-the-e2e-tests","text":"Follow the instructions to create an app registration and a test user for the E2E tests in the Authentication and Authorization document. Configure the E2E Test repository secrets Secret name Description TEST_APP_ID The application (client) ID of the E2E Test app TEST_USER_NAME The username of the E2E Test User TEST_USER_PASSWORD The password of the E2E Test User","title":"Create an app registration and a user for the E2E tests"},{"location":"tre-admins/setup-instructions/workflows/#create-a-workspace-app-registration-for-setting-up-workspaces-for-the-e2e-tests","text":"Follow the instructions to create a workspace app registration (used for the E2E tests) - and make the E2E test user a WorkspaceOwner for the app registration. Configure the TEST_WORKSPACE_APP_ID repository secret Secret name Description TEST_WORKSPACE_APP_ID The application (client) ID of the Workspaces app. TEST_WORKSPACE_APP_SECRET The application (client) secret of the Workspaces app.","title":"Create a workspace app registration for setting up workspaces (for the E2E tests)"},{"location":"tre-admins/setup-instructions/workflows/#create-a-teams-webhook-for-deployment-notifications","text":"The deploy_tre.yml workflow sends a notification to a Microsoft Teams channel when it finishes running. Note If you don't want to notify a channel, you can also remove the Notify dedicated teams channel steps in the workflow Follow the Microsoft Docs to create a webhook for your channel Configure the MS_TEAMS_WEBHOOK_URI repository secret Secret name Description MS_TEAMS_WEBHOOK_URI URI for the Teams channel webhook","title":"Create a Teams Webhook for deployment notifications"},{"location":"tre-admins/setup-instructions/workflows/#configure-repository-secrets","text":"Configure additional repository secrets used in the deployment workflow Secret name Description MGMT_RESOURCE_GROUP_NAME The name of the shared resource group for all Azure TRE core resources. MGMT_STORAGE_ACCOUNT_NAME The name of the storage account to hold the Terraform state and other deployment artifacts. E.g. mystorageaccount . ACR_NAME A globally unique name for the Azure Container Registry (ACR) that will be created to store deployment images. CORE_ADDRESS_SPACE The address space for the Azure TRE core virtual network. E.g. 10.1.0.0/22 . Recommended /22 or larger. TRE_ADDRESS_SPACE The address space for the whole TRE environment virtual network where workspaces networks will be created (can include the core network as well). E.g. 10.0.0.0/12 TERRAFORM_STATE_CONTAINER_NAME Optional. The name of the blob container to hold the Terraform state. Default value is tfstate . CORE_APP_SERVICE_PLAN_SKU Optional. The SKU used for AppService plan for core infrastructure. Default value is P1v2 . WORKSPACE_APP_SERVICE_PLAN_SKU Optional. The SKU used for AppService plan used in E2E tests. Default value is P1v2 .","title":"Configure repository secrets"},{"location":"tre-admins/setup-instructions/workflows/#deploy-the-tre-using-the-workflow","text":"With all the repository secrets set, you can trigger a workflow run by pushing to develop/main of your fork, or by dispatching the workflow manually.","title":"Deploy the TRE using the workflow"},{"location":"tre-developers/","text":"TRE Developers This section contains information relevant for developing against Azure TRE. See the topics in the index on the left.","title":"Introduction"},{"location":"tre-developers/#tre-developers","text":"This section contains information relevant for developing against Azure TRE. See the topics in the index on the left.","title":"TRE Developers"},{"location":"tre-developers/CLI/","text":"TRE CLI WARNING - this CLI is currently experimental This guide will cover various components of AzureTRE CLI such as installation, login, general command structure and other components that enable operating the CLI. Installation It is recommended to use CLI within the dev container. It should be installed automatically. To install it manually, run make install-cli . Shell completion The tre cli supports shell completion. To enable, run source <(_TRE_COMPLETE=bash_source tre) (or add to your profile). Other shells are supported, see the click docs . Login The CLI allows you to log in using either a device code flow or client credentials flow. Device code flow (interactive) To log in using device code flow, run: tre login device-code --base-url https://mytre.westeurope.cloudapp.azure.com/ This will prompt you to copy a device code and nagivate to https://microsoft.com/devicelogin to complete the login flow interactively. You can specify --no-verify to disable SSL cert verification. On versions of the API prior to '0.5.7', you will need to pass some additional parameters: tre login device-code \\ --base-url https://mytre.westeurope.cloudapp.azure.com/ \\ --client-id <API_CLIENT_ID> \\ --aad-tenant-id <AAD_TENANT_ID> \\ --api-scope <ROOT_API_SCOPE> Info the API scope is usually of the form api://<API_CLIENT_ID>/user_impersonation Info when using device code flow, you need to ensure that the app registrations for the root API and any workspaces you access have device code flow enabled. (Automating this is tracked in #2709 ) Workspace authentication Since the API scope for each workspace is different, the token returned when authenticating against the root API isn't valid against a workspace. When running interactively, the CLI will prompt you when it needs to reauthenticate for a workspace API. You can pre-emptively get an authentication token for a workspace using the --workspace option. This can be specified multiple times to authenticate against multiple workspaces at once. You can also using --all-workspaces to get a token for all workspaces in one command. Client credentials (service) To log in using client credentials flow (for a service principal), run: tre login client-credentials \\ --base-url https://mytre.westeurope.cloudapp.azure.com/ \\ --client-id <SERVICE_PRINICPAL_CLIENT_ID> \\ --client-secret <SERVICE_PRINCIPAL_CLIENT_SECRET> You can specify --no-verify to disable SSL cert verification. On versions of the API prior to '0.5.7', you will need to pass some additional parameters: tre login client-credentials \\ --base-url https://mytre.westeurope.cloudapp.azure.com/ \\ --client-id <SERVICE_PRINICPAL_CLIENT_ID> \\ --client-secret <SERVICE_PRINCIPAL_CLIENT_SECRET> \\ --aad-tenant-id <AAD_TENANT_ID> \\ --api-scope <ROOT_API_SCOPE> Info the API scope is usually of the form api://<API_CLIENT_ID>/user_impersonation General command structure The general command structure for the CLI is: tre plural_noun cmd # or tre singular_noun id cmd For example: # list workspaces tre workspaces list ## show an individual workspace tre workspace 567f17d6-1abb-450f-991a-19398f89b3c2 show This pattern is nested for sub-resources, e.g. operations for a workspace: ## list operations for a workspace tre workspace 567f17d6-1abb-450f-991a-19398f89b3c2 operations list ## show an individual operation for a workspace tre workspace 567f17d6-1abb-450f-991a-19398f89b3c2 operation 0f66839f-8727-43db-b2d6-6c7197712e36 show Asynchronous operations Many operations in TRE are asynchronous, and the corresponding API endpoints return a 202 Accepted response with a Location header pointing to an operation endpoint. The commands corresponding to these asynchronous operations will poll this resulting operation and wait until it has completed. If you don't want this behaviour, you can pass the --no-wait option. Command output Output formats Most commands support formatting output as table (default), json , jsonc , raw , or none via the --output option. This can also be controlled using the TRECLI_OUTPUT environment variable, i.e. set TRECLI_OUTPUT to table to default to the table output format. Option Description table Works well for interactive use json Plain JSON output, ideal for parsing via jq or other tools jsonc Coloured, formatted JSON raw Results are output as-is. Useful with --query when capturing a single value none No output Querying output Most commands support JMESPath queries for the output via the --query option. For example, to get a list of workspace IDs run tre workspaces list --query workspaces[].id . This can be combined with --output table , e.g. tre workspaces list -o table --query \"workspaces[].{id:id, name: properties.display_name}\" . Note that the query result must be an object with named properties (or an array of such objects) Capturing results Some of the commands in the CLI output progress information (e.g. tre workspace new ... ). When the CLI outputs progress information, it outputs it to stderr. The final result of the command is output to stdout. This gives a good experience when chaining commands together, e.g.: # Set the workspace to use WORKSPACE_ID = 567f17d6-1abb-450f-991a-19398f89b3c2 # Get the workspace etag ETAG = $( tre workspace $WORKSPACE_ID show --query workspace._etag --output json ) # Disable the workspace (this is an asynchronous operation) OPERATION = $( tre workspace $WORKSPACE_ID set-enabled --etag $ETAG --enable --output json ) # ^ this last command will output progress information while waiting for the operation to complete. # And OPERATION contains the JSON describing the completed operation # allowing you to query the status property etc echo $OPERATION Passing definitions When creating new resources (e.g. workspaces), you need to pass in a definition. This can be passed in various ways: as an inline value, from a file, or from stdin. To pass a definition inline, use the --definition option and include the JSON content, e.g. tre workspace new --definition '{\"templateName\":...}' To load a definition from a file, use the --definition-file option, e.g. tre workspace new --definition-file my-worspace.json To pass a definition via stdin, use --definition-file - (note the - to signal reading from stdin). Reading from stdin allows you to take some interesting approaches to specifying the definition. For example, you can use HEREDOC syntax to describe the JSON payload over multiple lines: cat << EOF | tre workspaces new --definition-file - { \"templateName\": \"my-workspace\", \"properties\": { \"display_name\": $DISPLAY_NAME, ... } } EOF Or you can load the content from a file that contains embedded environment variables and use envsubst to substitute them: cat my-workspace.json | envsubst | tre workspace new --definition file - Overriding the API URL When you run tre login you specify the base URL for the API, but when you are developing AzureTRE you may want to make calls against the locally running API. To support this, you can set the TRECLI_BASE_URL environment variable and that will override the API endpoint used by the CLI. Example usage Creating an import airlock request # Set the ID of the workspace to create the import request for WORKSPACE_ID = __ADD_ID_HERE__ # Create the airlock request - change the justification as appropriate request = $( tre workspace $WORKSPACE_ID airlock-requests new --type import --title \"Ant\" --justification \"It's import-ant\" --output json ) request_id = $( echo $request | jq -r .airlockRequest.id ) # Get the storage upload URL upload_url = $( tre workspace $WORKSPACE_ID airlock-request $request_id get-url --query containerUrl --output raw ) # Use the az CLI to upload ant.txt from the current directory (change as required) az storage blob upload-batch --source . --pattern ant.txt --destination $upload_url # Submit the request for review tre workspace $WORKSPACE_ID airlock-request $request_id submit","title":"AzureTRE CLI"},{"location":"tre-developers/CLI/#tre-cli","text":"WARNING - this CLI is currently experimental This guide will cover various components of AzureTRE CLI such as installation, login, general command structure and other components that enable operating the CLI.","title":"TRE CLI"},{"location":"tre-developers/CLI/#installation","text":"It is recommended to use CLI within the dev container. It should be installed automatically. To install it manually, run make install-cli .","title":"Installation"},{"location":"tre-developers/CLI/#shell-completion","text":"The tre cli supports shell completion. To enable, run source <(_TRE_COMPLETE=bash_source tre) (or add to your profile). Other shells are supported, see the click docs .","title":"Shell completion"},{"location":"tre-developers/CLI/#login","text":"The CLI allows you to log in using either a device code flow or client credentials flow.","title":"Login"},{"location":"tre-developers/CLI/#device-code-flow-interactive","text":"To log in using device code flow, run: tre login device-code --base-url https://mytre.westeurope.cloudapp.azure.com/ This will prompt you to copy a device code and nagivate to https://microsoft.com/devicelogin to complete the login flow interactively. You can specify --no-verify to disable SSL cert verification. On versions of the API prior to '0.5.7', you will need to pass some additional parameters: tre login device-code \\ --base-url https://mytre.westeurope.cloudapp.azure.com/ \\ --client-id <API_CLIENT_ID> \\ --aad-tenant-id <AAD_TENANT_ID> \\ --api-scope <ROOT_API_SCOPE> Info the API scope is usually of the form api://<API_CLIENT_ID>/user_impersonation Info when using device code flow, you need to ensure that the app registrations for the root API and any workspaces you access have device code flow enabled. (Automating this is tracked in #2709 )","title":"Device code flow (interactive)"},{"location":"tre-developers/CLI/#workspace-authentication","text":"Since the API scope for each workspace is different, the token returned when authenticating against the root API isn't valid against a workspace. When running interactively, the CLI will prompt you when it needs to reauthenticate for a workspace API. You can pre-emptively get an authentication token for a workspace using the --workspace option. This can be specified multiple times to authenticate against multiple workspaces at once. You can also using --all-workspaces to get a token for all workspaces in one command.","title":"Workspace authentication"},{"location":"tre-developers/CLI/#client-credentials-service","text":"To log in using client credentials flow (for a service principal), run: tre login client-credentials \\ --base-url https://mytre.westeurope.cloudapp.azure.com/ \\ --client-id <SERVICE_PRINICPAL_CLIENT_ID> \\ --client-secret <SERVICE_PRINCIPAL_CLIENT_SECRET> You can specify --no-verify to disable SSL cert verification. On versions of the API prior to '0.5.7', you will need to pass some additional parameters: tre login client-credentials \\ --base-url https://mytre.westeurope.cloudapp.azure.com/ \\ --client-id <SERVICE_PRINICPAL_CLIENT_ID> \\ --client-secret <SERVICE_PRINCIPAL_CLIENT_SECRET> \\ --aad-tenant-id <AAD_TENANT_ID> \\ --api-scope <ROOT_API_SCOPE> Info the API scope is usually of the form api://<API_CLIENT_ID>/user_impersonation","title":"Client credentials (service)"},{"location":"tre-developers/CLI/#general-command-structure","text":"The general command structure for the CLI is: tre plural_noun cmd # or tre singular_noun id cmd For example: # list workspaces tre workspaces list ## show an individual workspace tre workspace 567f17d6-1abb-450f-991a-19398f89b3c2 show This pattern is nested for sub-resources, e.g. operations for a workspace: ## list operations for a workspace tre workspace 567f17d6-1abb-450f-991a-19398f89b3c2 operations list ## show an individual operation for a workspace tre workspace 567f17d6-1abb-450f-991a-19398f89b3c2 operation 0f66839f-8727-43db-b2d6-6c7197712e36 show","title":"General command structure"},{"location":"tre-developers/CLI/#asynchronous-operations","text":"Many operations in TRE are asynchronous, and the corresponding API endpoints return a 202 Accepted response with a Location header pointing to an operation endpoint. The commands corresponding to these asynchronous operations will poll this resulting operation and wait until it has completed. If you don't want this behaviour, you can pass the --no-wait option.","title":"Asynchronous operations"},{"location":"tre-developers/CLI/#command-output","text":"","title":"Command output"},{"location":"tre-developers/CLI/#output-formats","text":"Most commands support formatting output as table (default), json , jsonc , raw , or none via the --output option. This can also be controlled using the TRECLI_OUTPUT environment variable, i.e. set TRECLI_OUTPUT to table to default to the table output format. Option Description table Works well for interactive use json Plain JSON output, ideal for parsing via jq or other tools jsonc Coloured, formatted JSON raw Results are output as-is. Useful with --query when capturing a single value none No output","title":"Output formats"},{"location":"tre-developers/CLI/#querying-output","text":"Most commands support JMESPath queries for the output via the --query option. For example, to get a list of workspace IDs run tre workspaces list --query workspaces[].id . This can be combined with --output table , e.g. tre workspaces list -o table --query \"workspaces[].{id:id, name: properties.display_name}\" . Note that the query result must be an object with named properties (or an array of such objects)","title":"Querying output"},{"location":"tre-developers/CLI/#capturing-results","text":"Some of the commands in the CLI output progress information (e.g. tre workspace new ... ). When the CLI outputs progress information, it outputs it to stderr. The final result of the command is output to stdout. This gives a good experience when chaining commands together, e.g.: # Set the workspace to use WORKSPACE_ID = 567f17d6-1abb-450f-991a-19398f89b3c2 # Get the workspace etag ETAG = $( tre workspace $WORKSPACE_ID show --query workspace._etag --output json ) # Disable the workspace (this is an asynchronous operation) OPERATION = $( tre workspace $WORKSPACE_ID set-enabled --etag $ETAG --enable --output json ) # ^ this last command will output progress information while waiting for the operation to complete. # And OPERATION contains the JSON describing the completed operation # allowing you to query the status property etc echo $OPERATION","title":"Capturing results"},{"location":"tre-developers/CLI/#passing-definitions","text":"When creating new resources (e.g. workspaces), you need to pass in a definition. This can be passed in various ways: as an inline value, from a file, or from stdin. To pass a definition inline, use the --definition option and include the JSON content, e.g. tre workspace new --definition '{\"templateName\":...}' To load a definition from a file, use the --definition-file option, e.g. tre workspace new --definition-file my-worspace.json To pass a definition via stdin, use --definition-file - (note the - to signal reading from stdin). Reading from stdin allows you to take some interesting approaches to specifying the definition. For example, you can use HEREDOC syntax to describe the JSON payload over multiple lines: cat << EOF | tre workspaces new --definition-file - { \"templateName\": \"my-workspace\", \"properties\": { \"display_name\": $DISPLAY_NAME, ... } } EOF Or you can load the content from a file that contains embedded environment variables and use envsubst to substitute them: cat my-workspace.json | envsubst | tre workspace new --definition file -","title":"Passing definitions"},{"location":"tre-developers/CLI/#overriding-the-api-url","text":"When you run tre login you specify the base URL for the API, but when you are developing AzureTRE you may want to make calls against the locally running API. To support this, you can set the TRECLI_BASE_URL environment variable and that will override the API endpoint used by the CLI.","title":"Overriding the API URL"},{"location":"tre-developers/CLI/#example-usage","text":"","title":"Example usage"},{"location":"tre-developers/CLI/#creating-an-import-airlock-request","text":"# Set the ID of the workspace to create the import request for WORKSPACE_ID = __ADD_ID_HERE__ # Create the airlock request - change the justification as appropriate request = $( tre workspace $WORKSPACE_ID airlock-requests new --type import --title \"Ant\" --justification \"It's import-ant\" --output json ) request_id = $( echo $request | jq -r .airlockRequest.id ) # Get the storage upload URL upload_url = $( tre workspace $WORKSPACE_ID airlock-request $request_id get-url --query containerUrl --output raw ) # Use the az CLI to upload ant.txt from the current directory (change as required) az storage blob upload-batch --source . --pattern ant.txt --destination $upload_url # Submit the request for review tre workspace $WORKSPACE_ID airlock-request $request_id submit","title":"Creating an import airlock request"},{"location":"tre-developers/api-permissions-map/","text":"TRE API Permissions Map These tables specify each endpoint that exists today in TRE API and the permissions it supports. Workspace API Endpoints Researcher Workspace Owner Airlock Manager GET /workspaces/{workspace_id}/workspace-services V V V GET /workspaces/{workspace_id}/workspace-service-templates V V V GET /workspaces/{workspace_id}/workspace-service-templates/{service_template_name}/user-resource-templates V V V GET /workspaces/{workspace_id}/workspace-services/{service_id} V V POST /workspaces/{workspace_id}/workspace-services X V PATCH /workspaces/{workspace_id}/workspace-services/{service_id} X V DELETE /workspaces/{workspace_id}/workspace-services/{service_id} X V POST /workspaces/{workspace_id}/workspace-services/{service_id}/invoke-action X V GET /workspaces/{workspace_id}/workspace-services/{service_id}/operations X V V GET /workspaces/{workspace_id}/workspace-services/{service_id}/operations/{operation_id} X V V GET /workspaces/{workspace_id}/workspace-services/{service_id}/user-resources V V V GET /workspaces/{workspace_id}/workspace-services/{service_id}/user-resources/{resource_id} V V V POST /workspaces/{workspace_id}/workspace-services/{service_id}/user-resources V V V PATCH /workspaces/{workspace_id}/workspace-services/{service_id}/user-resources/{resource_id} V V V DELETE /workspaces/{workspace_id}/workspace-services/{service_id}/user-resources/{resource_id} V V V POST /workspaces/{workspace_id}/workspace-services/{service_id}/user-resources/{resource_id}/invoke-action V V V GET /workspaces/{workspace_id}/workspace-services/{service_id}/user-resources/{resource_id}/operations V V V GET /workspaces/{workspace_id}/workspace-services/{service_id}/user-resources/{resource_id}/operations/{operation_id} V V V GET /workspaces/{workspace_id}/requests V V V GET /workspaces/{workspace_id}/requests/{airlock_request_id} V V V POST /workspaces/{workspace_id}/requests V V X POST /workspaces/{workspace_id}/requests/{airlock_request_id}/submit V V X POST /workspaces/{workspace_id}/requests/{airlock_request_id}/cancel V V X POST /workspaces/{workspace_id}/requests/{airlock_request_id}/review X X V POST /workspaces/{workspace_id}/requests/{airlock_request_id}/review-user-resource X X V GET /workspaces/{workspace_id}/requests/{airlock_request_id}/link V V V ## Core API Endpoints TRE Admin TRE User WS Owner ------------------------------------------------------------------------------------------------------------------- --------- -------- -------- GET /workspace-templates V V GET /workspace-templates/{workspace_template_name} V V POST /workspace-templates V X GET /workspace-service-templates V V GET /workspace-service-templates/{workspace_service_template_name} V V POST /workspace-service-templates V X GET /workspace-service-templates/{service_template_name}/user-resource-templates V V GET /workspace-service-templates/{service_template_name}/user-resource-templates/{user_resource_template_name} V V POST /workspace-service-templates/{service_template_name}/user-resource-templates V X GET /workspaces V V GET /workspaces/(workspace_id) V V POST /workspaces V X PATCH /workspaces/{workspace_id} V X X DELETE /workspaces/{workspace_id} V X X POST /workspaces/{workspace_id}/invoke-action V X X GET /workspaces/{workspace_id}/operations V X V GET /workspaces/{workspace_id}/operations/{operation_id} V X V GET /shared-service-templates V V GET /shared-service-templates/{shared_service_template_name} V V POST /shared-service-templates V X GET /shared-service V V GET /shared-service/{shared_service_id} V V POST /shared-service V X PATCH /shared-service/{shared_service_id} V X DELETE /shared-service/{shared_service_id} V X POST /shared-service/{shared_service_id}/invoke-action V X GET /shared-service/{shared_service_id}/operations V X GET /shared-service/{shared_service_id}/operations/{operation_id} V X POST /migrations V X GET /costs V X X GET /workspaces/{workspace_id}/costs V X V GET /health - - - GET /ping - - - GET /.metadata - - -","title":"TRE API Permissions Map"},{"location":"tre-developers/api-permissions-map/#tre-api-permissions-map","text":"These tables specify each endpoint that exists today in TRE API and the permissions it supports.","title":"TRE API Permissions Map"},{"location":"tre-developers/api-permissions-map/#workspace-api","text":"Endpoints Researcher Workspace Owner Airlock Manager GET /workspaces/{workspace_id}/workspace-services V V V GET /workspaces/{workspace_id}/workspace-service-templates V V V GET /workspaces/{workspace_id}/workspace-service-templates/{service_template_name}/user-resource-templates V V V GET /workspaces/{workspace_id}/workspace-services/{service_id} V V POST /workspaces/{workspace_id}/workspace-services X V PATCH /workspaces/{workspace_id}/workspace-services/{service_id} X V DELETE /workspaces/{workspace_id}/workspace-services/{service_id} X V POST /workspaces/{workspace_id}/workspace-services/{service_id}/invoke-action X V GET /workspaces/{workspace_id}/workspace-services/{service_id}/operations X V V GET /workspaces/{workspace_id}/workspace-services/{service_id}/operations/{operation_id} X V V GET /workspaces/{workspace_id}/workspace-services/{service_id}/user-resources V V V GET /workspaces/{workspace_id}/workspace-services/{service_id}/user-resources/{resource_id} V V V POST /workspaces/{workspace_id}/workspace-services/{service_id}/user-resources V V V PATCH /workspaces/{workspace_id}/workspace-services/{service_id}/user-resources/{resource_id} V V V DELETE /workspaces/{workspace_id}/workspace-services/{service_id}/user-resources/{resource_id} V V V POST /workspaces/{workspace_id}/workspace-services/{service_id}/user-resources/{resource_id}/invoke-action V V V GET /workspaces/{workspace_id}/workspace-services/{service_id}/user-resources/{resource_id}/operations V V V GET /workspaces/{workspace_id}/workspace-services/{service_id}/user-resources/{resource_id}/operations/{operation_id} V V V GET /workspaces/{workspace_id}/requests V V V GET /workspaces/{workspace_id}/requests/{airlock_request_id} V V V POST /workspaces/{workspace_id}/requests V V X POST /workspaces/{workspace_id}/requests/{airlock_request_id}/submit V V X POST /workspaces/{workspace_id}/requests/{airlock_request_id}/cancel V V X POST /workspaces/{workspace_id}/requests/{airlock_request_id}/review X X V POST /workspaces/{workspace_id}/requests/{airlock_request_id}/review-user-resource X X V GET /workspaces/{workspace_id}/requests/{airlock_request_id}/link V V V ## Core API Endpoints TRE Admin TRE User WS Owner ------------------------------------------------------------------------------------------------------------------- --------- -------- -------- GET /workspace-templates V V GET /workspace-templates/{workspace_template_name} V V POST /workspace-templates V X GET /workspace-service-templates V V GET /workspace-service-templates/{workspace_service_template_name} V V POST /workspace-service-templates V X GET /workspace-service-templates/{service_template_name}/user-resource-templates V V GET /workspace-service-templates/{service_template_name}/user-resource-templates/{user_resource_template_name} V V POST /workspace-service-templates/{service_template_name}/user-resource-templates V X GET /workspaces V V GET /workspaces/(workspace_id) V V POST /workspaces V X PATCH /workspaces/{workspace_id} V X X DELETE /workspaces/{workspace_id} V X X POST /workspaces/{workspace_id}/invoke-action V X X GET /workspaces/{workspace_id}/operations V X V GET /workspaces/{workspace_id}/operations/{operation_id} V X V GET /shared-service-templates V V GET /shared-service-templates/{shared_service_template_name} V V POST /shared-service-templates V X GET /shared-service V V GET /shared-service/{shared_service_id} V V POST /shared-service V X PATCH /shared-service/{shared_service_id} V X DELETE /shared-service/{shared_service_id} V X POST /shared-service/{shared_service_id}/invoke-action V X GET /shared-service/{shared_service_id}/operations V X GET /shared-service/{shared_service_id}/operations/{operation_id} V X POST /migrations V X GET /costs V X X GET /workspaces/{workspace_id}/costs V X V GET /health - - - GET /ping - - - GET /.metadata - - -","title":"Workspace API"},{"location":"tre-developers/api/","text":"TRE API The TRE API is a service that users can interact with to request changes to workspaces e.g., to create, update, delete workspaces and workspace services inside each workspace. This page is a guide for a developer looking to make a change to the API and debug it. Repository folder structure api_app \u251c\u2500\u2500 api - API implementation \u2502 \u251c\u2500\u2500 dependencies - Dependencies for routes definition \u2502 \u251c\u2500\u2500 errors - Definitions of error handlers \u2502 \u2514\u2500\u2500 routes - Web routes (API endpoints) \u2502 \u251c\u2500\u2500 core - Application configuration, startup events, logging \u2502 \u251c\u2500\u2500 db - Database related implementation \u2502 \u251c\u2500\u2500 migrations - Manually written alembic migrations \u2502 \u2514\u2500\u2500 repositories - All CRUD features \u2502 \u251c\u2500\u2500 models - Pydantic models for this application \u2502 \u251c\u2500\u2500 domain - Main models that are used almost everywhere \u2502 \u2514\u2500\u2500 schemas - Schemas for using in web routes \u2502 \u251c\u2500\u2500 resources - Strings that are used e.g., in web responses \u2502 \u251c\u2500\u2500 services - Logic that is not only CRUD related (authentication, logging, tracing, etc) \u2502 \u251c\u2500\u2500 tests_ma - Unit tests \u2502 \u2514\u2500\u2500 main.py - FastAPI application creation and configuration Unit tests The unit tests are written with pytest and located in folder /api_app/tests_ma/ . Run all unit tests with the following command in the root folder of the repository: pytest --ignore=e2e_tests Please refer to a different guide on running E2E tests locally . Local debugging To set up local debugging, first run (if you haven't done so already) az login make setup-local-debugging Next, go to \"Run and Debug\" panel in VSCode, and select TRE API. You will see a log similar to this: Now, you should be able to open Swagger UI for your local instance on http://localhost:8000/api/docs . Cloud instance On Azure Portal, find an App Service instance named app-${TRE_ID} . API logs in LogAnalytics To find logs in LogAnalytics, go to your resource group, then to LogAnalytics instance, which is named like log-${TRE_ID} . There, you can run a query like AppTraces | where AppRoleName == \"uvicorn\" | order by TimeGenerated desc API logs using deployment center Check that the version you are debugging/troubleshooting is the same one deployed on the App Service. You can check this in Deployment Center, or follow the logs as generated by the container in the logs tabs. Deploying a cloud instance To deploy a new version of the API to your TRE deployment, do this: Update the version in api_app/_version.py Run make build-and-push-api make deploy-core Enabling DEBUG mode on the API For security, the API is by default configured to not show detailed error messages and stack trace when an error occurs. You can enable debugging via one of the two ways: Set debug=true under developer_settings section in your config.yaml file (see []) To enable debugging on an already running instance: Go to App Service for the API and select Settings > Configuration . Click New Application Setting . in the new dialog box set Name=DEBUG and Value=true Using Swagger UI Swagger UI lets you send requests to the API. To send a request, click on the row with the request, then Try out , then Execute . See screenshot: Authorization Swagger UI is accessible under https://${TRE_ID}.${LOCATION}.cloudapp.azure.com/api/docs . To start using it, click Authorize button, then click Authorize (leave the field client_secret empty). See screenshot: If you see an error message saying something like: The redirect URI 'https://tanyagts8.westeurope.cloudapp.azure.com/api/docs/oauth2-redirect' specified in the request does not match the redirect URIs configured for the application '558602a8-764a-453c-8efa-4dc3ddd61570'. Then you'll need to update the redirect URI (see below). Otherwise, after you sign in on Azure Portal, the lock icon on Authorize button should look \"locked\". Then you can start executing queries. See also setup instructions . All workspace operations are executed using a different URL: https://${TRE_ID}.${LOCATION}.cloudapp.azure.com/api/workspaces/${WORKSPACE_ID}/docs . See also instructions on installing base workspace . Updating the redirect URI If you get the following error: You should run: make auth Alternatively, in Azure Portal you can add the redirect URL to the App Registration. Under AAD, find App Registrations, and find the App Registration with the ID shown in the error message. There, go to Redirect URL and add the URL given to you by the error message (it will have a form of https://${TRE_ID}.westeurope.cloudapp.azure.com/api/docs/oauth2-redirect ). Troubleshooting Wrong docker image version If this happens, you will see a log similar to this: 2022-05-10T05:34:48.844Z ERROR - DockerApiException: Docker API responded with status code=NotFound, response={\"message\":\"manifest for tborisdevtreacr.azurecr.io/microsoft/azuretre/api:0.2.24 not found: manifest unknown: manifest tagged by \\\"0.2.24\\\" is not found\"} To fix, run make build-and-push-api from your branch and restart the instance. Investigating /api/health response The endpoint /api/health tracks health of not only API, but other components of the system too, and can help to narrow down any problems with your deployment: { \"services\" : [ { \"service\" : \"Cosmos DB\" , \"status\" : \"OK\" , \"message\" : \"\" }, { \"service\" : \"Service Bus\" , \"status\" : \"OK\" , \"message\" : \"\" }, { \"service\" : \"Resource Processor\" , \"status\" : \"Not OK\" , \"message\" : \"Resource Processor is not responding\" } ] } In this case, next step is to look at logs of Resource Processor. See also Resource Processor docs .","title":"API"},{"location":"tre-developers/api/#tre-api","text":"The TRE API is a service that users can interact with to request changes to workspaces e.g., to create, update, delete workspaces and workspace services inside each workspace. This page is a guide for a developer looking to make a change to the API and debug it.","title":"TRE API"},{"location":"tre-developers/api/#repository-folder-structure","text":"api_app \u251c\u2500\u2500 api - API implementation \u2502 \u251c\u2500\u2500 dependencies - Dependencies for routes definition \u2502 \u251c\u2500\u2500 errors - Definitions of error handlers \u2502 \u2514\u2500\u2500 routes - Web routes (API endpoints) \u2502 \u251c\u2500\u2500 core - Application configuration, startup events, logging \u2502 \u251c\u2500\u2500 db - Database related implementation \u2502 \u251c\u2500\u2500 migrations - Manually written alembic migrations \u2502 \u2514\u2500\u2500 repositories - All CRUD features \u2502 \u251c\u2500\u2500 models - Pydantic models for this application \u2502 \u251c\u2500\u2500 domain - Main models that are used almost everywhere \u2502 \u2514\u2500\u2500 schemas - Schemas for using in web routes \u2502 \u251c\u2500\u2500 resources - Strings that are used e.g., in web responses \u2502 \u251c\u2500\u2500 services - Logic that is not only CRUD related (authentication, logging, tracing, etc) \u2502 \u251c\u2500\u2500 tests_ma - Unit tests \u2502 \u2514\u2500\u2500 main.py - FastAPI application creation and configuration","title":"Repository folder structure"},{"location":"tre-developers/api/#unit-tests","text":"The unit tests are written with pytest and located in folder /api_app/tests_ma/ . Run all unit tests with the following command in the root folder of the repository: pytest --ignore=e2e_tests Please refer to a different guide on running E2E tests locally .","title":"Unit tests"},{"location":"tre-developers/api/#local-debugging","text":"To set up local debugging, first run (if you haven't done so already) az login make setup-local-debugging Next, go to \"Run and Debug\" panel in VSCode, and select TRE API. You will see a log similar to this: Now, you should be able to open Swagger UI for your local instance on http://localhost:8000/api/docs .","title":"Local debugging"},{"location":"tre-developers/api/#cloud-instance","text":"On Azure Portal, find an App Service instance named app-${TRE_ID} .","title":"Cloud instance"},{"location":"tre-developers/api/#api-logs-in-loganalytics","text":"To find logs in LogAnalytics, go to your resource group, then to LogAnalytics instance, which is named like log-${TRE_ID} . There, you can run a query like AppTraces | where AppRoleName == \"uvicorn\" | order by TimeGenerated desc","title":"API logs in LogAnalytics"},{"location":"tre-developers/api/#api-logs-using-deployment-center","text":"Check that the version you are debugging/troubleshooting is the same one deployed on the App Service. You can check this in Deployment Center, or follow the logs as generated by the container in the logs tabs.","title":"API logs using deployment center"},{"location":"tre-developers/api/#deploying-a-cloud-instance","text":"To deploy a new version of the API to your TRE deployment, do this: Update the version in api_app/_version.py Run make build-and-push-api make deploy-core","title":"Deploying a cloud instance"},{"location":"tre-developers/api/#enabling-debug-mode-on-the-api","text":"For security, the API is by default configured to not show detailed error messages and stack trace when an error occurs. You can enable debugging via one of the two ways: Set debug=true under developer_settings section in your config.yaml file (see []) To enable debugging on an already running instance: Go to App Service for the API and select Settings > Configuration . Click New Application Setting . in the new dialog box set Name=DEBUG and Value=true","title":"Enabling DEBUG mode on the API"},{"location":"tre-developers/api/#using-swagger-ui","text":"Swagger UI lets you send requests to the API. To send a request, click on the row with the request, then Try out , then Execute . See screenshot:","title":"Using Swagger UI"},{"location":"tre-developers/api/#authorization","text":"Swagger UI is accessible under https://${TRE_ID}.${LOCATION}.cloudapp.azure.com/api/docs . To start using it, click Authorize button, then click Authorize (leave the field client_secret empty). See screenshot: If you see an error message saying something like: The redirect URI 'https://tanyagts8.westeurope.cloudapp.azure.com/api/docs/oauth2-redirect' specified in the request does not match the redirect URIs configured for the application '558602a8-764a-453c-8efa-4dc3ddd61570'. Then you'll need to update the redirect URI (see below). Otherwise, after you sign in on Azure Portal, the lock icon on Authorize button should look \"locked\". Then you can start executing queries. See also setup instructions . All workspace operations are executed using a different URL: https://${TRE_ID}.${LOCATION}.cloudapp.azure.com/api/workspaces/${WORKSPACE_ID}/docs . See also instructions on installing base workspace .","title":"Authorization"},{"location":"tre-developers/api/#updating-the-redirect-uri","text":"If you get the following error: You should run: make auth Alternatively, in Azure Portal you can add the redirect URL to the App Registration. Under AAD, find App Registrations, and find the App Registration with the ID shown in the error message. There, go to Redirect URL and add the URL given to you by the error message (it will have a form of https://${TRE_ID}.westeurope.cloudapp.azure.com/api/docs/oauth2-redirect ).","title":"Updating the redirect URI"},{"location":"tre-developers/api/#troubleshooting","text":"","title":"Troubleshooting"},{"location":"tre-developers/api/#wrong-docker-image-version","text":"If this happens, you will see a log similar to this: 2022-05-10T05:34:48.844Z ERROR - DockerApiException: Docker API responded with status code=NotFound, response={\"message\":\"manifest for tborisdevtreacr.azurecr.io/microsoft/azuretre/api:0.2.24 not found: manifest unknown: manifest tagged by \\\"0.2.24\\\" is not found\"} To fix, run make build-and-push-api from your branch and restart the instance.","title":"Wrong docker image version"},{"location":"tre-developers/api/#investigating-apihealth-response","text":"The endpoint /api/health tracks health of not only API, but other components of the system too, and can help to narrow down any problems with your deployment: { \"services\" : [ { \"service\" : \"Cosmos DB\" , \"status\" : \"OK\" , \"message\" : \"\" }, { \"service\" : \"Service Bus\" , \"status\" : \"OK\" , \"message\" : \"\" }, { \"service\" : \"Resource Processor\" , \"status\" : \"Not OK\" , \"message\" : \"Resource Processor is not responding\" } ] } In this case, next step is to look at logs of Resource Processor. See also Resource Processor docs .","title":"Investigating /api/health response"},{"location":"tre-developers/end-to-end-tests/","text":"End-to-end (E2E) tests Prerequisites Authentication and Authorization configuration set up as noted here An Azure Tre deployed environment. Registering bundles to run End-to-end tests End-to-end tests depend on certain bundles to be registered within the TRE API. When End-to-end tests run in CI, they are registered as a prerequisite to running tests. When running tests locally, use the prepare-for-e2e Makefile target: make prepare-for-e2e Debugging the End-to-End tests Use the \"Run and Debug\" panel within Visual Studio Code, select \"E2E Extended\", \"E2E Smoke\" or \"E2E Performance\" in the drop down box and click play. This will copy config.yaml settings to /workspaces/AzureTRE/e2e_tests/.env for you which supplies your authentciation details This will also use /workspaces/AzureTRE/templates/core/private.env file for other values.","title":"End to End Tests"},{"location":"tre-developers/end-to-end-tests/#end-to-end-e2e-tests","text":"","title":"End-to-end (E2E) tests"},{"location":"tre-developers/end-to-end-tests/#prerequisites","text":"Authentication and Authorization configuration set up as noted here An Azure Tre deployed environment.","title":"Prerequisites"},{"location":"tre-developers/end-to-end-tests/#registering-bundles-to-run-end-to-end-tests","text":"End-to-end tests depend on certain bundles to be registered within the TRE API. When End-to-end tests run in CI, they are registered as a prerequisite to running tests. When running tests locally, use the prepare-for-e2e Makefile target: make prepare-for-e2e","title":"Registering bundles to run End-to-end tests"},{"location":"tre-developers/end-to-end-tests/#debugging-the-end-to-end-tests","text":"Use the \"Run and Debug\" panel within Visual Studio Code, select \"E2E Extended\", \"E2E Smoke\" or \"E2E Performance\" in the drop down box and click play. This will copy config.yaml settings to /workspaces/AzureTRE/e2e_tests/.env for you which supplies your authentciation details This will also use /workspaces/AzureTRE/templates/core/private.env file for other values.","title":"Debugging the End-to-End tests"},{"location":"tre-developers/letsencrypt/","text":"Letsencrypt Certain components of the TRE require the aquisition of a certificate via Letsencrypt to ensure secure HTTPS connections. In order to aquire these certificates, there must be a public facing endpoint which can be reached by Letsencrypt. As TREs are secured environments with very few publicly facing points, additional resources are required to ensure the certificate can be provisioned for the correct domain. The additional resources are as followed: Public IP provisioned in the same location as the web app that the certificate is intended for; this will also have a domain label which matches the web app name. Storage Account with a static web app. Application gateway to route traffic from the Public IP to the static web app The following diagram illustrated the flow of data between the resources: flowchart RL subgraph .dev Container direction TB A(letsencrypt process runs) end subgraph External direction TB B[letsencrypt authority] end subgraph TRE subgraph Core VNet C[Public IP <br/> Domain Label: < web-app-name > <br/> Endpoint: < web-app-name >.< location >.cloudapp.net] subgraph Storage Account D[SA Static Site] end end subgraph VNet E[Key Vault <br/> kv-< tre_id >] subgraph VM F[Web App] end G[Private DNS Zone < web-app-name >.< location >.cloudapp.net] end end A --> |1. Request to | B B --> |2. Attempts to hit | C C --> |3. App Gateway routes | D D --> |4. Responds | C C --> |5. Responds | B B --> |6. Acquires certificate | A A --> |7. Stores Certificate | E F --> |8. Pulls Certificate | E","title":"Letsencrypt"},{"location":"tre-developers/letsencrypt/#letsencrypt","text":"Certain components of the TRE require the aquisition of a certificate via Letsencrypt to ensure secure HTTPS connections. In order to aquire these certificates, there must be a public facing endpoint which can be reached by Letsencrypt. As TREs are secured environments with very few publicly facing points, additional resources are required to ensure the certificate can be provisioned for the correct domain. The additional resources are as followed: Public IP provisioned in the same location as the web app that the certificate is intended for; this will also have a domain label which matches the web app name. Storage Account with a static web app. Application gateway to route traffic from the Public IP to the static web app The following diagram illustrated the flow of data between the resources: flowchart RL subgraph .dev Container direction TB A(letsencrypt process runs) end subgraph External direction TB B[letsencrypt authority] end subgraph TRE subgraph Core VNet C[Public IP <br/> Domain Label: < web-app-name > <br/> Endpoint: < web-app-name >.< location >.cloudapp.net] subgraph Storage Account D[SA Static Site] end end subgraph VNet E[Key Vault <br/> kv-< tre_id >] subgraph VM F[Web App] end G[Private DNS Zone < web-app-name >.< location >.cloudapp.net] end end A --> |1. Request to | B B --> |2. Attempts to hit | C C --> |3. App Gateway routes | D D --> |4. Responds | C C --> |5. Responds | B B --> |6. Acquires certificate | A A --> |7. Stores Certificate | E F --> |8. Pulls Certificate | E","title":"Letsencrypt"},{"location":"tre-developers/release/","text":"How to release an AzureTRE version A release is created when enough changes have been made and the main branch is stable enough. The process follows these steps: Update CHANGELOG.md in a PR with the following: 1. Rename the top-most verion noted as unreleaed with the version number that makes sense. Note that you don't have to keep the one that is currently in the file as the version number chosen should reflect the changes made (major, minor, etc.) 1. Create a new section for the next-unreleaed version so that future changes will be placed there. 1. Run devops/scripts/list_versions.sh and include the output in the change log for the version you're about the release Merge the PR Create a GitHub Release 1. Go to https://github.com/microsoft/AzureTRE/releases/new 1. Click on Choose a tag and type a new one for you version. It should be in the form of v0.9.2 - note the \"v\" in the begining. 1. The release title should be just the version number \"0.9.2\" in the example above. 1. Copy the text from the CHANGELOG.md file and paste in the release description. 1. Include a final line with a link to the full changelog similar to this: Full Changelog : https://github.com/microsoft/AzureTRE/compare/v0.9.1...v0.9.2 Update AzureTRE-Deployment . The procedure may vary depending on the level of changes introduced in the new version but should include the following steps: 1. Update the tag used in devcontainer.json . 1. Rebuild the container. 1. Compare both .devcontainer and .github folders of the new release with the ones in the repo and make required updates so that only required difference exist. The comapre can be done with VSCode Compare Folders extension as you have both the old version (under to root folder) and the \"new\" one inside the AzureTRE symlink. 1. With all changes made, rebuild the container to verify it's working and that AzureTRE folder has been populated correctly.","title":"Releases"},{"location":"tre-developers/release/#how-to-release-an-azuretre-version","text":"A release is created when enough changes have been made and the main branch is stable enough. The process follows these steps: Update CHANGELOG.md in a PR with the following: 1. Rename the top-most verion noted as unreleaed with the version number that makes sense. Note that you don't have to keep the one that is currently in the file as the version number chosen should reflect the changes made (major, minor, etc.) 1. Create a new section for the next-unreleaed version so that future changes will be placed there. 1. Run devops/scripts/list_versions.sh and include the output in the change log for the version you're about the release Merge the PR Create a GitHub Release 1. Go to https://github.com/microsoft/AzureTRE/releases/new 1. Click on Choose a tag and type a new one for you version. It should be in the form of v0.9.2 - note the \"v\" in the begining. 1. The release title should be just the version number \"0.9.2\" in the example above. 1. Copy the text from the CHANGELOG.md file and paste in the release description. 1. Include a final line with a link to the full changelog similar to this: Full Changelog : https://github.com/microsoft/AzureTRE/compare/v0.9.1...v0.9.2 Update AzureTRE-Deployment . The procedure may vary depending on the level of changes introduced in the new version but should include the following steps: 1. Update the tag used in devcontainer.json . 1. Rebuild the container. 1. Compare both .devcontainer and .github folders of the new release with the ones in the repo and make required updates so that only required difference exist. The comapre can be done with VSCode Compare Folders extension as you have both the old version (under to root folder) and the \"new\" one inside the AzureTRE symlink. 1. With all changes made, rebuild the container to verify it's working and that AzureTRE folder has been populated correctly.","title":"How to release an AzureTRE version"},{"location":"tre-developers/resource-processor/","text":"Resource Processor (VMSS) Resource Processor is the Azure TRE component automating Porter bundle deployments. It hosts Porter and its dependencies. This page is a guide for a developer looking to make a change to the Resource Processor and debug it. Overview The logic in Resource Processor is written in Python. The Resource Processor implementation is located in resource_processor folder of the repository. Read how a workspace is provisioned using Porter Local debugging To set up local debugging, first run, if you haven't done so already (make sure ENABLE_LOCAL_DEBUGGING is set to true in your .env file): az login make setup-local-debugging This will allowlist your local IP against Azure resources and create a Service Principal for the Resource Processor. Next, disable the existing Resource Processor from running in your deployment. The easiest way to do this is to stop the VM scale set: Now, go to \"Run and Debug\" panel in VSCode, and select Resource Processor. Info If you get a credential error when trying to connect to Service Bus, make sure you've authenticated in the AZ CLI first as it uses your local credentials. Info If you get an error similar to Environment variable 'ARM_CLIENT_ID' is not set correctly , make sure you have ran make setup-local-debugging You can use an API instance deployed in your environment to create deployment requests, and debug your locally running Resource Processor. For more information on how to use API, refer to API documentation . Cloud instance On Azure Portal, find an Virtual VM scale set with a name vmss-rp-porter-${TRE_ID} . Resource Processor logs in LogAnalytics To find logs in LogAnalytics, go to your resource group, then to LogAnalytics instance, which is named like log-${TRE_ID} . There, you can run a query like AppTraces | where AppRoleName == \"runner.py\" | order by TimeGenerated desc SSH-ing to the instance The processor runs in a VNET, and you cannot connect to it directly. To SSH to this instance, use Bastion. Find a keyvault with a name kv-${TRE_ID} in your resource group. Copy a secret named resource-processor-vmss-password If you don't have permissions to see the secret, add yourself to the Access Policy of this keyvault with a permission to read secrets: 1. Connect to the instance using Bastion. Use the username adminuser and the password you just copied. Getting container logs SSH into the Resource Processor VM as described above Check the status of the container using sudo docker ps If you see nothing (and the container was pulled) then the processor has either not started yet or it has crashed. Get the logs from the container using sudo docker logs <container_id> command. Starting container manually Find the runner_image:tag by running docker ps Execute the following command from the root (/) of the file system sudo docker run -v /var/run/docker.sock:/var/run/docker.sock --env-file .env --name resource_processor_vmss_porter_debug [runner_image:tag] Info If you start a container manually you will probably want to install software, for example, an editor. However, the firewall blocks all ingress traffic, so you cannot run sudo apt update . You need to add an override rule in the firewall to allow the traffic. Caution Remember to remove this rule when debugging is done. Troubleshooting No container logs on the instance If you don't see container logs, you should check the status of cloud-init which is used to bootstrap the machine with docker and start the processor. Log files for cloud init are: /var/log/cloud-init.log /var/log/cloud-init-output.log If the Docker container is pulled as shown in logs then the resource processor should start. 1. Check the status of all Docker processes using docker ps -a which should show you if the container terminated prematurely. Implementation details Porter Azure TRE needed a solution for implementing and deploying workspaces and workspace services with the following properties: Means for packaging and versioning workspaces and workspace services Providing unified structure for deployment definitions (scripts, pipelines) so that the process can be easily automated Solid developer experience - easy to use and learn Porter meets all these requirements well. Porter packages cloud application into a versioned, self-contained Docker container called a Porter bundle. CNAB spec defines actions that Porter implements : install, upgrade and uninstall . The developer has practically complete freedom on how to implement logic for these actions. The deployment pipeline definition is created in YAML. The YAML file is called Porter manifest and in additon to the actions, it contains the name, version, description of the bundle and defines the input parameters, possible credentials and output. Furthermore, Porter provides a set of mixins - analogous to the concrete actions in GitHub workflows and tasks in Azure DevOps pipelines - which simplify and reduce the development cost when implementing deployment logic. For example, Terraform mixin installs the required tools and provides a clean step in the pipeline to execute Terraform deployments. Exec mixin allows running any command or script; especially useful, if no suitable mixin for a specific technology is available. Implementing custom mixins is possible too. Porter Azure plugin Resource Processor uses Porter Azure plugin to store Porter data in TRE management storage account. The storage table, named porter , is created during the bootstrapping phase of TRE deployment. The /resource_processor/run.sh script generates a config.toml file in Porter home folder to enable the Azure plugin when the image is started. Porter bundle inputs When Porter runs bundle actions, it passes input parameters. Full set of inputs that Porter passes can be found in config.py . Info Note that Resource Processor does not pass any location-related attributes when running bundle actions. Instead, a location attribute is passed from the API. This is so that different TRE resources could be potentially deployed to different regions.","title":"Resource Processor"},{"location":"tre-developers/resource-processor/#resource-processor-vmss","text":"Resource Processor is the Azure TRE component automating Porter bundle deployments. It hosts Porter and its dependencies. This page is a guide for a developer looking to make a change to the Resource Processor and debug it.","title":"Resource Processor (VMSS)"},{"location":"tre-developers/resource-processor/#overview","text":"The logic in Resource Processor is written in Python. The Resource Processor implementation is located in resource_processor folder of the repository. Read how a workspace is provisioned using Porter","title":"Overview"},{"location":"tre-developers/resource-processor/#local-debugging","text":"To set up local debugging, first run, if you haven't done so already (make sure ENABLE_LOCAL_DEBUGGING is set to true in your .env file): az login make setup-local-debugging This will allowlist your local IP against Azure resources and create a Service Principal for the Resource Processor. Next, disable the existing Resource Processor from running in your deployment. The easiest way to do this is to stop the VM scale set: Now, go to \"Run and Debug\" panel in VSCode, and select Resource Processor. Info If you get a credential error when trying to connect to Service Bus, make sure you've authenticated in the AZ CLI first as it uses your local credentials. Info If you get an error similar to Environment variable 'ARM_CLIENT_ID' is not set correctly , make sure you have ran make setup-local-debugging You can use an API instance deployed in your environment to create deployment requests, and debug your locally running Resource Processor. For more information on how to use API, refer to API documentation .","title":"Local debugging"},{"location":"tre-developers/resource-processor/#cloud-instance","text":"On Azure Portal, find an Virtual VM scale set with a name vmss-rp-porter-${TRE_ID} .","title":"Cloud instance"},{"location":"tre-developers/resource-processor/#resource-processor-logs-in-loganalytics","text":"To find logs in LogAnalytics, go to your resource group, then to LogAnalytics instance, which is named like log-${TRE_ID} . There, you can run a query like AppTraces | where AppRoleName == \"runner.py\" | order by TimeGenerated desc","title":"Resource Processor logs in LogAnalytics"},{"location":"tre-developers/resource-processor/#ssh-ing-to-the-instance","text":"The processor runs in a VNET, and you cannot connect to it directly. To SSH to this instance, use Bastion. Find a keyvault with a name kv-${TRE_ID} in your resource group. Copy a secret named resource-processor-vmss-password If you don't have permissions to see the secret, add yourself to the Access Policy of this keyvault with a permission to read secrets: 1. Connect to the instance using Bastion. Use the username adminuser and the password you just copied.","title":"SSH-ing to the instance"},{"location":"tre-developers/resource-processor/#getting-container-logs","text":"SSH into the Resource Processor VM as described above Check the status of the container using sudo docker ps If you see nothing (and the container was pulled) then the processor has either not started yet or it has crashed. Get the logs from the container using sudo docker logs <container_id> command.","title":"Getting container logs"},{"location":"tre-developers/resource-processor/#starting-container-manually","text":"Find the runner_image:tag by running docker ps Execute the following command from the root (/) of the file system sudo docker run -v /var/run/docker.sock:/var/run/docker.sock --env-file .env --name resource_processor_vmss_porter_debug [runner_image:tag] Info If you start a container manually you will probably want to install software, for example, an editor. However, the firewall blocks all ingress traffic, so you cannot run sudo apt update . You need to add an override rule in the firewall to allow the traffic. Caution Remember to remove this rule when debugging is done.","title":"Starting container manually"},{"location":"tre-developers/resource-processor/#troubleshooting","text":"","title":"Troubleshooting"},{"location":"tre-developers/resource-processor/#no-container-logs-on-the-instance","text":"If you don't see container logs, you should check the status of cloud-init which is used to bootstrap the machine with docker and start the processor. Log files for cloud init are: /var/log/cloud-init.log /var/log/cloud-init-output.log If the Docker container is pulled as shown in logs then the resource processor should start. 1. Check the status of all Docker processes using docker ps -a which should show you if the container terminated prematurely.","title":"No container logs on the instance"},{"location":"tre-developers/resource-processor/#implementation-details","text":"","title":"Implementation details"},{"location":"tre-developers/resource-processor/#porter","text":"Azure TRE needed a solution for implementing and deploying workspaces and workspace services with the following properties: Means for packaging and versioning workspaces and workspace services Providing unified structure for deployment definitions (scripts, pipelines) so that the process can be easily automated Solid developer experience - easy to use and learn Porter meets all these requirements well. Porter packages cloud application into a versioned, self-contained Docker container called a Porter bundle. CNAB spec defines actions that Porter implements : install, upgrade and uninstall . The developer has practically complete freedom on how to implement logic for these actions. The deployment pipeline definition is created in YAML. The YAML file is called Porter manifest and in additon to the actions, it contains the name, version, description of the bundle and defines the input parameters, possible credentials and output. Furthermore, Porter provides a set of mixins - analogous to the concrete actions in GitHub workflows and tasks in Azure DevOps pipelines - which simplify and reduce the development cost when implementing deployment logic. For example, Terraform mixin installs the required tools and provides a clean step in the pipeline to execute Terraform deployments. Exec mixin allows running any command or script; especially useful, if no suitable mixin for a specific technology is available. Implementing custom mixins is possible too.","title":"Porter"},{"location":"tre-developers/resource-processor/#porter-azure-plugin","text":"Resource Processor uses Porter Azure plugin to store Porter data in TRE management storage account. The storage table, named porter , is created during the bootstrapping phase of TRE deployment. The /resource_processor/run.sh script generates a config.toml file in Porter home folder to enable the Azure plugin when the image is started.","title":"Porter Azure plugin"},{"location":"tre-developers/resource-processor/#porter-bundle-inputs","text":"When Porter runs bundle actions, it passes input parameters. Full set of inputs that Porter passes can be found in config.py . Info Note that Resource Processor does not pass any location-related attributes when running bundle actions. Instead, a location attribute is passed from the API. This is so that different TRE resources could be potentially deployed to different regions.","title":"Porter bundle inputs"},{"location":"tre-developers/ui/","text":"TRE Web User Interface This project contains a React-based web UI which covers the core aspects of a TRE, for researchers and workspace owners. Chosen UI Stack + Components The UI is built upon several popular web frameworks: - React v18 (created via create-react-app, with all build configurations left as defaults) - Typescript - React Router v6 for client side routing - Fluent UI Fluent UI Docs - MSAL v2: AAD authentication msal-react docs Folder structure ui \u251c\u2500\u2500 app - Root of the React application \u2502 \u251c\u2500\u2500 build - Location of compiled files after build process \u2502 \u251c\u2500\u2500 public - Location for static HTML to bootstrap the app \u2502 \u251c\u2500\u2500 src - All .tsx components \u2502 \u251c\u2500\u2500 index.tsx - Entry point for the app \u2502 \u251c\u2500\u2500 App.tsx - Wrapper and routing for the app \u2502 \u2514\u2500\u2500 config.source.json - JSON file to be used as source file for autogenerated config AuthN + AuthZ For further details on the auth setup, see Auth . As stated above, AAD is used for Authentication and Authorization. There are 3 AAD apps involved here: - TRE UX . This is the app that the user authenticates against. Once authenticated, the client will request an access token for the TRE Api . - TRE Api . In the access token response from this app we get the user's role membership for TRE-level roles ( TREAdmin / TREUser ). Based on these role memberships, aspects of the UI will be made available. If the user is in a TREAdmin role, they will see buttons to create workspaces for instance. When the user navigates into a Workspace, the client will request an access token for that Workspace App . - Workspace App(s) . Each TRE workspace will have a workspace app registration. The Application Id URI for each workspace app is stored in the Workspace resource object in Cosmos, and the client uses this URI to gain an access token for that particular workspace. Workspace app registrations may be reused across multiple workspaces in development scenarios. From this access token we can find the Workspace-level roles the user is in ( WorkspaceOwner / WorkspaceResearcher ). These are in turn used to show/hide features of the UI. React Contexts The React Context API is a clean way to handle a limited amount of global state, and is used for a few scenarios in this project: - TRE Roles Context: A context provides details of the base TRE roles a user is in, which can be consumed anywhere throughout the app - Workspace Context: Tracks the currently selected Workspace, and the roles the user is in for that Workspace. This context is used for nested components to be able to authenticate against the correct AAD App via workspaceCtx.workspaceApplicationIdURI . - Create Form Context: A context to control the Create / Update form behaviour. - Notifications Context: Tracks all the in-progress operations currently running. For each operation, the Notifications panel also uses this context to broadcast Component 'actions' which are subscribed to by downstream components. This way, a resource component does not have to track it's own changes, and can be 'told' by the Notifications Context whether it should refresh / lock etc. Custom Hooks Hooks are used throughout the project, and a couple of custom hooks were written to abstract common logic: - useAuthApiCall : A way to encapsulate an authenticated fetch request and provide a simple interface for downstream components to use. - useComponentManager : This hook subscribes to changes broadcast from the Notifications panel, via the context. A component can simply add this hook to start subscribing to changes and react accordingly. Deployment The UI is deployed as part of the tre-deploy make target (unless you set deploy_ui=false under tre defaults section in your config.yaml file). To re-deploy just the UI (after an initial deploy), run make build-and-deploy-ui from the root of the dev container. This will: - Use the environment variables from your deployment to create a config.json file for the UI - Build the source code, via yarn build - Deploy the code to Azure blob storage, where it will be statically served behind the App Gateway that also fronts the APi.","title":"UI"},{"location":"tre-developers/ui/#tre-web-user-interface","text":"This project contains a React-based web UI which covers the core aspects of a TRE, for researchers and workspace owners.","title":"TRE Web User Interface"},{"location":"tre-developers/ui/#chosen-ui-stack-components","text":"The UI is built upon several popular web frameworks: - React v18 (created via create-react-app, with all build configurations left as defaults) - Typescript - React Router v6 for client side routing - Fluent UI Fluent UI Docs - MSAL v2: AAD authentication msal-react docs","title":"Chosen UI Stack + Components"},{"location":"tre-developers/ui/#folder-structure","text":"ui \u251c\u2500\u2500 app - Root of the React application \u2502 \u251c\u2500\u2500 build - Location of compiled files after build process \u2502 \u251c\u2500\u2500 public - Location for static HTML to bootstrap the app \u2502 \u251c\u2500\u2500 src - All .tsx components \u2502 \u251c\u2500\u2500 index.tsx - Entry point for the app \u2502 \u251c\u2500\u2500 App.tsx - Wrapper and routing for the app \u2502 \u2514\u2500\u2500 config.source.json - JSON file to be used as source file for autogenerated config","title":"Folder structure"},{"location":"tre-developers/ui/#authn-authz","text":"For further details on the auth setup, see Auth . As stated above, AAD is used for Authentication and Authorization. There are 3 AAD apps involved here: - TRE UX . This is the app that the user authenticates against. Once authenticated, the client will request an access token for the TRE Api . - TRE Api . In the access token response from this app we get the user's role membership for TRE-level roles ( TREAdmin / TREUser ). Based on these role memberships, aspects of the UI will be made available. If the user is in a TREAdmin role, they will see buttons to create workspaces for instance. When the user navigates into a Workspace, the client will request an access token for that Workspace App . - Workspace App(s) . Each TRE workspace will have a workspace app registration. The Application Id URI for each workspace app is stored in the Workspace resource object in Cosmos, and the client uses this URI to gain an access token for that particular workspace. Workspace app registrations may be reused across multiple workspaces in development scenarios. From this access token we can find the Workspace-level roles the user is in ( WorkspaceOwner / WorkspaceResearcher ). These are in turn used to show/hide features of the UI.","title":"AuthN + AuthZ"},{"location":"tre-developers/ui/#react-contexts","text":"The React Context API is a clean way to handle a limited amount of global state, and is used for a few scenarios in this project: - TRE Roles Context: A context provides details of the base TRE roles a user is in, which can be consumed anywhere throughout the app - Workspace Context: Tracks the currently selected Workspace, and the roles the user is in for that Workspace. This context is used for nested components to be able to authenticate against the correct AAD App via workspaceCtx.workspaceApplicationIdURI . - Create Form Context: A context to control the Create / Update form behaviour. - Notifications Context: Tracks all the in-progress operations currently running. For each operation, the Notifications panel also uses this context to broadcast Component 'actions' which are subscribed to by downstream components. This way, a resource component does not have to track it's own changes, and can be 'told' by the Notifications Context whether it should refresh / lock etc.","title":"React Contexts"},{"location":"tre-developers/ui/#custom-hooks","text":"Hooks are used throughout the project, and a couple of custom hooks were written to abstract common logic: - useAuthApiCall : A way to encapsulate an authenticated fetch request and provide a simple interface for downstream components to use. - useComponentManager : This hook subscribes to changes broadcast from the Notifications panel, via the context. A component can simply add this hook to start subscribing to changes and react accordingly.","title":"Custom Hooks"},{"location":"tre-developers/ui/#deployment","text":"The UI is deployed as part of the tre-deploy make target (unless you set deploy_ui=false under tre defaults section in your config.yaml file). To re-deploy just the UI (after an initial deploy), run make build-and-deploy-ui from the root of the dev container. This will: - Use the environment variables from your deployment to create a config.json file for the UI - Build the source code, via yarn build - Deploy the code to Azure blob storage, where it will be statically served behind the App Gateway that also fronts the APi.","title":"Deployment"},{"location":"tre-templates/","text":"Templates and Services Info Coming soon We're working to improve our documentation, and fill in some gaps. Unfortunately, this particular page is one of the gaps we're looking to fill and isn't yet available. How to Contribute to our Documentation If you have any comments or suggestions about our documentation then you can visit our GitHub project and either raise a new issue, or comment on one of the existing ones. You can find our existing documentation issues on GitHub by clicking on the link below: Existing Documentation Issues Or, you can raise a new issue by clicking on this link: Report an Issue or Make a Suggestion Thank you for your patience and support!","title":"Templates and Services"},{"location":"tre-templates/#templates-and-services","text":"Info Coming soon We're working to improve our documentation, and fill in some gaps. Unfortunately, this particular page is one of the gaps we're looking to fill and isn't yet available.","title":"Templates and Services"},{"location":"tre-templates/#how-to-contribute-to-our-documentation","text":"If you have any comments or suggestions about our documentation then you can visit our GitHub project and either raise a new issue, or comment on one of the existing ones. You can find our existing documentation issues on GitHub by clicking on the link below: Existing Documentation Issues Or, you can raise a new issue by clicking on this link: Report an Issue or Make a Suggestion Thank you for your patience and support!","title":"How to Contribute to our Documentation"},{"location":"tre-templates/pipeline-templates/overview/","text":"Pipeline Templates Occasionally there will be a need for the deployment / update of one resource to affect a change in another. This section outlines how that can be achieved with Pipeline Templates. Overview A pipeline template is an optional pipeline: {} block that can be added to the top level of a resource schema document. It allows a template developer to define actions to run against other resources before and after the primary resource is deployed. Example Consider the following template_schema.json : { \"$schema\" : \"http://json-schema.org/draft-07/schema\" , \"$id\" : \"https://github.com/microsoft/AzureTRE/templates/workspace_services/guacamole/user_resources/guacamole-dev-vm/template_schema.json\" , ... \"properties\" : { ... }, \"pipeline\" : { \"install\" : [ { \"stepId\" : \"6d2d7eb7-984e-4330-bd3c-c7ec98658402\" , \"stepTitle\" : \"Update the firewall name\" , \"resourceTemplateName\" : \"tre-shared-service-firewall\" , \"resourceType\" : \"shared_service\" , \"resourceAction\" : \"upgrade\" , \"properties\" : [ { \"name\" : \"display_name\" , \"type\" : \"string\" , \"value\" : \"A new name here!\" }] }, { \"stepId\" : \"main\" }, { \"stepId\" : \"2fe8a6a7-2c27-4c49-8773-127df8a48b4e\" , ... } ] } } When a user deploys this resource, the API will read the install: [] array within the pipeline: {} block, and will: - Orchestrate the upgrade of the tre-shared-service-firewall , changing the display_name property to A new name here! . - Run the main (primary resource) install - Complete the next step A single Operation document will be used to keep track of which steps in the deployment chain have completed. Current Limitations This feature is undergoing active development, and is currently limited in the following ways: - Only statically addressable resources can be referred to - shared_services , as these are singletons and can be referenced by a template name. - Only the upgrade action for each secondary resource is supported. Support for install / uninstall of secondary resources is planned. - No current planned support for customActions .","title":"Overview"},{"location":"tre-templates/pipeline-templates/overview/#pipeline-templates","text":"Occasionally there will be a need for the deployment / update of one resource to affect a change in another. This section outlines how that can be achieved with Pipeline Templates.","title":"Pipeline Templates"},{"location":"tre-templates/pipeline-templates/overview/#overview","text":"A pipeline template is an optional pipeline: {} block that can be added to the top level of a resource schema document. It allows a template developer to define actions to run against other resources before and after the primary resource is deployed.","title":"Overview"},{"location":"tre-templates/pipeline-templates/overview/#example","text":"Consider the following template_schema.json : { \"$schema\" : \"http://json-schema.org/draft-07/schema\" , \"$id\" : \"https://github.com/microsoft/AzureTRE/templates/workspace_services/guacamole/user_resources/guacamole-dev-vm/template_schema.json\" , ... \"properties\" : { ... }, \"pipeline\" : { \"install\" : [ { \"stepId\" : \"6d2d7eb7-984e-4330-bd3c-c7ec98658402\" , \"stepTitle\" : \"Update the firewall name\" , \"resourceTemplateName\" : \"tre-shared-service-firewall\" , \"resourceType\" : \"shared_service\" , \"resourceAction\" : \"upgrade\" , \"properties\" : [ { \"name\" : \"display_name\" , \"type\" : \"string\" , \"value\" : \"A new name here!\" }] }, { \"stepId\" : \"main\" }, { \"stepId\" : \"2fe8a6a7-2c27-4c49-8773-127df8a48b4e\" , ... } ] } } When a user deploys this resource, the API will read the install: [] array within the pipeline: {} block, and will: - Orchestrate the upgrade of the tre-shared-service-firewall , changing the display_name property to A new name here! . - Run the main (primary resource) install - Complete the next step A single Operation document will be used to keep track of which steps in the deployment chain have completed.","title":"Example"},{"location":"tre-templates/pipeline-templates/overview/#current-limitations","text":"This feature is undergoing active development, and is currently limited in the following ways: - Only statically addressable resources can be referred to - shared_services , as these are singletons and can be referenced by a template name. - Only the upgrade action for each secondary resource is supported. Support for install / uninstall of secondary resources is planned. - No current planned support for customActions .","title":"Current Limitations"},{"location":"tre-templates/pipeline-templates/pipeline-schema/","text":"Pipeline Template Schema This document will help you write a valid pipeline: {} block in your template. For a working example, see ./templates/shared-services/sonatype-nexus/template_schema.json . Schema \"pipeline\" : { \"install\" : [ // <-- [install | upgrade | uninstall] { \"stepId\" : \"a unique string value here\" , \"stepTitle\" : \"Friendly description of the step here - will be displayed in the UI\" , \"resourceTemplateName\" : \"name of the resource template to update\" , // only required for shared_service targets \"resourceType\" : \"shared_service\" , // [ shared_service | user_resource | workspace_service | workspace ] \"resourceAction\" : \"upgrade\" , // <-- currently only upgrade supported \"properties\" : [ { \"name\" : \"display_name\" , \"type\" : \"string\" , \"value\" : \"A new name here!\" }] }, { \"stepId\" : \"main\" // <-- deployment of the VM resource }, Substituting Resource Property Values It's possible to refer to properties from the primary resource (the resource that triggered this pipeline) in the template steps. The values will be substituted in at runtime. The syntax is {{ resource.propertyName }} . For example: \"{{ resource.properties.display_name }}\" . Example pipeline in template_schema.json : The below example references 2 properties from the primary resource to be used in updating the firewall shared service. \"pipeline\" : { \"upgrade\" : [ { \"stepId\" : \"1234567-87654-2345-6543\" , \"stepTitle\" : \"Update a firewall rule\" , \"resourceTemplateName\" : \"tre-shared-service-firewall\" , \"resourceType\" : \"shared_service\" , \"resourceAction\" : \"upgrade\" , \"arraySubstitutionAction\" : \"replace\" , // <-- [append | remove | replace] \"arrayMatchField\" : \"name\" , // <-- name of the field in the array object to match on, for remove / replace \"properties\" : [ { \"name\" : \"rule_collections\" , \"type\" : \"array\" , // <-- More on array types below \"value\" : { // <-- value can be string or object \"name\" : \"my-firewall-rule-collection\" , \"action\" : \"Allow\" , \"rules\" : [ { \"name\" : \"my-rules\" , \"target_fqdns\" : \"{{ resource.properties.fqdns_list }}\" , \"source_addresses\" : \"{{ resource.properties.address_prefixes }}\" } } }] }, Working with Properties Containing Arrays It's possible that a resource property would actually be an array. As an example, the firewall shared service has the rule_collections property. This single property contains an array of objects. Since the values inside this array may have been sourced from different resources, it's important to leave other values in tact when modifying the property. To do so, the arraySubstitutionAction field supports the following values: - append - just append this object into the array - replace - find this object in the array (using the arrayMatchField value), and replace it with this value - remove - remove this property from the array (useful for uninstall actions) Notes Each step is executed in serial, in the order defined in the template Theoretically any number of steps could be created A step with step_id of main represents where in the chain the primary resource will get deployed. It is possible to omit this step altogether, and not touch the primary resource at all.","title":"Pipeline Schema"},{"location":"tre-templates/pipeline-templates/pipeline-schema/#pipeline-template-schema","text":"This document will help you write a valid pipeline: {} block in your template. For a working example, see ./templates/shared-services/sonatype-nexus/template_schema.json .","title":"Pipeline Template Schema"},{"location":"tre-templates/pipeline-templates/pipeline-schema/#schema","text":"\"pipeline\" : { \"install\" : [ // <-- [install | upgrade | uninstall] { \"stepId\" : \"a unique string value here\" , \"stepTitle\" : \"Friendly description of the step here - will be displayed in the UI\" , \"resourceTemplateName\" : \"name of the resource template to update\" , // only required for shared_service targets \"resourceType\" : \"shared_service\" , // [ shared_service | user_resource | workspace_service | workspace ] \"resourceAction\" : \"upgrade\" , // <-- currently only upgrade supported \"properties\" : [ { \"name\" : \"display_name\" , \"type\" : \"string\" , \"value\" : \"A new name here!\" }] }, { \"stepId\" : \"main\" // <-- deployment of the VM resource },","title":"Schema"},{"location":"tre-templates/pipeline-templates/pipeline-schema/#substituting-resource-property-values","text":"It's possible to refer to properties from the primary resource (the resource that triggered this pipeline) in the template steps. The values will be substituted in at runtime. The syntax is {{ resource.propertyName }} . For example: \"{{ resource.properties.display_name }}\" . Example pipeline in template_schema.json : The below example references 2 properties from the primary resource to be used in updating the firewall shared service. \"pipeline\" : { \"upgrade\" : [ { \"stepId\" : \"1234567-87654-2345-6543\" , \"stepTitle\" : \"Update a firewall rule\" , \"resourceTemplateName\" : \"tre-shared-service-firewall\" , \"resourceType\" : \"shared_service\" , \"resourceAction\" : \"upgrade\" , \"arraySubstitutionAction\" : \"replace\" , // <-- [append | remove | replace] \"arrayMatchField\" : \"name\" , // <-- name of the field in the array object to match on, for remove / replace \"properties\" : [ { \"name\" : \"rule_collections\" , \"type\" : \"array\" , // <-- More on array types below \"value\" : { // <-- value can be string or object \"name\" : \"my-firewall-rule-collection\" , \"action\" : \"Allow\" , \"rules\" : [ { \"name\" : \"my-rules\" , \"target_fqdns\" : \"{{ resource.properties.fqdns_list }}\" , \"source_addresses\" : \"{{ resource.properties.address_prefixes }}\" } } }] },","title":"Substituting Resource Property Values"},{"location":"tre-templates/pipeline-templates/pipeline-schema/#working-with-properties-containing-arrays","text":"It's possible that a resource property would actually be an array. As an example, the firewall shared service has the rule_collections property. This single property contains an array of objects. Since the values inside this array may have been sourced from different resources, it's important to leave other values in tact when modifying the property. To do so, the arraySubstitutionAction field supports the following values: - append - just append this object into the array - replace - find this object in the array (using the arrayMatchField value), and replace it with this value - remove - remove this property from the array (useful for uninstall actions)","title":"Working with Properties Containing Arrays"},{"location":"tre-templates/pipeline-templates/pipeline-schema/#notes","text":"Each step is executed in serial, in the order defined in the template Theoretically any number of steps could be created A step with step_id of main represents where in the chain the primary resource will get deployed. It is possible to omit this step altogether, and not touch the primary resource at all.","title":"Notes"},{"location":"tre-templates/shared-services/airlock-notifier/","text":"Airlock Notifications Shared Service This shared service connects to the Airlock's notification event grid and send emails to the researchers/ws owners upon Airlock requests changes. Development and modification This service was built with extensibility and modification in mind, since each organization might have different messaging platform and preferences. From that reason, and for low-code development, Airlock notification service (or Airlock Notifier) is defined in an Azure Logic App workflow. Editing the workflow can be done through the Azure Portal, or with the Azure Logic Apps (Standard) Visual Studio Code extension . In this repository, you will find that as the default, the email is sent using the Logic App SMTP connector . Since the connector is 'Managed', your environment or firewall must allow access for the outbound IP addresses used by these connectors in your datacenter region. In the future, the SMTP connection should transition into a 'Built-in connector' , thus running in the same cluster as the Azure Logic Apps host runtime, and using virtual network (VNet) integration capabilities to access resources over a private network. As an alternative to the SMTP connector, you can modify the Logic app to use other email and messaging platforms as connectors, like Office 365 , Outlook.com , MailChimp , Mandrill .","title":"Airlock Notifier"},{"location":"tre-templates/shared-services/airlock-notifier/#airlock-notifications-shared-service","text":"This shared service connects to the Airlock's notification event grid and send emails to the researchers/ws owners upon Airlock requests changes.","title":"Airlock Notifications Shared Service"},{"location":"tre-templates/shared-services/airlock-notifier/#development-and-modification","text":"This service was built with extensibility and modification in mind, since each organization might have different messaging platform and preferences. From that reason, and for low-code development, Airlock notification service (or Airlock Notifier) is defined in an Azure Logic App workflow. Editing the workflow can be done through the Azure Portal, or with the Azure Logic Apps (Standard) Visual Studio Code extension . In this repository, you will find that as the default, the email is sent using the Logic App SMTP connector . Since the connector is 'Managed', your environment or firewall must allow access for the outbound IP addresses used by these connectors in your datacenter region. In the future, the SMTP connection should transition into a 'Built-in connector' , thus running in the same cluster as the Azure Logic Apps host runtime, and using virtual network (VNet) integration capabilities to access resources over a private network. As an alternative to the SMTP connector, you can modify the Logic app to use other email and messaging platforms as connectors, like Office 365 , Outlook.com , MailChimp , Mandrill .","title":"Development and modification"},{"location":"tre-templates/shared-services/cyclecloud/","text":"Azure CycleCloud Shared Service Azure CycleCloud is an enterprise-friendly tool for orchestrating and managing High Performance Computing (HPC) environments on Azure. This shared service deploys a single CycleCloud server, which can be used to by a TRE Administrator to create and manage multiple HPC clusters. Used \"as is\", this shared service is only appropriate for proof of concept work and small projects, however can be used as a starting point for more advanced scenarios. Using the CycleCloud cluster properties the TRE Administrator can choose which virtual network the cluster will be deployed into, and hence the workspace the cluster can be accessed from. At present there is no self service cluster creation for research teams, and as such costs are not attributed to individual workspace however this could be added in the future, and is tracked in this issue https://github.com/microsoft/AzureTRE/issues/2230 . Deployment and Configuration The CycleCloud shared service template needs registering with the TRE as per <../../tre-admins/registering-templates/> The templates can be found at templates/shared_services/cyclecloud . Prior to deploying the CycleCloud server, the license terms for any Azure VM marketplace images used by CycleCloud must be accepted. This can be done by running the following command while logged into the Azure CLI: az vm image terms accept --urn azurecyclecloud:azure-cyclecloud:cyclecloud8:latest az vm image terms accept --urn almalinux:almalinux-hpc:8_5-hpc:latest Deploy the CycleCloud server using UI or API. To connect to the CycleCloud server, the TRE Administrator must connect to the CycleCloud server from the administration jumpbox. Use Azure Bastion to connect to the jumpbox a with the username admin and the select the password located in your core KeyVault. Connect to the CycleCloud server at the URL: https://cyclecloud-{TRE_ID}.{LOCATION}.cloudapp.azure.com/ . Provide a name for the cyclecloud server instance. -Review the terms and conditions and hit next. Provide your user details, including SSH key Hit Done, and wait for the add subscription dialog. Select the region your TRE is deployed into, leave the resource group as the default <Create New Per Cluster> and select the storage account beginning stgcc . This should look similar to: Hit Save, and then \"Back to Clusters\" Create a Cluster Before you start creating the cluster retrieve the last 4 digits of the workspace ID that you want to deploy the cluster into. Create a user in CycleCloud as per https://docs.microsoft.com/en-us/azure/cyclecloud/concepts/user-management?view=cyclecloud-8#adding-new-users-to-cyclecloud . The SSH key for the user will need to be created within the workspace and public key exporting. We suggest using the 4 digits retrieved in step 1 as part of the user account. Select your cluster type, we have tested Slurm and Grid Engine using the methods documented here. Give the cluster a name - again we suggest using the last 4 digits of the workspace ID as part of the name.Click Next. Select your required settings. In the Subnet ID box, choose the ServicesSubnet in the resource group and virtual network containing the 4 digit workspace ID. Click Next. Configure any storage settings and click Next. Under advanced settings, under advanced networking - uncheck Return Proxy, and Public Head node. Click Next. Under cloud init , paste the below script, with the appropriate values for TRE ID and Region into each of the nodes to ensure the package mirror is used. #!/bin/sh TRE_ID = \"mrtredemo2\" REGION = \"westeurope\" ls /etc/yum.repos.d/*.repo | xargs sed -i 's/mirrorlist/# mirrorlist/g' ls /etc/yum.repos.d/*.repo | xargs sed -i \"s,# baseurl=https://repo.almalinux.org/,baseurl=https://nexus- $TRE_ID . $REGION .cloudapp.azure.com/repository/almalinux/,g\" yum -y install epel-release ls /etc/yum.repos.d/*.repo | xargs sed -i 's/metalink/# metalink/g' ls /etc/yum.repos.d/*.repo | xargs sed -i \"s,#baseurl=https://download.fedoraproject.org/,baseurl=https://nexus- $TRE_ID . $REGION .cloudapp.azure.com/repository/fedoraproject/,g\" yum -y install python3 python3-pip sudo tee /etc/pip.conf <<EOF [global] index = https://nexus-$TRE_ID.$REGION.cloudapp.azure.com/repository/pypi/pypi index-url = https://nexus-$TRE_ID.$REGION.cloudapp.azure.com/repository/pypi/simple trusted-host = https://nexus-$TRE_ID.$REGION.cloudapp.azure.com EOF sudo cat > /etc/yum.repos.d/cyclecloud.repo <<EOF [cyclecloud] name=cyclecloud baseurl=https://nexus-$TRE_ID.$REGION.cloudapp.azure.com/repository/microsoft-yumrepos/cyclecloud gpgcheck=1 gpgkey=https://nexus-$TRE_ID.$REGION.cloudapp.azure.com/repository/microsoft-keys/microsoft.asc EOF Click Save. Under the new cluster, click Access and add the user created earlier and configure node access. Start the cluster, ensure the cluster starts successfully and provide the users connection details as detailed here: https://docs.microsoft.com/en-us/azure/cyclecloud/how-to/connect-to-node?view=cyclecloud-8","title":"Azure CycleCloud (HPC Compute)"},{"location":"tre-templates/shared-services/cyclecloud/#azure-cyclecloud-shared-service","text":"Azure CycleCloud is an enterprise-friendly tool for orchestrating and managing High Performance Computing (HPC) environments on Azure. This shared service deploys a single CycleCloud server, which can be used to by a TRE Administrator to create and manage multiple HPC clusters. Used \"as is\", this shared service is only appropriate for proof of concept work and small projects, however can be used as a starting point for more advanced scenarios. Using the CycleCloud cluster properties the TRE Administrator can choose which virtual network the cluster will be deployed into, and hence the workspace the cluster can be accessed from. At present there is no self service cluster creation for research teams, and as such costs are not attributed to individual workspace however this could be added in the future, and is tracked in this issue https://github.com/microsoft/AzureTRE/issues/2230 .","title":"Azure CycleCloud Shared Service"},{"location":"tre-templates/shared-services/cyclecloud/#deployment-and-configuration","text":"The CycleCloud shared service template needs registering with the TRE as per <../../tre-admins/registering-templates/> The templates can be found at templates/shared_services/cyclecloud . Prior to deploying the CycleCloud server, the license terms for any Azure VM marketplace images used by CycleCloud must be accepted. This can be done by running the following command while logged into the Azure CLI: az vm image terms accept --urn azurecyclecloud:azure-cyclecloud:cyclecloud8:latest az vm image terms accept --urn almalinux:almalinux-hpc:8_5-hpc:latest Deploy the CycleCloud server using UI or API. To connect to the CycleCloud server, the TRE Administrator must connect to the CycleCloud server from the administration jumpbox. Use Azure Bastion to connect to the jumpbox a with the username admin and the select the password located in your core KeyVault. Connect to the CycleCloud server at the URL: https://cyclecloud-{TRE_ID}.{LOCATION}.cloudapp.azure.com/ . Provide a name for the cyclecloud server instance. -Review the terms and conditions and hit next. Provide your user details, including SSH key Hit Done, and wait for the add subscription dialog. Select the region your TRE is deployed into, leave the resource group as the default <Create New Per Cluster> and select the storage account beginning stgcc . This should look similar to: Hit Save, and then \"Back to Clusters\"","title":"Deployment and Configuration"},{"location":"tre-templates/shared-services/cyclecloud/#create-a-cluster","text":"Before you start creating the cluster retrieve the last 4 digits of the workspace ID that you want to deploy the cluster into. Create a user in CycleCloud as per https://docs.microsoft.com/en-us/azure/cyclecloud/concepts/user-management?view=cyclecloud-8#adding-new-users-to-cyclecloud . The SSH key for the user will need to be created within the workspace and public key exporting. We suggest using the 4 digits retrieved in step 1 as part of the user account. Select your cluster type, we have tested Slurm and Grid Engine using the methods documented here. Give the cluster a name - again we suggest using the last 4 digits of the workspace ID as part of the name.Click Next. Select your required settings. In the Subnet ID box, choose the ServicesSubnet in the resource group and virtual network containing the 4 digit workspace ID. Click Next. Configure any storage settings and click Next. Under advanced settings, under advanced networking - uncheck Return Proxy, and Public Head node. Click Next. Under cloud init , paste the below script, with the appropriate values for TRE ID and Region into each of the nodes to ensure the package mirror is used. #!/bin/sh TRE_ID = \"mrtredemo2\" REGION = \"westeurope\" ls /etc/yum.repos.d/*.repo | xargs sed -i 's/mirrorlist/# mirrorlist/g' ls /etc/yum.repos.d/*.repo | xargs sed -i \"s,# baseurl=https://repo.almalinux.org/,baseurl=https://nexus- $TRE_ID . $REGION .cloudapp.azure.com/repository/almalinux/,g\" yum -y install epel-release ls /etc/yum.repos.d/*.repo | xargs sed -i 's/metalink/# metalink/g' ls /etc/yum.repos.d/*.repo | xargs sed -i \"s,#baseurl=https://download.fedoraproject.org/,baseurl=https://nexus- $TRE_ID . $REGION .cloudapp.azure.com/repository/fedoraproject/,g\" yum -y install python3 python3-pip sudo tee /etc/pip.conf <<EOF [global] index = https://nexus-$TRE_ID.$REGION.cloudapp.azure.com/repository/pypi/pypi index-url = https://nexus-$TRE_ID.$REGION.cloudapp.azure.com/repository/pypi/simple trusted-host = https://nexus-$TRE_ID.$REGION.cloudapp.azure.com EOF sudo cat > /etc/yum.repos.d/cyclecloud.repo <<EOF [cyclecloud] name=cyclecloud baseurl=https://nexus-$TRE_ID.$REGION.cloudapp.azure.com/repository/microsoft-yumrepos/cyclecloud gpgcheck=1 gpgkey=https://nexus-$TRE_ID.$REGION.cloudapp.azure.com/repository/microsoft-keys/microsoft.asc EOF Click Save. Under the new cluster, click Access and add the user created earlier and configure node access. Start the cluster, ensure the cluster starts successfully and provide the users connection details as detailed here: https://docs.microsoft.com/en-us/azure/cyclecloud/how-to/connect-to-node?view=cyclecloud-8","title":"Create a Cluster"},{"location":"tre-templates/shared-services/gitea/","text":"Gitea Shared Service As outbound access to public git repositories such as GitHub is often blocked a git mirror may be required. Gitea can be deployed as a shared service to offer this functionality. Documentation on Gitea can be found here: https://docs.gitea.io/ . Deploy To deploy this shared service you should use the UI (or the API) to issue a request. If you don't see the option available for this specifc template make sure it has been built, published and registered by the TRE Admin. Getting Started Connect to the Gitea admin console https://yourtreuri/gitea/ with the giteaadmin user. You can find the password in keyvault as gitea password . Network requirements Gitea needs to be able to access the following resource outside the Azure TRE VNET via explicitly allowed Service Tags or URLs. Service Tag / Destination Justification AzureActiveDirectory Authorize the signed in user against Azure Active Directory. AzureContainerRegistry Pull the Gitea container image, as it is located in Azure Container Registry. (www.)github.com Allows Gitea to mirror any repo on GitHub","title":"Gitea (Source Mirror)"},{"location":"tre-templates/shared-services/gitea/#gitea-shared-service","text":"As outbound access to public git repositories such as GitHub is often blocked a git mirror may be required. Gitea can be deployed as a shared service to offer this functionality. Documentation on Gitea can be found here: https://docs.gitea.io/ .","title":"Gitea Shared Service"},{"location":"tre-templates/shared-services/gitea/#deploy","text":"To deploy this shared service you should use the UI (or the API) to issue a request. If you don't see the option available for this specifc template make sure it has been built, published and registered by the TRE Admin.","title":"Deploy"},{"location":"tre-templates/shared-services/gitea/#getting-started","text":"Connect to the Gitea admin console https://yourtreuri/gitea/ with the giteaadmin user. You can find the password in keyvault as gitea password .","title":"Getting Started"},{"location":"tre-templates/shared-services/gitea/#network-requirements","text":"Gitea needs to be able to access the following resource outside the Azure TRE VNET via explicitly allowed Service Tags or URLs. Service Tag / Destination Justification AzureActiveDirectory Authorize the signed in user against Azure Active Directory. AzureContainerRegistry Pull the Gitea container image, as it is located in Azure Container Registry. (www.)github.com Allows Gitea to mirror any repo on GitHub","title":"Network requirements"},{"location":"tre-templates/shared-services/nexus/","text":"Nexus Shared Service Sonatype Nexus (RepoManager) allows users in workspaces to access external software packages securely. Documentation on Nexus can be found here: https://help.sonatype.com/repomanager3/ . Deploy To deploy this service use the UI or API directly and choose the nexus template. Nexus will be deployed as part of the main TRE terraform deployment. A configuration script needs to be run once the deployment is done. The script will: Fetch the Nexus generated password from storage account. Reset the default password and set a new one. Store the new password in Key Vault under nexus-<TRE_ID>-admin-password Create an anonymous default PyPI proxy repository Setup and usage A TRE Administrator can access Nexus though the admin jumpbox provisioned as part of the TRE deployment. The username is adminuser and the password is located in the KeyVault under vm-<tre-id>-jumpbox-password A researcher can access Nexus from within the workspace by using the internal Nexus URL of: https://nexus- .azurewebsites.net/ To fetch Python packages from the PyPI proxy, a researcher can use pip install while specifying the proxy server: pip install packagename --index-url https://nexus-<TRE_ID>.azurewebsites.net/repository/apt-pypi/simple Network requirements Nexus Shared Service requires access to resources outside of the Azure TRE VNET. These are set as part of the firewall provisioning pipeline via explicit allow on Service Tags or URLs. Notice that since Nexus Shared Service is running on an App Service, the outgoing exceptions are made for the calls coming out of the Web App Subnet. Service Tag / Destination Justification AzureActiveDirectory Authorize the signed in user against Azure Active Directory. AzureContainerRegistry Pull the Nexus container image, as it is located in Azure Container Registry. pypi.org Enables Nexus to \"proxy\" python packages to use inside of workspaces. repo.anaconda.com Enables Nexus to \"proxy\" conda packages to use inside of workspaces. conda.anaconda.org Enables Nexus to \"proxy\" additional conda packages to use inside of workspaces such as conda-forge. *.docker.com Enables Nexus to \"proxy\" docker repos to use inside of workspaces. *.docker.io Enables Nexus to \"proxy\" docker repos to use inside of workspaces. archive.ubuntu.com Enables Nexus to \"proxy\" apt packages to use inside of workspaces. security.ubuntu.com Enables Nexus to \"proxy\" apt packages to use inside of workspaces. Current Repos Name Type Source URI Nexus URI Usage PiPy PiPy [https://pypi.org/] https://nexus-<TRE_ID>.azurewebsites.net/repository/pypi/ Allow use of pip commands. Apt PiPy Apt [https://pypi.org/] https://nexus-<TRE_ID>.azurewebsites.net/repository/apt-pypi/ Install pip via apt on Linux systems. Conda conda [https://repo.anaconda.com/pkgs/main/] https://nexus-<TRE_ID>.azurewebsites.net/repository/conda/ Configure conda to have access to default conda packages. Conda-Forge conda [https://conda.anaconda.org/conda-forge/] https://nexus-<TRE_ID>.azurewebsites.net/repository/conda-forge/ Configure conda to have access to conda-forge packages. Docker apt [https://download.docker.com/linux/ubuntu/] https://nexus-<TRE_ID>.azurewebsites.net/repository/docker/ Install Docker via apt on Linux systems. Docker GPG raw [https://download.docker.com/linux/ubuntu/] https://nexus-<TRE_ID>.azurewebsites.net/repository/docker-public-key/ Provide public key to sign apt source for above Docker apt. Docker Hub docker [https://registry-1.docker.io] https://nexus-<TRE_ID>.azurewebsites.net/repository/docker-hub/ Provide docker access to public images repo. Ubuntu Packages apt [http://archive.ubuntu.com/ubuntu/] https://nexus-<TRE_ID>.azurewebsites.net/repository/ubuntu/ Provide access to Ubuntu apt packages on Ubuntu systems. Ubuntu Security Packages apt [http://security.ubuntu.com/ubuntu/] https://nexus-<TRE_ID>.azurewebsites.net/repository/ubuntu-security/ Provide access to Ubuntu Security apt packages on Ubuntu systems.","title":"Nexus (Package Mirror)"},{"location":"tre-templates/shared-services/nexus/#nexus-shared-service","text":"Sonatype Nexus (RepoManager) allows users in workspaces to access external software packages securely. Documentation on Nexus can be found here: https://help.sonatype.com/repomanager3/ .","title":"Nexus Shared Service"},{"location":"tre-templates/shared-services/nexus/#deploy","text":"To deploy this service use the UI or API directly and choose the nexus template. Nexus will be deployed as part of the main TRE terraform deployment. A configuration script needs to be run once the deployment is done. The script will: Fetch the Nexus generated password from storage account. Reset the default password and set a new one. Store the new password in Key Vault under nexus-<TRE_ID>-admin-password Create an anonymous default PyPI proxy repository","title":"Deploy"},{"location":"tre-templates/shared-services/nexus/#setup-and-usage","text":"A TRE Administrator can access Nexus though the admin jumpbox provisioned as part of the TRE deployment. The username is adminuser and the password is located in the KeyVault under vm-<tre-id>-jumpbox-password A researcher can access Nexus from within the workspace by using the internal Nexus URL of: https://nexus- .azurewebsites.net/ To fetch Python packages from the PyPI proxy, a researcher can use pip install while specifying the proxy server: pip install packagename --index-url https://nexus-<TRE_ID>.azurewebsites.net/repository/apt-pypi/simple","title":"Setup and usage"},{"location":"tre-templates/shared-services/nexus/#network-requirements","text":"Nexus Shared Service requires access to resources outside of the Azure TRE VNET. These are set as part of the firewall provisioning pipeline via explicit allow on Service Tags or URLs. Notice that since Nexus Shared Service is running on an App Service, the outgoing exceptions are made for the calls coming out of the Web App Subnet. Service Tag / Destination Justification AzureActiveDirectory Authorize the signed in user against Azure Active Directory. AzureContainerRegistry Pull the Nexus container image, as it is located in Azure Container Registry. pypi.org Enables Nexus to \"proxy\" python packages to use inside of workspaces. repo.anaconda.com Enables Nexus to \"proxy\" conda packages to use inside of workspaces. conda.anaconda.org Enables Nexus to \"proxy\" additional conda packages to use inside of workspaces such as conda-forge. *.docker.com Enables Nexus to \"proxy\" docker repos to use inside of workspaces. *.docker.io Enables Nexus to \"proxy\" docker repos to use inside of workspaces. archive.ubuntu.com Enables Nexus to \"proxy\" apt packages to use inside of workspaces. security.ubuntu.com Enables Nexus to \"proxy\" apt packages to use inside of workspaces.","title":"Network requirements"},{"location":"tre-templates/shared-services/nexus/#current-repos","text":"Name Type Source URI Nexus URI Usage PiPy PiPy [https://pypi.org/] https://nexus-<TRE_ID>.azurewebsites.net/repository/pypi/ Allow use of pip commands. Apt PiPy Apt [https://pypi.org/] https://nexus-<TRE_ID>.azurewebsites.net/repository/apt-pypi/ Install pip via apt on Linux systems. Conda conda [https://repo.anaconda.com/pkgs/main/] https://nexus-<TRE_ID>.azurewebsites.net/repository/conda/ Configure conda to have access to default conda packages. Conda-Forge conda [https://conda.anaconda.org/conda-forge/] https://nexus-<TRE_ID>.azurewebsites.net/repository/conda-forge/ Configure conda to have access to conda-forge packages. Docker apt [https://download.docker.com/linux/ubuntu/] https://nexus-<TRE_ID>.azurewebsites.net/repository/docker/ Install Docker via apt on Linux systems. Docker GPG raw [https://download.docker.com/linux/ubuntu/] https://nexus-<TRE_ID>.azurewebsites.net/repository/docker-public-key/ Provide public key to sign apt source for above Docker apt. Docker Hub docker [https://registry-1.docker.io] https://nexus-<TRE_ID>.azurewebsites.net/repository/docker-hub/ Provide docker access to public images repo. Ubuntu Packages apt [http://archive.ubuntu.com/ubuntu/] https://nexus-<TRE_ID>.azurewebsites.net/repository/ubuntu/ Provide access to Ubuntu apt packages on Ubuntu systems. Ubuntu Security Packages apt [http://security.ubuntu.com/ubuntu/] https://nexus-<TRE_ID>.azurewebsites.net/repository/ubuntu-security/ Provide access to Ubuntu Security apt packages on Ubuntu systems.","title":"Current Repos"},{"location":"tre-templates/user-resources/export-reviewvm/","text":"Guacamole User Resource Service bundle (Windows) This is a User Resource Service template. It defines a VM to be used by TRE Airlock Managers with Guacamole server . It blocks all inbound traffic to the internet and allows only RDP connections from within the vnet. It also blocks all outbound traffic except for traffic to Airlock Export In-Review storage account within the workspace.For more information about Airlock, see overview page . Data that needs to be reviewed will be downloaded onto the VM during VM creation, and available on Desktop. It can be only deployed by an Airlock Manager. Prerequisites A base workspace bundle installed A guacamole workspace service bundle installed","title":"Export Review VM"},{"location":"tre-templates/user-resources/export-reviewvm/#guacamole-user-resource-service-bundle-windows","text":"This is a User Resource Service template. It defines a VM to be used by TRE Airlock Managers with Guacamole server . It blocks all inbound traffic to the internet and allows only RDP connections from within the vnet. It also blocks all outbound traffic except for traffic to Airlock Export In-Review storage account within the workspace.For more information about Airlock, see overview page . Data that needs to be reviewed will be downloaded onto the VM during VM creation, and available on Desktop. It can be only deployed by an Airlock Manager.","title":"Guacamole User Resource Service bundle (Windows)"},{"location":"tre-templates/user-resources/export-reviewvm/#prerequisites","text":"A base workspace bundle installed A guacamole workspace service bundle installed","title":"Prerequisites"},{"location":"tre-templates/user-resources/guacamole-linux-vm/","text":"Guacamole User Resource Service bundle (Linux) This is a User Resource Service template. It defines a Linux-based VM to be used by TRE researchers and to be connected to using a Guacamole server . It blocks all inbound and outbound traffic to the internet and allows only RDP connections from within the vnet. Prerequisites A base workspace bundle installed A guacamole workspace service bundle installed","title":"Guacamole Linux VM"},{"location":"tre-templates/user-resources/guacamole-linux-vm/#guacamole-user-resource-service-bundle-linux","text":"This is a User Resource Service template. It defines a Linux-based VM to be used by TRE researchers and to be connected to using a Guacamole server . It blocks all inbound and outbound traffic to the internet and allows only RDP connections from within the vnet.","title":"Guacamole User Resource Service bundle (Linux)"},{"location":"tre-templates/user-resources/guacamole-linux-vm/#prerequisites","text":"A base workspace bundle installed A guacamole workspace service bundle installed","title":"Prerequisites"},{"location":"tre-templates/user-resources/guacamole-windows-vm/","text":"Guacamole User Resource Service bundle (Windows) This is a User Resource Service template. It defines a Windows 10/Server 2019 VM to be used by TRE researchers and to be connected to using a Guacamole server . It blocks all inbound and outbound traffic to the internet and allows only RDP connections from within the vnet. Prerequisites A base workspace bundle installed A guacamole workspace service bundle installed","title":"Guacamole Windows VM"},{"location":"tre-templates/user-resources/guacamole-windows-vm/#guacamole-user-resource-service-bundle-windows","text":"This is a User Resource Service template. It defines a Windows 10/Server 2019 VM to be used by TRE researchers and to be connected to using a Guacamole server . It blocks all inbound and outbound traffic to the internet and allows only RDP connections from within the vnet.","title":"Guacamole User Resource Service bundle (Windows)"},{"location":"tre-templates/user-resources/guacamole-windows-vm/#prerequisites","text":"A base workspace bundle installed A guacamole workspace service bundle installed","title":"Prerequisites"},{"location":"tre-templates/user-resources/import-reviewvm/","text":"Guacamole User Resource Service bundle (Windows) This is a User Resource Service template. It defines a VM to be used by TRE Airlock Managers with Guacamole server . It blocks all inbound traffic to the internet and allows only RDP connections from within the vnet. When deployed in an Airlock Import Review workspace, it has access to the Airlock Import In-Progress storage account outside of the workspace. For more information about Airlock, see overview page . Data that needs to be reviewed will be downloaded onto the VM during VM creation, and available on Desktop. It can be only deployed by an Airlock Manager. Prerequisites An Airlock Import workspace bundle installed A guacamole workspace service bundle installed in that workspace","title":"Import Review VM"},{"location":"tre-templates/user-resources/import-reviewvm/#guacamole-user-resource-service-bundle-windows","text":"This is a User Resource Service template. It defines a VM to be used by TRE Airlock Managers with Guacamole server . It blocks all inbound traffic to the internet and allows only RDP connections from within the vnet. When deployed in an Airlock Import Review workspace, it has access to the Airlock Import In-Progress storage account outside of the workspace. For more information about Airlock, see overview page . Data that needs to be reviewed will be downloaded onto the VM during VM creation, and available on Desktop. It can be only deployed by an Airlock Manager.","title":"Guacamole User Resource Service bundle (Windows)"},{"location":"tre-templates/user-resources/import-reviewvm/#prerequisites","text":"An Airlock Import workspace bundle installed A guacamole workspace service bundle installed in that workspace","title":"Prerequisites"},{"location":"tre-templates/workspace-services/azure-ml/","text":"Azure Machine Learning Service bundle See: https://azure.microsoft.com/services/machine-learning/ This service installs the following resources into an existing virtual network within the workspace: Any users with the role of Workspace Researcher will be assigned the AzureML Data Scientist role within the AML workspace. Properties display_name - The name of the Azure Machine Learning workspace. description - The description of the Azure Machine Learning workspace. is_exposed_externally - If True , the Azure Machine Learning workspace is accessible from outside of the worksapce virtual network. Firewall Rules Please be aware that the following outbound Firewall rules are opened for the workspace when this service is deployed, including to Azure Storage. This does open the possibility to extract data from a workspace if the user is determined to do so. Work is ongoing to remove some of these requirements: Service Tags: - AzureActiveDirectory - AzureResourceManager - AzureMachineLearning\" - Storage. {AzureRegion} - MicrosoftContainerRegistry URLs: - aadcdn.msftauth.net - ml.azure.com Prerequisites A base workspace bundle installed","title":"Azure ML"},{"location":"tre-templates/workspace-services/azure-ml/#azure-machine-learning-service-bundle","text":"See: https://azure.microsoft.com/services/machine-learning/ This service installs the following resources into an existing virtual network within the workspace: Any users with the role of Workspace Researcher will be assigned the AzureML Data Scientist role within the AML workspace.","title":"Azure Machine Learning Service bundle"},{"location":"tre-templates/workspace-services/azure-ml/#properties","text":"display_name - The name of the Azure Machine Learning workspace. description - The description of the Azure Machine Learning workspace. is_exposed_externally - If True , the Azure Machine Learning workspace is accessible from outside of the worksapce virtual network.","title":"Properties"},{"location":"tre-templates/workspace-services/azure-ml/#firewall-rules","text":"Please be aware that the following outbound Firewall rules are opened for the workspace when this service is deployed, including to Azure Storage. This does open the possibility to extract data from a workspace if the user is determined to do so. Work is ongoing to remove some of these requirements: Service Tags: - AzureActiveDirectory - AzureResourceManager - AzureMachineLearning\" - Storage. {AzureRegion} - MicrosoftContainerRegistry URLs: - aadcdn.msftauth.net - ml.azure.com","title":"Firewall Rules"},{"location":"tre-templates/workspace-services/azure-ml/#prerequisites","text":"A base workspace bundle installed","title":"Prerequisites"},{"location":"tre-templates/workspace-services/gitea/","text":"Gitea Workspace Service See: https://gitea.io/ Firewall Rules The Gitea worskpace service opens outbound access to: AzureActiveDirectory Azure AD CDN - https://aadcdn.msftauth.net Prerequisites A base workspace deployed The Gitea workspace service container image needs building and pushing: make workspace_service_bundle BUNDLE=gitea Authenticating to Gitea and setting up a local username and password Navigate to the Gitea workspace service using the connection URI from the details tab. and from the menu click the Sign in button. Click sign in with OpenID button and sign in with the same credentials used to access the workspace. Once succesfully signed in choose a username. Navigate to the user settings and under the account tab set a password for your account( https://<gitea_url>/user/settings/account ). This username and passowrd should be used to authenticate against Gitea when carrying out git operations.","title":"Gitea"},{"location":"tre-templates/workspace-services/gitea/#gitea-workspace-service","text":"See: https://gitea.io/","title":"Gitea Workspace Service"},{"location":"tre-templates/workspace-services/gitea/#firewall-rules","text":"The Gitea worskpace service opens outbound access to: AzureActiveDirectory Azure AD CDN - https://aadcdn.msftauth.net","title":"Firewall Rules"},{"location":"tre-templates/workspace-services/gitea/#prerequisites","text":"A base workspace deployed The Gitea workspace service container image needs building and pushing: make workspace_service_bundle BUNDLE=gitea","title":"Prerequisites"},{"location":"tre-templates/workspace-services/gitea/#authenticating-to-gitea-and-setting-up-a-local-username-and-password","text":"Navigate to the Gitea workspace service using the connection URI from the details tab. and from the menu click the Sign in button. Click sign in with OpenID button and sign in with the same credentials used to access the workspace. Once succesfully signed in choose a username. Navigate to the user settings and under the account tab set a password for your account( https://<gitea_url>/user/settings/account ). This username and passowrd should be used to authenticate against Gitea when carrying out git operations.","title":"Authenticating to Gitea and setting up a local username and password"},{"location":"tre-templates/workspace-services/guacamole/","text":"Guacamole Service bundle See: https://guacamole.apache.org/ Firewall Rules Please be aware that the following Firewall rules are opened for the workspace when this service is deployed: Service Tags: AzureActiveDirectory Prerequisites A base workspace bundle installed Guacamole Workspace Service Configuration When deploying a Guacamole service into a workspace the following properties need to be configured. Optional Properties Property Options Description guac_disable_copy true / false (Default: true ) Disable Copy functionality guac_disable_paste true / false (Default: false ) Disable Paste functionality\" guac_enable_drive true / false (Default: true ) Enable mounted drive guac_disable_download true / false (Default: true ) Disable files download is_exposed_externally true / false (Default: true ) Is the Guacamole service exposed outside of the vnet","title":"Guacamole"},{"location":"tre-templates/workspace-services/guacamole/#guacamole-service-bundle","text":"See: https://guacamole.apache.org/","title":"Guacamole Service bundle"},{"location":"tre-templates/workspace-services/guacamole/#firewall-rules","text":"Please be aware that the following Firewall rules are opened for the workspace when this service is deployed: Service Tags: AzureActiveDirectory","title":"Firewall Rules"},{"location":"tre-templates/workspace-services/guacamole/#prerequisites","text":"A base workspace bundle installed","title":"Prerequisites"},{"location":"tre-templates/workspace-services/guacamole/#guacamole-workspace-service-configuration","text":"When deploying a Guacamole service into a workspace the following properties need to be configured.","title":"Guacamole Workspace Service Configuration"},{"location":"tre-templates/workspace-services/guacamole/#optional-properties","text":"Property Options Description guac_disable_copy true / false (Default: true ) Disable Copy functionality guac_disable_paste true / false (Default: false ) Disable Paste functionality\" guac_enable_drive true / false (Default: true ) Enable mounted drive guac_disable_download true / false (Default: true ) Disable files download is_exposed_externally true / false (Default: true ) Is the Guacamole service exposed outside of the vnet","title":"Optional Properties"},{"location":"tre-templates/workspace-services/inner-eye/","text":"InnerEye DeepLearning Service Bundle Azure ML See: https://github.com/microsoft/InnerEye-DeepLearning Firewall Rules Please be aware that the following Firewall rules are opened for the workspace when this service is deployed. These are all dependencies needed by InnerEye to be able to develop and train models: URLs: *.anaconda.com *.anaconda.org binstar-cio-packages-prod.s3.amazonaws.com *pythonhosted.org github-cloud.githubusercontent.com azure.archive.ubuntu.com (git lfs package) packagecloud.io (git lfs package installation script) Initial setup Provision an InnerEye workspace by invoking a POST to https://<treid>.<region>.cloudapp.azure.com/api/workspaces with the following payload: { \"templateName\" : \"tre-workspace-innereye\" , \"properties\" : { \"display_name\" : \"InnerEye\" , \"description\" : \"InnerEyer workspace\" , \"client_id\" : \"<WORKSPACE_API_CLIENT_ID>\" , \"inference_sp_client_id\" : \"<spn_client_id>\" , \"inference_sp_client_secret\" : \"<spn_client_secret>\" } } This will provision Base Workspace, with AML service and InnerEye service, including InnerEye Inference web app. Running the InnerEye HelloWorld Preparation steps performed by the TRE Admin Ensure that you have completed \"Configuring Shared Services\" Log onto a TREAdmin Jumpbox and mirror Github repos needed by InnerEye Helloworld: ./templates/workspace_services/gitea/gitea_migrate_repo.sh -t <tre_id> -g https://github.com/microsoft/InnerEye-DeepLearning ./templates/workspace_services/gitea/gitea_migrate_repo.sh -t <tre_id> -g https://github.com/analysiscenter/radio ./templates/workspace_services/gitea/gitea_migrate_repo.sh -t <tre_id> -g https://github.com/microsoft/InnerEye-Inference Setup the InnerEye run from AML Compute Instance Log onto a VM in the workspace In the VM open your browser and navigate to ml.azure.com , login, select the right Subscription and AML workspace. Select the Notebooks tab and then click Terminal. This will open a terminal on a running compute instance Pull the InnerEye-DeepLearning git repo from Gitea mirror and configure: git clone https://gitea-<TRE_ID>.azurewebsites.net/giteaadmin/InnerEye-DeepLearning cd InnerEye-DeepLearning curl -s https://packagecloud.io/install/repositories/github/git-lfs/script.deb.sh | sudo bash sudo apt-get install git-lfs git lfs install git lfs pull export PIP_INDEX_URL=https://nexus-<TRE_ID>.azurewebsites.net/repository/apt-pypi/simple conda init conda env create --file environment.yml conda activate InnerEye Login to AzureCLI and set default subscription if needed az login az account set --subscription Create a \"datasets\" container az storage container create --name datasets --account-name stgws<workspace_id> 1. Copy dataset.csv file from Tests/ML/test_data/dataset.csv to the hello_world folder: az storage blob upload --account-name stgws<workspace_id> --container-name datasets --file ./Tests/ML/test_data/dataset.csv --name hello_world/dataset.csv 1. Copy the whole train_and_test_data folder from Test/ML/test_data/train_and_test_data to the hello_world folder: az storage blob directory upload -c datasets --account-name stgws<workspace_id> -s \"./Tests/ML/test_data/train_and_test_data\" -d hello_world --recursive Get storage keys for your storage: az storage account keys list --account-name stgws<workspace_id> Update the following variables in InnerEye/settings.yml : subscription_id, resource_group, workspace_name, cluster (see AML setup for more details). Navigate to Data stores in AML Workspace. Create a New datastore named innereyedatasets and link it to your storage account and datasets container. Use the key collected from the step above. Back from the Terminal run python InnerEye/ML/runner.py --model=HelloWorld --azureml=True The runner will provide you with a link and ask you to open it to login. Copy the link and open it in browser (Edge) on the DSVM and login. The run will continue after login. In your browser navigate to https://ml.azure.com and open the Experiments tab to follow the progress of the training Configuring and testing inference service The workspace service provisions an App Service Plan and an App Service for hosting the inference webapp. The webapp will be integrated into the workspace network, allowing the webapp to connect to the AML workspace. Following the setup you will need to: Log onto a VM in the workspace and run: git clone https://gitea-<TRE_ID>.azurewebsites.net/giteaadmin/InnerEye-Inference cd InnerEye-Inference Create a file named \"set_environment.sh\" with the following variables as content: #!/bin/bash export CUSTOMCONNSTR_AZUREML_SERVICE_PRINCIPAL_SECRET = <inference_sp_client_secret-from-above> export CUSTOMCONNSTR_API_AUTH_SECRET = <generate-a-random-guid--that-is-used-for-authentication> export CLUSTER = <name-of-compute-cluster> export WORKSPACE_NAME = <name-of-AML-workspace> export EXPERIMENT_NAME = <name-of-AML-experiment> export RESOURCE_GROUP = <name-of-resource-group> export SUBSCRIPTION_ID = <subscription-id> export APPLICATION_ID = <inference_sp_client_id-from-above> export TENANT_ID = <tenant-id> export DATASTORE_NAME = inferencedatastore export IMAGE_DATA_FOLDER = imagedata Upload the configuration file to the web app: az webapp up --name <inference-app-name> -g <resource-group-name> Create a new container in your storage account for storing inference images called inferencedatastore . Create a new folder in that container called imagedata . Navigate to the ml.azure.com, Datastores and create a new datastore named inferencedatastore and connect it to the newly created container. Test the service by sending a GET or POST command using curl or Invoke-WebRequest where API_AUTH_SECRET is the random GUID generated for CUSTOMCONNSTR_API_AUTH_SECRET above: Simple ping: Invoke-WebRequest https://yourservicename.azurewebsites.net/v1/ping -Headers @{'Accept' = 'application/json'; 'API_AUTH_SECRET' = 'your-secret-1234-1123445'} Test connection with AML: Invoke-WebRequest https://yourservicename.azurewebsites.net/v1/model/start/HelloWorld:1 -Method POST -Headers @{'Accept' = 'application/json'; 'API_AUTH_SECRET' = 'your-secret-1234-1123445'}","title":"InnerEye"},{"location":"tre-templates/workspace-services/inner-eye/#innereye-deeplearning-service-bundle","text":"Azure ML See: https://github.com/microsoft/InnerEye-DeepLearning","title":"InnerEye DeepLearning Service Bundle"},{"location":"tre-templates/workspace-services/inner-eye/#firewall-rules","text":"Please be aware that the following Firewall rules are opened for the workspace when this service is deployed. These are all dependencies needed by InnerEye to be able to develop and train models: URLs: *.anaconda.com *.anaconda.org binstar-cio-packages-prod.s3.amazonaws.com *pythonhosted.org github-cloud.githubusercontent.com azure.archive.ubuntu.com (git lfs package) packagecloud.io (git lfs package installation script)","title":"Firewall Rules"},{"location":"tre-templates/workspace-services/inner-eye/#initial-setup","text":"Provision an InnerEye workspace by invoking a POST to https://<treid>.<region>.cloudapp.azure.com/api/workspaces with the following payload: { \"templateName\" : \"tre-workspace-innereye\" , \"properties\" : { \"display_name\" : \"InnerEye\" , \"description\" : \"InnerEyer workspace\" , \"client_id\" : \"<WORKSPACE_API_CLIENT_ID>\" , \"inference_sp_client_id\" : \"<spn_client_id>\" , \"inference_sp_client_secret\" : \"<spn_client_secret>\" } } This will provision Base Workspace, with AML service and InnerEye service, including InnerEye Inference web app.","title":"Initial setup"},{"location":"tre-templates/workspace-services/inner-eye/#running-the-innereye-helloworld","text":"","title":"Running the InnerEye HelloWorld"},{"location":"tre-templates/workspace-services/inner-eye/#preparation-steps-performed-by-the-tre-admin","text":"Ensure that you have completed \"Configuring Shared Services\" Log onto a TREAdmin Jumpbox and mirror Github repos needed by InnerEye Helloworld: ./templates/workspace_services/gitea/gitea_migrate_repo.sh -t <tre_id> -g https://github.com/microsoft/InnerEye-DeepLearning ./templates/workspace_services/gitea/gitea_migrate_repo.sh -t <tre_id> -g https://github.com/analysiscenter/radio ./templates/workspace_services/gitea/gitea_migrate_repo.sh -t <tre_id> -g https://github.com/microsoft/InnerEye-Inference","title":"Preparation steps performed by the TRE Admin"},{"location":"tre-templates/workspace-services/inner-eye/#setup-the-innereye-run-from-aml-compute-instance","text":"Log onto a VM in the workspace In the VM open your browser and navigate to ml.azure.com , login, select the right Subscription and AML workspace. Select the Notebooks tab and then click Terminal. This will open a terminal on a running compute instance Pull the InnerEye-DeepLearning git repo from Gitea mirror and configure: git clone https://gitea-<TRE_ID>.azurewebsites.net/giteaadmin/InnerEye-DeepLearning cd InnerEye-DeepLearning curl -s https://packagecloud.io/install/repositories/github/git-lfs/script.deb.sh | sudo bash sudo apt-get install git-lfs git lfs install git lfs pull export PIP_INDEX_URL=https://nexus-<TRE_ID>.azurewebsites.net/repository/apt-pypi/simple conda init conda env create --file environment.yml conda activate InnerEye Login to AzureCLI and set default subscription if needed az login az account set --subscription Create a \"datasets\" container az storage container create --name datasets --account-name stgws<workspace_id> 1. Copy dataset.csv file from Tests/ML/test_data/dataset.csv to the hello_world folder: az storage blob upload --account-name stgws<workspace_id> --container-name datasets --file ./Tests/ML/test_data/dataset.csv --name hello_world/dataset.csv 1. Copy the whole train_and_test_data folder from Test/ML/test_data/train_and_test_data to the hello_world folder: az storage blob directory upload -c datasets --account-name stgws<workspace_id> -s \"./Tests/ML/test_data/train_and_test_data\" -d hello_world --recursive Get storage keys for your storage: az storage account keys list --account-name stgws<workspace_id> Update the following variables in InnerEye/settings.yml : subscription_id, resource_group, workspace_name, cluster (see AML setup for more details). Navigate to Data stores in AML Workspace. Create a New datastore named innereyedatasets and link it to your storage account and datasets container. Use the key collected from the step above. Back from the Terminal run python InnerEye/ML/runner.py --model=HelloWorld --azureml=True The runner will provide you with a link and ask you to open it to login. Copy the link and open it in browser (Edge) on the DSVM and login. The run will continue after login. In your browser navigate to https://ml.azure.com and open the Experiments tab to follow the progress of the training","title":"Setup the InnerEye run from AML Compute Instance"},{"location":"tre-templates/workspace-services/inner-eye/#configuring-and-testing-inference-service","text":"The workspace service provisions an App Service Plan and an App Service for hosting the inference webapp. The webapp will be integrated into the workspace network, allowing the webapp to connect to the AML workspace. Following the setup you will need to: Log onto a VM in the workspace and run: git clone https://gitea-<TRE_ID>.azurewebsites.net/giteaadmin/InnerEye-Inference cd InnerEye-Inference Create a file named \"set_environment.sh\" with the following variables as content: #!/bin/bash export CUSTOMCONNSTR_AZUREML_SERVICE_PRINCIPAL_SECRET = <inference_sp_client_secret-from-above> export CUSTOMCONNSTR_API_AUTH_SECRET = <generate-a-random-guid--that-is-used-for-authentication> export CLUSTER = <name-of-compute-cluster> export WORKSPACE_NAME = <name-of-AML-workspace> export EXPERIMENT_NAME = <name-of-AML-experiment> export RESOURCE_GROUP = <name-of-resource-group> export SUBSCRIPTION_ID = <subscription-id> export APPLICATION_ID = <inference_sp_client_id-from-above> export TENANT_ID = <tenant-id> export DATASTORE_NAME = inferencedatastore export IMAGE_DATA_FOLDER = imagedata Upload the configuration file to the web app: az webapp up --name <inference-app-name> -g <resource-group-name> Create a new container in your storage account for storing inference images called inferencedatastore . Create a new folder in that container called imagedata . Navigate to the ml.azure.com, Datastores and create a new datastore named inferencedatastore and connect it to the newly created container. Test the service by sending a GET or POST command using curl or Invoke-WebRequest where API_AUTH_SECRET is the random GUID generated for CUSTOMCONNSTR_API_AUTH_SECRET above: Simple ping: Invoke-WebRequest https://yourservicename.azurewebsites.net/v1/ping -Headers @{'Accept' = 'application/json'; 'API_AUTH_SECRET' = 'your-secret-1234-1123445'} Test connection with AML: Invoke-WebRequest https://yourservicename.azurewebsites.net/v1/model/start/HelloWorld:1 -Method POST -Headers @{'Accept' = 'application/json'; 'API_AUTH_SECRET' = 'your-secret-1234-1123445'}","title":"Configuring and testing inference service"},{"location":"tre-templates/workspace-services/mlflow/","text":"MLflow Workspace Service See: https://www.mlflow.org Prerequisites A base workspace deployed MLflow Workspace VM Configuration Each MLflow server deployment creates a PowerShell (for Windows) and a shell script (for Linux) with the same name as the MLflow server, in the shared storage mounted on the researcher VMs. These scripts will configure the researcher VMs (by installing the required packages and setting up the environment variables) to communicate with the MLflow tracking server. Note Please ensure that nexus reposiory is configured before running the above scripts. MLflow set tracking URI Researchers will be required to set the remote tracking URI in their scripts remote_server_uri = \"https://xxxxxxx.azurewebsites.net/\" mlflow . set_tracking_uri ( remote_server_uri ) Using with Conda-Forge If working with Conda-Forge you need to ensure the user resource you are using is configured correctly and using the channels available via the Nexus repository . If the user resource you have deployed used one of the pre-existing Guacamole user resource templates and has conda installed by default, conda will already be configured to use the correct channels via Nexus. If not and conda has been manually deployed on the user resource, the following script can be used to configure conda: conda config --add channels ${ nexus_proxy_url } /repository/conda/ --system conda config --add channels ${ nexus_proxy_url } /repository/conda-forge/ --system conda config --remove channels defaults --system conda config --set channel_alias ${ nexus_proxy_url } /repository/conda/ --system conda.yml When using a conda.yml file to configure your MLFlow environment it is required to specify the channels to use. As the traditional channels (conda-forge, defaults etc) have been replaced with Nexus channels, you must ensure that the Nexus channels are being specified here instead. To retireve these channels, run conda config --show channels once conda has been configured to use Nexus. Note When logging models using sklearn, an optional parameter conda_env can be passed as either JSON or YML. If this is not passed a default conda.yml will be generate for the model, targeting the channel conda-forge causing any subsequent environments created using the model to fail. See the official documentation here for the full details.","title":"MLFlow"},{"location":"tre-templates/workspace-services/mlflow/#mlflow-workspace-service","text":"See: https://www.mlflow.org","title":"MLflow Workspace Service"},{"location":"tre-templates/workspace-services/mlflow/#prerequisites","text":"A base workspace deployed","title":"Prerequisites"},{"location":"tre-templates/workspace-services/mlflow/#mlflow-workspace-vm-configuration","text":"Each MLflow server deployment creates a PowerShell (for Windows) and a shell script (for Linux) with the same name as the MLflow server, in the shared storage mounted on the researcher VMs. These scripts will configure the researcher VMs (by installing the required packages and setting up the environment variables) to communicate with the MLflow tracking server. Note Please ensure that nexus reposiory is configured before running the above scripts.","title":"MLflow Workspace VM Configuration"},{"location":"tre-templates/workspace-services/mlflow/#mlflow-set-tracking-uri","text":"Researchers will be required to set the remote tracking URI in their scripts remote_server_uri = \"https://xxxxxxx.azurewebsites.net/\" mlflow . set_tracking_uri ( remote_server_uri )","title":"MLflow set tracking URI"},{"location":"tre-templates/workspace-services/mlflow/#using-with-conda-forge","text":"If working with Conda-Forge you need to ensure the user resource you are using is configured correctly and using the channels available via the Nexus repository . If the user resource you have deployed used one of the pre-existing Guacamole user resource templates and has conda installed by default, conda will already be configured to use the correct channels via Nexus. If not and conda has been manually deployed on the user resource, the following script can be used to configure conda: conda config --add channels ${ nexus_proxy_url } /repository/conda/ --system conda config --add channels ${ nexus_proxy_url } /repository/conda-forge/ --system conda config --remove channels defaults --system conda config --set channel_alias ${ nexus_proxy_url } /repository/conda/ --system","title":"Using with Conda-Forge"},{"location":"tre-templates/workspace-services/mlflow/#condayml","text":"When using a conda.yml file to configure your MLFlow environment it is required to specify the channels to use. As the traditional channels (conda-forge, defaults etc) have been replaced with Nexus channels, you must ensure that the Nexus channels are being specified here instead. To retireve these channels, run conda config --show channels once conda has been configured to use Nexus. Note When logging models using sklearn, an optional parameter conda_env can be passed as either JSON or YML. If this is not passed a default conda.yml will be generate for the model, targeting the channel conda-forge causing any subsequent environments created using the model to fail. See the official documentation here for the full details.","title":"conda.yml"},{"location":"tre-templates/workspaces/airlock-import-review/","text":"Airlock Import Review workspace Airlock Import Review workspace is used as part of Review workflow for Airlock . It allows to review Airlock Data Import requests from, by providing a workspace to spin up VMs in that then can access the in-progress storage account. The workspace is built upon the base workspace template. It adds a private endpoint to connect to Imlort In-Progress storage account, and disables shared storage for VMs.","title":"Airlock Import Review"},{"location":"tre-templates/workspaces/airlock-import-review/#airlock-import-review-workspace","text":"Airlock Import Review workspace is used as part of Review workflow for Airlock . It allows to review Airlock Data Import requests from, by providing a workspace to spin up VMs in that then can access the in-progress storage account. The workspace is built upon the base workspace template. It adds a private endpoint to connect to Imlort In-Progress storage account, and disables shared storage for VMs.","title":"Airlock Import Review workspace"},{"location":"tre-templates/workspaces/base/","text":"Azure TRE base workspace The base workspace template is the foundation that all other workspaces and workspace services are built upon. Alternative workspace architectures could be used. However, the templates provided in this repository rely on the specific architecture of this base workspace. The base workspace template contains the following resources: Virtual Network Storage Account Key Vault VNet Peer to Core VNet Network Security Group App Service Plan Workspace Configuration When deploying a workspace the following properties need to be configured. Required Properties Property Options Description client_id Valid client ID of the Workspace App Registration. The OpenID client ID which should be submitted to the OpenID service when necessary. This value is typically provided to you by the OpenID service when OpenID credentials are generated for your application. client_secret Valid client secret. Azure Trusted Services Azure Trusted Services are allowed to connect to both the key vault and storage account provsioned within the workspace. If this is undesirable additonal resources without this setting configured can be deployed. Further details around which Azure services are allowed to connect can be found below: Key Vault: https://docs.microsoft.com/en-us/azure/key-vault/general/overview-vnet-service-endpoints#trusted-services Azure Storage: https://docs.microsoft.com/en-us/azure/storage/common/storage-network-security?msclkid=ee4e79e4b97911eca46dae54da464d11&tabs=azure-portal#trusted-access-for-resources-registered-in-your-subscription","title":"Base"},{"location":"tre-templates/workspaces/base/#azure-tre-base-workspace","text":"The base workspace template is the foundation that all other workspaces and workspace services are built upon. Alternative workspace architectures could be used. However, the templates provided in this repository rely on the specific architecture of this base workspace. The base workspace template contains the following resources: Virtual Network Storage Account Key Vault VNet Peer to Core VNet Network Security Group App Service Plan","title":"Azure TRE base workspace"},{"location":"tre-templates/workspaces/base/#workspace-configuration","text":"When deploying a workspace the following properties need to be configured.","title":"Workspace Configuration"},{"location":"tre-templates/workspaces/base/#required-properties","text":"Property Options Description client_id Valid client ID of the Workspace App Registration. The OpenID client ID which should be submitted to the OpenID service when necessary. This value is typically provided to you by the OpenID service when OpenID credentials are generated for your application. client_secret Valid client secret.","title":"Required Properties"},{"location":"tre-templates/workspaces/base/#azure-trusted-services","text":"Azure Trusted Services are allowed to connect to both the key vault and storage account provsioned within the workspace. If this is undesirable additonal resources without this setting configured can be deployed. Further details around which Azure services are allowed to connect can be found below: Key Vault: https://docs.microsoft.com/en-us/azure/key-vault/general/overview-vnet-service-endpoints#trusted-services Azure Storage: https://docs.microsoft.com/en-us/azure/storage/common/storage-network-security?msclkid=ee4e79e4b97911eca46dae54da464d11&tabs=azure-portal#trusted-access-for-resources-registered-in-your-subscription","title":"Azure Trusted Services"},{"location":"tre-templates/workspaces/unrestricted/","text":"Unrestricted workspace The unrestricted workspace template is a workspace template that allows for unrestricted access to the Internet from inside the workspace virtual network. This is useful for working on open data sets where data exfiltration is not a concern. This workspace template builds upon the base workspace template by adding additional firewall rules and disabling the airlock.","title":"Unrestricted"},{"location":"tre-templates/workspaces/unrestricted/#unrestricted-workspace","text":"The unrestricted workspace template is a workspace template that allows for unrestricted access to the Internet from inside the workspace virtual network. This is useful for working on open data sets where data exfiltration is not a concern. This workspace template builds upon the base workspace template by adding additional firewall rules and disabling the airlock.","title":"Unrestricted workspace"},{"location":"tre-workspace-authors/authoring-workspace-templates/","text":"Authoring templates Azure TRE workspaces, workspace services, shared services, and user resources are Porter bundles. Porter bundles are based on Cloud Native Application Bundles (CNAB) . Authors are free to choose the technology stack for provisioning resources (e.g., ARM templates, Terraform etc.), but the Azure TRE framework sets certain requirements for the bundle manifests, which specify the credentials, input and output parameters, deployment actions among other things. This document describes the requirements, and the process to author a template. Tip Use the base workspace bundle as reference or as the basis for the new bundle. To create a bundle from scratch follow the Porter Quickstart Guide ( porter create CLI command will generate a new bundle in the current directory). Read more about Porter in Resource Processor doc . Prerequisites Docker installed Porter installed Azure TRE instance deployed to test against Workspace bundle manifest The manifest of a workspace bundle is the porter.yaml file (see Author Bundles in Porter documentation ). This section describes the mandatory credentials, input and output parameters of a TRE workspace bundle. Credentials A workspace bundle requires the following credentials to provision resources in Azure: Azure tenant ID Azure subscription ID The client ID of a service principal with privileges to provision resources The client secret (password) of a service principal The credentials are provided as environment variables by the deployment runner. The bundle author must use the following environment variable names: ARM_TENANT_ID ARM_SUBSCRIPTION_ID ARM_CLIENT_ID ARM_CLIENT_SECRET The names of the Porter credentials ( name field in porter.yaml ) can be freely chosen by the author. Example: credentials : - name : azure_tenant_id env : ARM_TENANT_ID - name : azure_subscription_id env : ARM_SUBSCRIPTION_ID - name : azure_client_id env : ARM_CLIENT_ID - name : azure_client_secret env : ARM_CLIENT_SECRET Parameters This section describes the mandatory (input) parameters of a workspace bundle manifest. Parameter Type Description Example value tre_id string Unique ID of for the TRE instance. tre-dev-42 workspace_id string Unique 4-character long, alphanumeric workspace ID. 0a9e azure_location string Azure location (region) to deploy the workspace resource to. westeurope address_space string VNet address space for the workspace services. 10.2.1.0/24 tre_id can be found in the resource names of the Azure TRE instance; for example the resource group name of the Azure TRE instance based on the example in the above table would be \" rg-tre-dev-42 \". Similarly to tre_id , workspace_id is used in the resource names of the workspace. The resource group name of the workspace must be of form \" rg-<tre_id>-ws-<workspace_id> \", for example: \" rg-tre-dev-42-ws-0a9e \". All the values for the required parameters will be provided by the deployment runner. Any custom parameters are picked up by Azure TRE API and will be queried from the user deploying the workspace bundle. Custom parameters should also be defined in the template_schema.json file at the root of the bundle. This file follows the JSON schema standard and can be used by a user interface to generate a UI for the user to input the parameters. Output Todo After a workspace with virtual machines is implemented this section can be written based on that. ( Outputs in Porter documentation to be linked here too.) Actions The required actions are the main two of CNAB spec: install - Deploys/repairs the workspace Azure resources, and must be idempotent uninstall - Tears down (deletes) the Azure resources of the workspace and its services Workspace service bundle manifests Workspace service bundles are generated in the same way as workspace bundles. The mandatory parameters for workspace services are: Parameter Type Description Example value tre_id string Unique ID of for the TRE instance. tre-dev-42 workspace_id string Unique 4-character long, alphanumeric workspace ID. 0a9e User resource bundle manifests User Resource bundles are generated in the same way as workspace bundles and workspace services bundles. The main difference is that a workspace service type needs to be supplied when registering a user resource template, as it only applies to a given workspace service. The mandatory parameters for User Resources are: Parameter Type Description Example value tre_id string Unique ID of for the TRE instance. tre-dev-42 workspace_id string Unique 4-character long, alphanumeric workspace ID. 0a9e Azure Resources Tagging TRE Cost Reporting is based on Azure tagging to be able to generate cost report for core services, shared services, workspace, workspace services and user resources. Templates authors need to make sure that underling Azure resources are tagged with the relevent tags, for more information see cost reporting : Versioning Workspace versions are the bundle versions specified in the metadata . The bundle versions should match the image tags in the container registry (see Publishing workspace bundle ). Bundle versions should follow Semantic Versioning , given a version number MAJOR.MINOR.PATCH , increment the: MAJOR version when you make a breaking change, potential data loss, changes that don't easily/automatically upgrade, or significant changes which require someone to review what has changed and take some appropriate action, or functionality of the component has significantly changed and users might need training. MINOR version when you add minor functionality which can be automatically upgraded. PATCH version when you make backward-compatible bug or typo fixes. For resource version upgrades see Upgrading Resources Version . Publishing workspace bundle See Registering workspace templates . Manual Deployment Caution Resources should be deployed using the API (i.e. through the Swagger UI as described in the setup instructions ). Only deploy manually for development/testing purposes. Create a copy of the Porter bundle's environment settings from /templates/<scope>/.env.sample with the name .env and update the variables with the appropriate values. Build and deploy the Porter bundle make bundle-build DIR=./templates/<scope>/<bundle_name> make bundle-publish DIR=./templates/<scope>/<bundle_name> make bundle-register DIR=./templates/<scope>/<bundle_name> BUNDLE_TYPE=<scope>","title":"Authoring Workspace Templates"},{"location":"tre-workspace-authors/authoring-workspace-templates/#authoring-templates","text":"Azure TRE workspaces, workspace services, shared services, and user resources are Porter bundles. Porter bundles are based on Cloud Native Application Bundles (CNAB) . Authors are free to choose the technology stack for provisioning resources (e.g., ARM templates, Terraform etc.), but the Azure TRE framework sets certain requirements for the bundle manifests, which specify the credentials, input and output parameters, deployment actions among other things. This document describes the requirements, and the process to author a template. Tip Use the base workspace bundle as reference or as the basis for the new bundle. To create a bundle from scratch follow the Porter Quickstart Guide ( porter create CLI command will generate a new bundle in the current directory). Read more about Porter in Resource Processor doc .","title":"Authoring templates"},{"location":"tre-workspace-authors/authoring-workspace-templates/#prerequisites","text":"Docker installed Porter installed Azure TRE instance deployed to test against","title":"Prerequisites"},{"location":"tre-workspace-authors/authoring-workspace-templates/#workspace-bundle-manifest","text":"The manifest of a workspace bundle is the porter.yaml file (see Author Bundles in Porter documentation ). This section describes the mandatory credentials, input and output parameters of a TRE workspace bundle.","title":"Workspace bundle manifest"},{"location":"tre-workspace-authors/authoring-workspace-templates/#credentials","text":"A workspace bundle requires the following credentials to provision resources in Azure: Azure tenant ID Azure subscription ID The client ID of a service principal with privileges to provision resources The client secret (password) of a service principal The credentials are provided as environment variables by the deployment runner. The bundle author must use the following environment variable names: ARM_TENANT_ID ARM_SUBSCRIPTION_ID ARM_CLIENT_ID ARM_CLIENT_SECRET The names of the Porter credentials ( name field in porter.yaml ) can be freely chosen by the author. Example: credentials : - name : azure_tenant_id env : ARM_TENANT_ID - name : azure_subscription_id env : ARM_SUBSCRIPTION_ID - name : azure_client_id env : ARM_CLIENT_ID - name : azure_client_secret env : ARM_CLIENT_SECRET","title":"Credentials"},{"location":"tre-workspace-authors/authoring-workspace-templates/#parameters","text":"This section describes the mandatory (input) parameters of a workspace bundle manifest. Parameter Type Description Example value tre_id string Unique ID of for the TRE instance. tre-dev-42 workspace_id string Unique 4-character long, alphanumeric workspace ID. 0a9e azure_location string Azure location (region) to deploy the workspace resource to. westeurope address_space string VNet address space for the workspace services. 10.2.1.0/24 tre_id can be found in the resource names of the Azure TRE instance; for example the resource group name of the Azure TRE instance based on the example in the above table would be \" rg-tre-dev-42 \". Similarly to tre_id , workspace_id is used in the resource names of the workspace. The resource group name of the workspace must be of form \" rg-<tre_id>-ws-<workspace_id> \", for example: \" rg-tre-dev-42-ws-0a9e \". All the values for the required parameters will be provided by the deployment runner. Any custom parameters are picked up by Azure TRE API and will be queried from the user deploying the workspace bundle. Custom parameters should also be defined in the template_schema.json file at the root of the bundle. This file follows the JSON schema standard and can be used by a user interface to generate a UI for the user to input the parameters.","title":"Parameters"},{"location":"tre-workspace-authors/authoring-workspace-templates/#output","text":"Todo After a workspace with virtual machines is implemented this section can be written based on that. ( Outputs in Porter documentation to be linked here too.)","title":"Output"},{"location":"tre-workspace-authors/authoring-workspace-templates/#actions","text":"The required actions are the main two of CNAB spec: install - Deploys/repairs the workspace Azure resources, and must be idempotent uninstall - Tears down (deletes) the Azure resources of the workspace and its services","title":"Actions"},{"location":"tre-workspace-authors/authoring-workspace-templates/#workspace-service-bundle-manifests","text":"Workspace service bundles are generated in the same way as workspace bundles. The mandatory parameters for workspace services are: Parameter Type Description Example value tre_id string Unique ID of for the TRE instance. tre-dev-42 workspace_id string Unique 4-character long, alphanumeric workspace ID. 0a9e","title":"Workspace service bundle manifests"},{"location":"tre-workspace-authors/authoring-workspace-templates/#user-resource-bundle-manifests","text":"User Resource bundles are generated in the same way as workspace bundles and workspace services bundles. The main difference is that a workspace service type needs to be supplied when registering a user resource template, as it only applies to a given workspace service. The mandatory parameters for User Resources are: Parameter Type Description Example value tre_id string Unique ID of for the TRE instance. tre-dev-42 workspace_id string Unique 4-character long, alphanumeric workspace ID. 0a9e","title":"User resource bundle manifests"},{"location":"tre-workspace-authors/authoring-workspace-templates/#azure-resources-tagging","text":"TRE Cost Reporting is based on Azure tagging to be able to generate cost report for core services, shared services, workspace, workspace services and user resources. Templates authors need to make sure that underling Azure resources are tagged with the relevent tags, for more information see cost reporting :","title":"Azure Resources Tagging"},{"location":"tre-workspace-authors/authoring-workspace-templates/#versioning","text":"Workspace versions are the bundle versions specified in the metadata . The bundle versions should match the image tags in the container registry (see Publishing workspace bundle ). Bundle versions should follow Semantic Versioning , given a version number MAJOR.MINOR.PATCH , increment the: MAJOR version when you make a breaking change, potential data loss, changes that don't easily/automatically upgrade, or significant changes which require someone to review what has changed and take some appropriate action, or functionality of the component has significantly changed and users might need training. MINOR version when you add minor functionality which can be automatically upgraded. PATCH version when you make backward-compatible bug or typo fixes. For resource version upgrades see Upgrading Resources Version .","title":"Versioning"},{"location":"tre-workspace-authors/authoring-workspace-templates/#publishing-workspace-bundle","text":"See Registering workspace templates .","title":"Publishing workspace bundle"},{"location":"tre-workspace-authors/authoring-workspace-templates/#manual-deployment","text":"Caution Resources should be deployed using the API (i.e. through the Swagger UI as described in the setup instructions ). Only deploy manually for development/testing purposes. Create a copy of the Porter bundle's environment settings from /templates/<scope>/.env.sample with the name .env and update the variables with the appropriate values. Build and deploy the Porter bundle make bundle-build DIR=./templates/<scope>/<bundle_name> make bundle-publish DIR=./templates/<scope>/<bundle_name> make bundle-register DIR=./templates/<scope>/<bundle_name> BUNDLE_TYPE=<scope>","title":"Manual Deployment"},{"location":"tre-workspace-authors/firewall-rules/","text":"Adding Firewall Rules as part of a workspace or service deployment Note Creating firewall rules will in the future only be allowed through the firewall shared services #882 . A TRE service may require certain firewall rules to be opened in the TRE firewall. Examples include: Access to an external authorisation endpoint Access to an external data store Access to an external API Please be aware when opening firewall rules there is the potential for data to be leaked from the workspace to the external location. Using Terraform to open firewall rules Until a mechanism to update shared services has been implemented, firewall rule updates should be done using terraform as part of the service deployment. The aim is to create a firewall rule that grants access from the workspace's address space to the external location. A challenge with this is that the rule must use a priority that has not been used by any other rule. Create a firewall.tf file in the terraform directory of the workspace. Add the following code to the firewall.tf file to enable the TRE firewall and workspace network to be referenced: data \"azurerm_firewall\" \"fw\" { name = \"fw-${var.tre_id}\" resource_group_name = \"rg-${var.tre_id}\" } data \"azurerm_virtual_network\" \"ws\" { name = \"vnet-${var.tre_id}-ws-${var.workspace_id}\" resource_group_name = data.azurerm_resource_group.ws.name } Define a local variable that contains the locations that access should be allowed to, and the naming format for the service resources for example: locals { allowed_urls = [ \"*.anaconda.com\", \"*.anaconda.org\" ] service_resource_name_suffix = \"${var.tre_id}-ws-${var.workspace_id}-svc-${local.service_id}\" } Log into the Azure CLI using service principal details: resource \"null_resource\" \"az_login\" { provisioner \"local-exec\" { command = \"az login --identity -u '${var.arm_client_id}'\" } triggers = { timestamp = timestamp () } } Call the get_firewall_priorities.sh script to find the next available priority: data \"external\" \"rule_priorities\" { program = [ \"bash\", \"-c\", \"./get_firewall_priorities.sh\" ] query = { firewall_name = data.azurerm_firewall.fw.name resource_group_name = data.azurerm_firewall.fw.resource_group_name service_resource_name_suffix = local.service_resource_name_suffix } depends_on = [ null_resource.az_login ] } Save the get_firewall_priorities.sh script as a file in the terraform directory: #!/bin/bash set -e eval \" $( jq -r '@sh \"firewall_name=\\(.firewall_name) resource_group_name=\\(.resource_group_name) service_resource_name_suffix=\\(.service_resource_name_suffix)\"' ) \" if NETWORK_RULES = $( az network firewall network-rule list -g $resource_group_name -f $firewall_name --collection-name \"nrc- $service_resource_name_suffix \" -o json ) ; then NETWORK_RULE_PRIORITY = $( echo $NETWORK_RULES | jq '.priority' ) else NETWORK_RULE_MAX_PRIORITY = $( az network firewall network-rule collection list -f $firewall_name -g $resource_group_name -o json --query 'not_null(max_by([],&priority).priority) || `100`' ) NETWORK_RULE_PRIORITY = $(( $NETWORK_RULE_MAX_PRIORITY + 1 )) fi if APPLICATION_RULES = $( az network firewall application-rule list -g $resource_group_name -f $firewall_name --collection-name \"arc- $service_resource_name_suffix \" -o json ) ; then APPLICATION_RULE_PRIORITY = $( echo $APPLICATION_RULES | jq '.priority' ) else APPLICATION_RULE_MAX_PRIORITY = $( az network firewall application-rule collection list -f $firewall_name -g $resource_group_name -o json --query 'not_null(max_by([],&priority).priority) || `100`' ) APPLICATION_RULE_PRIORITY = $(( $APPLICATION_RULE_MAX_PRIORITY + 1 )) fi # Safely produce a JSON object containing the result value. jq -n --arg network_rule_priority \" $NETWORK_RULE_PRIORITY \" --arg application_rule_priority \" $APPLICATION_RULE_PRIORITY \" '{ \"network_rule_priority\":$network_rule_priority, \"application_rule_priority\":$application_rule_priority }' Create the firewall rule using a resource similar to the below: resource \"azurerm_firewall_application_rule_collection\" \"apprulecollection\" { name = \"arc-${local.service_resource_name_suffix}\" azure_firewall_name = data.azurerm_firewall.fw.name resource_group_name = data.azurerm_firewall.fw.resource_group_name priority = data.external.rule_priorities.result.application_rule_priority action = \"Allow\" rule { name = \"allowServiceXRules\" source_addresses = data.azurerm_virtual_network.ws.address_space target_fqdns = local.allowed_urls protocol { port = \"443\" type = \"Https\" } protocol { port = \"80\" type = \"Http\" } } }","title":"Firewall Rules"},{"location":"tre-workspace-authors/firewall-rules/#adding-firewall-rules-as-part-of-a-workspace-or-service-deployment","text":"Note Creating firewall rules will in the future only be allowed through the firewall shared services #882 . A TRE service may require certain firewall rules to be opened in the TRE firewall. Examples include: Access to an external authorisation endpoint Access to an external data store Access to an external API Please be aware when opening firewall rules there is the potential for data to be leaked from the workspace to the external location.","title":"Adding Firewall Rules as part of a workspace or service deployment"},{"location":"tre-workspace-authors/firewall-rules/#using-terraform-to-open-firewall-rules","text":"Until a mechanism to update shared services has been implemented, firewall rule updates should be done using terraform as part of the service deployment. The aim is to create a firewall rule that grants access from the workspace's address space to the external location. A challenge with this is that the rule must use a priority that has not been used by any other rule. Create a firewall.tf file in the terraform directory of the workspace. Add the following code to the firewall.tf file to enable the TRE firewall and workspace network to be referenced: data \"azurerm_firewall\" \"fw\" { name = \"fw-${var.tre_id}\" resource_group_name = \"rg-${var.tre_id}\" } data \"azurerm_virtual_network\" \"ws\" { name = \"vnet-${var.tre_id}-ws-${var.workspace_id}\" resource_group_name = data.azurerm_resource_group.ws.name } Define a local variable that contains the locations that access should be allowed to, and the naming format for the service resources for example: locals { allowed_urls = [ \"*.anaconda.com\", \"*.anaconda.org\" ] service_resource_name_suffix = \"${var.tre_id}-ws-${var.workspace_id}-svc-${local.service_id}\" } Log into the Azure CLI using service principal details: resource \"null_resource\" \"az_login\" { provisioner \"local-exec\" { command = \"az login --identity -u '${var.arm_client_id}'\" } triggers = { timestamp = timestamp () } } Call the get_firewall_priorities.sh script to find the next available priority: data \"external\" \"rule_priorities\" { program = [ \"bash\", \"-c\", \"./get_firewall_priorities.sh\" ] query = { firewall_name = data.azurerm_firewall.fw.name resource_group_name = data.azurerm_firewall.fw.resource_group_name service_resource_name_suffix = local.service_resource_name_suffix } depends_on = [ null_resource.az_login ] } Save the get_firewall_priorities.sh script as a file in the terraform directory: #!/bin/bash set -e eval \" $( jq -r '@sh \"firewall_name=\\(.firewall_name) resource_group_name=\\(.resource_group_name) service_resource_name_suffix=\\(.service_resource_name_suffix)\"' ) \" if NETWORK_RULES = $( az network firewall network-rule list -g $resource_group_name -f $firewall_name --collection-name \"nrc- $service_resource_name_suffix \" -o json ) ; then NETWORK_RULE_PRIORITY = $( echo $NETWORK_RULES | jq '.priority' ) else NETWORK_RULE_MAX_PRIORITY = $( az network firewall network-rule collection list -f $firewall_name -g $resource_group_name -o json --query 'not_null(max_by([],&priority).priority) || `100`' ) NETWORK_RULE_PRIORITY = $(( $NETWORK_RULE_MAX_PRIORITY + 1 )) fi if APPLICATION_RULES = $( az network firewall application-rule list -g $resource_group_name -f $firewall_name --collection-name \"arc- $service_resource_name_suffix \" -o json ) ; then APPLICATION_RULE_PRIORITY = $( echo $APPLICATION_RULES | jq '.priority' ) else APPLICATION_RULE_MAX_PRIORITY = $( az network firewall application-rule collection list -f $firewall_name -g $resource_group_name -o json --query 'not_null(max_by([],&priority).priority) || `100`' ) APPLICATION_RULE_PRIORITY = $(( $APPLICATION_RULE_MAX_PRIORITY + 1 )) fi # Safely produce a JSON object containing the result value. jq -n --arg network_rule_priority \" $NETWORK_RULE_PRIORITY \" --arg application_rule_priority \" $APPLICATION_RULE_PRIORITY \" '{ \"network_rule_priority\":$network_rule_priority, \"application_rule_priority\":$application_rule_priority }' Create the firewall rule using a resource similar to the below: resource \"azurerm_firewall_application_rule_collection\" \"apprulecollection\" { name = \"arc-${local.service_resource_name_suffix}\" azure_firewall_name = data.azurerm_firewall.fw.name resource_group_name = data.azurerm_firewall.fw.resource_group_name priority = data.external.rule_priorities.result.application_rule_priority action = \"Allow\" rule { name = \"allowServiceXRules\" source_addresses = data.azurerm_virtual_network.ws.address_space target_fqdns = local.allowed_urls protocol { port = \"443\" type = \"Https\" } protocol { port = \"80\" type = \"Http\" } } }","title":"Using Terraform to open firewall rules"},{"location":"troubleshooting-faq/","text":"Operations Debugging and Troubleshooting guide This guide explains how to go about finding the root cause of why a workspace resource might not have been deployed. The topics included in this section should be followed in order as that is how the message also flows in the system.","title":"Operations Debugging and Troubleshooting guide"},{"location":"troubleshooting-faq/#operations-debugging-and-troubleshooting-guide","text":"This guide explains how to go about finding the root cause of why a workspace resource might not have been deployed. The topics included in this section should be followed in order as that is how the message also flows in the system.","title":"Operations Debugging and Troubleshooting guide"},{"location":"troubleshooting-faq/api-logs-deployment-center/","text":"API logs using deployment center Check that the version you are debugging/troubleshooting is the same one deployed on the App Service. You can check this in Azure's Deployment Center, or follow the logs as generated by the container in the logs tabs.","title":"API logs using deployment center"},{"location":"troubleshooting-faq/api-logs-deployment-center/#api-logs-using-deployment-center","text":"Check that the version you are debugging/troubleshooting is the same one deployed on the App Service. You can check this in Azure's Deployment Center, or follow the logs as generated by the container in the logs tabs.","title":"API logs using deployment center"},{"location":"troubleshooting-faq/app-insights-logs/","text":"Checking the logs in App Insights Every component of TRE should send their trace logs to App Insights logging backend, and you should be able to see the process flow by using a suitable query. Note AppTraces can take time to appear so be patient. Go to the deployed app insights instance and select Monitoring > Logs where you can run the following example query to get the logs for a specific deployment. let tracking_id=\"<workspace_id>\"; AppTraces | where Message has tracking_id or OperationId == tracking_id | sort by TimeGenerated desc For a successful deployment you should see a message similiar to: Received deployment status update message with correlation ID 70b09db1-30c4-475c-b1a1-8f9599a5a2f4: {'id': '70b09db1-30c4-475c-b1a1-8f9599a5a2f4', 'status': 'deployed', 'message': 'cse-msr-dev-b7f6: Workspace was deployed successfully...'} It should also be evident from the message flow where the current processing is stuck or failed. Failed deployment status should also be available in the GET /api/workspaces/{workspace_id} and this is just another way to confirm it.","title":"Checking Logs in Application Insights"},{"location":"troubleshooting-faq/app-insights-logs/#checking-the-logs-in-app-insights","text":"Every component of TRE should send their trace logs to App Insights logging backend, and you should be able to see the process flow by using a suitable query. Note AppTraces can take time to appear so be patient. Go to the deployed app insights instance and select Monitoring > Logs where you can run the following example query to get the logs for a specific deployment. let tracking_id=\"<workspace_id>\"; AppTraces | where Message has tracking_id or OperationId == tracking_id | sort by TimeGenerated desc For a successful deployment you should see a message similiar to: Received deployment status update message with correlation ID 70b09db1-30c4-475c-b1a1-8f9599a5a2f4: {'id': '70b09db1-30c4-475c-b1a1-8f9599a5a2f4', 'status': 'deployed', 'message': 'cse-msr-dev-b7f6: Workspace was deployed successfully...'} It should also be evident from the message flow where the current processing is stuck or failed. Failed deployment status should also be available in the GET /api/workspaces/{workspace_id} and this is just another way to confirm it.","title":"Checking the logs in App Insights"},{"location":"troubleshooting-faq/debug-api/","text":"Enabling DEBUG mode on the API The API is by default configured to not show detailed error messages and stack trace when an error occurs. This is done to prevent leaking internal state to the outside world and to minimize information which an attacker could use against the deployed instance. However, you can enable debugging, by setting DEBUG=true in the configuration settings of the API using Azure portal. Go to App Service for the API and select Settings > Configuration . Click New Application Setting . in the new dialog box set Name=DEBUG and Value=true","title":"Enabling Debugging for the API"},{"location":"troubleshooting-faq/debug-api/#enabling-debug-mode-on-the-api","text":"The API is by default configured to not show detailed error messages and stack trace when an error occurs. This is done to prevent leaking internal state to the outside world and to minimize information which an attacker could use against the deployed instance. However, you can enable debugging, by setting DEBUG=true in the configuration settings of the API using Azure portal. Go to App Service for the API and select Settings > Configuration . Click New Application Setting . in the new dialog box set Name=DEBUG and Value=true","title":"Enabling DEBUG mode on the API"},{"location":"troubleshooting-faq/manually-editing-resources/","text":"Manually editing resources in Cosmos DB On occasion, resources in the TRE (i.e. a user resource, workspace service or workspace) can get into a corrupted state, usually when an operation performed by the API and Resource Processor has failed and has not been gracefully handled. This can leave the resource state stored in Cosmos out of sync with the state of the resource in Azure. For scenarios where you need to manually modify the state of the TRE resource, you can use the following guide. Caution This should only be performed when absolutely necessary. Modifying properties in a resource to unexpected/inaccurate values can cause various failures when the API/RP performs a subsequent operation on it. Find the Resource Id We want to make sure we find the correct resource record in Cosmos before modifying it; we can do this by locating the Resource Id of the resource we wish to modify so we can correlate it later on. If you don't already know the Resource Id, follow one of the sub-sections below; otherwise, skip to Access Cosmos DB . Using the TRE UI Navigate to the UI in your browser (typically {YOUR_TRE_ID}.{REGION}.cloudapp.azure.com ) Find the resource card of the resource you wish to modify, then click the i button and copy the Resource Id Using the TRE API Head to the Swagger UI (typically {YOUR_TRE_ID}.{REGION}.cloudapp.azure.com/api/docs ) - If looking for a resource within a workspace (i.e. a workspace service or user resource), you will instead need to open /api/workspaces/{WORKSPACE_ID}/docs Click Authorize and authenticate Find the GET method for the resource type you're looking for, hit Try it out , fill in any required parameters, then click Execute . Locate the item you're interested in within the response array and copy the value from the id field Access Cosmos DB Find your Azure TRE main resource group (typically rg-{YOUR_TRE_ID} ) in the Azure Portal and select the Cosmos DB instance ( cosmos-{YOUR_TRE_ID} ) In the side-menu, select the Networking tab and click Add my current IP then Save to whitelist your IP in the Cosmos DB firewall. This will start an operation that will take a few minutes to complete. You can check the status of this in the Notifications panel of the portal. Edit resource Once the operation to whitelist your IP has completed, navigate to the Data Explorer pane, and you should see a list of collections. Select the appropriate one that you intend to modify (most likely Resources , which contains all of the deployed resources within your TRE), then select Items . Click Edit Filter and enter WHERE c.id = \"{YOUR_RESOURCE_ID}\" , then press Apply Filter . Select the only document in the list. You can now edit the JSON object within the Data Explorer editor, then hit Update when you're done. This will immediately update the resource in Cosmos DB. Caution Don't forget to remove your IP from the Cosmos firewall whitelist when you're done!","title":"Manually edit resources in Cosmos DB"},{"location":"troubleshooting-faq/manually-editing-resources/#manually-editing-resources-in-cosmos-db","text":"On occasion, resources in the TRE (i.e. a user resource, workspace service or workspace) can get into a corrupted state, usually when an operation performed by the API and Resource Processor has failed and has not been gracefully handled. This can leave the resource state stored in Cosmos out of sync with the state of the resource in Azure. For scenarios where you need to manually modify the state of the TRE resource, you can use the following guide. Caution This should only be performed when absolutely necessary. Modifying properties in a resource to unexpected/inaccurate values can cause various failures when the API/RP performs a subsequent operation on it.","title":"Manually editing resources in Cosmos DB"},{"location":"troubleshooting-faq/manually-editing-resources/#find-the-resource-id","text":"We want to make sure we find the correct resource record in Cosmos before modifying it; we can do this by locating the Resource Id of the resource we wish to modify so we can correlate it later on. If you don't already know the Resource Id, follow one of the sub-sections below; otherwise, skip to Access Cosmos DB .","title":"Find the Resource Id"},{"location":"troubleshooting-faq/manually-editing-resources/#using-the-tre-ui","text":"Navigate to the UI in your browser (typically {YOUR_TRE_ID}.{REGION}.cloudapp.azure.com ) Find the resource card of the resource you wish to modify, then click the i button and copy the Resource Id","title":"Using the TRE UI"},{"location":"troubleshooting-faq/manually-editing-resources/#using-the-tre-api","text":"Head to the Swagger UI (typically {YOUR_TRE_ID}.{REGION}.cloudapp.azure.com/api/docs ) - If looking for a resource within a workspace (i.e. a workspace service or user resource), you will instead need to open /api/workspaces/{WORKSPACE_ID}/docs Click Authorize and authenticate Find the GET method for the resource type you're looking for, hit Try it out , fill in any required parameters, then click Execute . Locate the item you're interested in within the response array and copy the value from the id field","title":"Using the TRE API"},{"location":"troubleshooting-faq/manually-editing-resources/#access-cosmos-db","text":"Find your Azure TRE main resource group (typically rg-{YOUR_TRE_ID} ) in the Azure Portal and select the Cosmos DB instance ( cosmos-{YOUR_TRE_ID} ) In the side-menu, select the Networking tab and click Add my current IP then Save to whitelist your IP in the Cosmos DB firewall. This will start an operation that will take a few minutes to complete. You can check the status of this in the Notifications panel of the portal.","title":"Access Cosmos DB"},{"location":"troubleshooting-faq/manually-editing-resources/#edit-resource","text":"Once the operation to whitelist your IP has completed, navigate to the Data Explorer pane, and you should see a list of collections. Select the appropriate one that you intend to modify (most likely Resources , which contains all of the deployed resources within your TRE), then select Items . Click Edit Filter and enter WHERE c.id = \"{YOUR_RESOURCE_ID}\" , then press Apply Filter . Select the only document in the list. You can now edit the JSON object within the Data Explorer editor, then hit Update when you're done. This will immediately update the resource in Cosmos DB. Caution Don't forget to remove your IP from the Cosmos firewall whitelist when you're done!","title":"Edit resource"},{"location":"troubleshooting-faq/troubleshooting-rp/","text":"Checking the Virtual Machine Scale Set (VMSS) instance running resource processor If you see messages hanging in the service bus queue then the resource processor is not up and running. Verify that the VMSS instance is up and healthy. The processor runs in a VNET, and you cannot connect to it directly. Connect to the instance using Bastion. Bastion is already deployed, and you can use the username adminuser . The password is stored in the keyvault under the secret resource-processor-vmss-password Info You cannot see secrets unless you are added to a suitable access policy for the Key Vault. After logging in you should check the status of cloud-init which is used to bootstrap the machine with docker and start the processor. Log files for cloud init are: /var/log/cloud-init.log /var/log/cloud-init-output.log If the Docker container is pulled as shown in logs then the resource processor should start. Check the status of the container using docker ps If you see nothing (and the container was pulled) then the processor has either not started yet or it has crashed. Check the status of all Docker processes using docker ps -a which should show you if the container terminated prematurely. Get the logs from the container using docker logs <container_id> command. To start a processor container manually: Find the runner_image:tag by running docker ps Execute the following command from the root (/) of the file system docker run -v /var/run/docker.sock:/var/run/docker.sock --env-file .env --name resource_processor_vmss_porter_debug [runner_image:tag] Info All logs from the resource processor should also be transferred to the App Insights instance, so it is not necessary to follow the progress by logging into the instance. Logging into the instance and starting a container manually however, is helpful in live debugging. Updating the running container If you start a container manually you will probably want to install software, for example, an editor. However, the firewall blocks all ingress traffic, so you cannot run sudo apt update . You need to add an override rule in the firewall to allow the traffic. Caution Remember to remove this rule when debugging is done.","title":"Troubleshooting the Resource Processor"},{"location":"troubleshooting-faq/troubleshooting-rp/#checking-the-virtual-machine-scale-set-vmss-instance-running-resource-processor","text":"If you see messages hanging in the service bus queue then the resource processor is not up and running. Verify that the VMSS instance is up and healthy. The processor runs in a VNET, and you cannot connect to it directly. Connect to the instance using Bastion. Bastion is already deployed, and you can use the username adminuser . The password is stored in the keyvault under the secret resource-processor-vmss-password Info You cannot see secrets unless you are added to a suitable access policy for the Key Vault. After logging in you should check the status of cloud-init which is used to bootstrap the machine with docker and start the processor. Log files for cloud init are: /var/log/cloud-init.log /var/log/cloud-init-output.log If the Docker container is pulled as shown in logs then the resource processor should start. Check the status of the container using docker ps If you see nothing (and the container was pulled) then the processor has either not started yet or it has crashed. Check the status of all Docker processes using docker ps -a which should show you if the container terminated prematurely. Get the logs from the container using docker logs <container_id> command. To start a processor container manually: Find the runner_image:tag by running docker ps Execute the following command from the root (/) of the file system docker run -v /var/run/docker.sock:/var/run/docker.sock --env-file .env --name resource_processor_vmss_porter_debug [runner_image:tag] Info All logs from the resource processor should also be transferred to the App Insights instance, so it is not necessary to follow the progress by logging into the instance. Logging into the instance and starting a container manually however, is helpful in live debugging.","title":"Checking the Virtual Machine Scale Set (VMSS) instance running resource processor"},{"location":"troubleshooting-faq/troubleshooting-rp/#updating-the-running-container","text":"If you start a container manually you will probably want to install software, for example, an editor. However, the firewall blocks all ingress traffic, so you cannot run sudo apt update . You need to add an override rule in the firewall to allow the traffic. Caution Remember to remove this rule when debugging is done.","title":"Updating the running container"},{"location":"troubleshooting-faq/troubleshooting-sb/","text":"Checking the Service Bus If the message payload is accepted by the API, and a workspace_id is generated, you should be able to track the progress of the deployment using GET /api/workspaces/{workspace_id} Initially the status is always reported as: { \"deployment\" : { \"status\" : \"awaiting_deployment\" , \"message\" : \"This resource has not yet been deployed\" } } This should eventually change as the message flows through the system. If the message remains at this stage, you should first verify that the message arrived in the service bus. In the Azure portal: Select the Service Bus from deployed resources and click Entities > Queues > workspacequeue . Select the Service Bus Explorer and the Peek tab to check for hanging messages.","title":"Checking the Service Bus"},{"location":"troubleshooting-faq/troubleshooting-sb/#checking-the-service-bus","text":"If the message payload is accepted by the API, and a workspace_id is generated, you should be able to track the progress of the deployment using GET /api/workspaces/{workspace_id} Initially the status is always reported as: { \"deployment\" : { \"status\" : \"awaiting_deployment\" , \"message\" : \"This resource has not yet been deployed\" } } This should eventually change as the message flows through the system. If the message remains at this stage, you should first verify that the message arrived in the service bus. In the Azure portal: Select the Service Bus from deployed resources and click Entities > Queues > workspacequeue . Select the Service Bus Explorer and the Peek tab to check for hanging messages.","title":"Checking the Service Bus"},{"location":"using-tre/","text":"Using the Azure TRE This section contains information relevant on how to use AzureTRE.","title":"Introduction"},{"location":"using-tre/#using-the-azure-tre","text":"This section contains information relevant on how to use AzureTRE.","title":"Using the Azure TRE"},{"location":"using-tre/faq/","text":"FAQ Info Coming soon We're working to improve our documentation, and fill in some gaps. Unfortunately, this particular page is one of the gaps we're looking to fill and isn't yet available. How to Contribute to our Documentation If you have any comments or suggestions about our documentation then you can visit our GitHub project and either raise a new issue, or comment on one of the existing ones. You can find our existing documentation issues on GitHub by clicking on the link below: Existing Documentation Issues Or, you can raise a new issue by clicking on this link: Report an Issue or Make a Suggestion Thank you for your patience and support!","title":"FAQ"},{"location":"using-tre/faq/#faq","text":"Info Coming soon We're working to improve our documentation, and fill in some gaps. Unfortunately, this particular page is one of the gaps we're looking to fill and isn't yet available.","title":"FAQ"},{"location":"using-tre/faq/#how-to-contribute-to-our-documentation","text":"If you have any comments or suggestions about our documentation then you can visit our GitHub project and either raise a new issue, or comment on one of the existing ones. You can find our existing documentation issues on GitHub by clicking on the link below: Existing Documentation Issues Or, you can raise a new issue by clicking on this link: Report an Issue or Make a Suggestion Thank you for your patience and support!","title":"How to Contribute to our Documentation"},{"location":"using-tre/terms-definitions/","text":"Terms and Definitions Trusted Research Environments (TRE) enforce a secure boundary around distinct workspaces to enable information governance controls to be enforced. A Trusted Research Environment (typically one per organization, or one per department in large organizations) consist of: One Composition Service (API, deployment engine etc. used to manage and deploy workspaces, workspace services and user resources) One set of Shared Services used by all workspaces A number of Workspaces , where each workspace is its own security boundary, and in turn contains Workspace Services and User Resources The Composition Service The Composition Service offers an abstraction over the lower-level Azure resources to allow for TRE users to provision resources in terms of workspaces and workspace services. The Composition Service reconciles the desired state with the actual state by invoking Azure resource deployments. The composition service is fronted by an API that helps the TRE Admin, TRE Workspace Owners and TRE Researchers create and manage the workspaces and workspace services . Shared Services A service provides one or more capabilities to you as a user of the TRE or to the TRE itself. Depending on the type of the service it is scoped to the environment and shared across all workspaces (Shared Service) or scoped to a specific workspace (Workspace Service). The types of services required for a research project varies greatly why extensibility is a key aspect of the Azure TRE solution. New services can be developed by you and your organization to fit your needs. Shared Services are services and resource shared by all workspaces. These services are created once, when the TRE is deployed and managed by the TRE Administrator. Examples of shared services are: Firewall Package Mirror Git Mirror Workspace A workspace is a set of resources on a network, with inbound traffic restricted to authorised users, and outbound access restricted to defined network locations. The workspace is a security boundary and there should be zero transfer of data out from the workspace unless explicitly configured. Data transfer is not restricted within a workspace. The workspace itself contains only the bare essentials to provide this functionality, such as virtual network(s), storage etc. Workspaces can be enhanced with one or more building blocks called workspace services like Azure ML, Guacamole etc. to allow functionality such as development of machine learning models, data engineering, data analysis and software development. Multiple workspaces can be created within a single Trusted Research Environment to enable the required separation for your projects. Each workspace has workspace users : a workspace owner (normally only one), and one or more workspace researchers that can access the data and workspace services in the workspace. The workspace owner is also considered a workspace researcher. Workspace Service A workspace service is a service, created as a building block, with pre-configured set of resources that can be applied to a workspace. Examples of Workspace Services are: Guacamole (Virtual Desktops) Azure Machine Learning Unlike shared services, a workspace service is only accessible to the workspace users. Some workspace services, such as Guacamole, allow users to add on user-specific resources (user resources) All workspace services can be deployed to all workspaces. User Resource A user resource is a resource that is only available to a particular researcher. For example a virtual machine exposed by Guacamole. User resources can be deployed to workspaces with a compatible workspace service. E.g. Guacamole VMs can only be deployed to workspaces where the Guacamole workspace service is deployed. Templates In order to deploy resources (workspaces, workspace services, user resources), the resources have to be defined in templates. A template contains everything needed to create an instance of the resource. Ex. a base workspace template, or a Guacamole workspace service template. The templates describe the porter bundles used, and the input parameters needed to deploy them. To use a template, and deploy a resource, the template needs to be registered in the TRE. This is done using the TRE API. Tip Once a template is registered it can be used multiple times to deploy multiple workspaces, workspace services etc. If you want to author your own workspace, workspace service, or user resource template, consult the template authoring guide How to Contribute to our Documentation If you have any comments or suggestions about our documentation then you can visit our GitHub project and either raise a new issue, or comment on one of the existing ones. You can find our existing documentation issues on GitHub by clicking on the link below: Existing Documentation Issues Or, you can raise a new issue by clicking on this link: Report an Issue or Make a Suggestion Thank you for your patience and support!","title":"Terms and Definitions"},{"location":"using-tre/terms-definitions/#terms-and-definitions","text":"Trusted Research Environments (TRE) enforce a secure boundary around distinct workspaces to enable information governance controls to be enforced. A Trusted Research Environment (typically one per organization, or one per department in large organizations) consist of: One Composition Service (API, deployment engine etc. used to manage and deploy workspaces, workspace services and user resources) One set of Shared Services used by all workspaces A number of Workspaces , where each workspace is its own security boundary, and in turn contains Workspace Services and User Resources","title":"Terms and Definitions"},{"location":"using-tre/terms-definitions/#the-composition-service","text":"The Composition Service offers an abstraction over the lower-level Azure resources to allow for TRE users to provision resources in terms of workspaces and workspace services. The Composition Service reconciles the desired state with the actual state by invoking Azure resource deployments. The composition service is fronted by an API that helps the TRE Admin, TRE Workspace Owners and TRE Researchers create and manage the workspaces and workspace services .","title":"The Composition Service"},{"location":"using-tre/terms-definitions/#shared-services","text":"A service provides one or more capabilities to you as a user of the TRE or to the TRE itself. Depending on the type of the service it is scoped to the environment and shared across all workspaces (Shared Service) or scoped to a specific workspace (Workspace Service). The types of services required for a research project varies greatly why extensibility is a key aspect of the Azure TRE solution. New services can be developed by you and your organization to fit your needs. Shared Services are services and resource shared by all workspaces. These services are created once, when the TRE is deployed and managed by the TRE Administrator. Examples of shared services are: Firewall Package Mirror Git Mirror","title":"Shared Services"},{"location":"using-tre/terms-definitions/#workspace","text":"A workspace is a set of resources on a network, with inbound traffic restricted to authorised users, and outbound access restricted to defined network locations. The workspace is a security boundary and there should be zero transfer of data out from the workspace unless explicitly configured. Data transfer is not restricted within a workspace. The workspace itself contains only the bare essentials to provide this functionality, such as virtual network(s), storage etc. Workspaces can be enhanced with one or more building blocks called workspace services like Azure ML, Guacamole etc. to allow functionality such as development of machine learning models, data engineering, data analysis and software development. Multiple workspaces can be created within a single Trusted Research Environment to enable the required separation for your projects. Each workspace has workspace users : a workspace owner (normally only one), and one or more workspace researchers that can access the data and workspace services in the workspace. The workspace owner is also considered a workspace researcher.","title":"Workspace"},{"location":"using-tre/terms-definitions/#workspace-service","text":"A workspace service is a service, created as a building block, with pre-configured set of resources that can be applied to a workspace. Examples of Workspace Services are: Guacamole (Virtual Desktops) Azure Machine Learning Unlike shared services, a workspace service is only accessible to the workspace users. Some workspace services, such as Guacamole, allow users to add on user-specific resources (user resources) All workspace services can be deployed to all workspaces.","title":"Workspace Service"},{"location":"using-tre/terms-definitions/#user-resource","text":"A user resource is a resource that is only available to a particular researcher. For example a virtual machine exposed by Guacamole. User resources can be deployed to workspaces with a compatible workspace service. E.g. Guacamole VMs can only be deployed to workspaces where the Guacamole workspace service is deployed.","title":"User Resource"},{"location":"using-tre/terms-definitions/#templates","text":"In order to deploy resources (workspaces, workspace services, user resources), the resources have to be defined in templates. A template contains everything needed to create an instance of the resource. Ex. a base workspace template, or a Guacamole workspace service template. The templates describe the porter bundles used, and the input parameters needed to deploy them. To use a template, and deploy a resource, the template needs to be registered in the TRE. This is done using the TRE API. Tip Once a template is registered it can be used multiple times to deploy multiple workspaces, workspace services etc. If you want to author your own workspace, workspace service, or user resource template, consult the template authoring guide","title":"Templates"},{"location":"using-tre/terms-definitions/#how-to-contribute-to-our-documentation","text":"If you have any comments or suggestions about our documentation then you can visit our GitHub project and either raise a new issue, or comment on one of the existing ones. You can find our existing documentation issues on GitHub by clicking on the link below: Existing Documentation Issues Or, you can raise a new issue by clicking on this link: Report an Issue or Make a Suggestion Thank you for your patience and support!","title":"How to Contribute to our Documentation"},{"location":"using-tre/local-development/local-development/","text":"Local Development This guide will cover how to setup local development environment to add custom templates to AzureTRE and deploy AzureTRE from the local machine. Local Development Setup Prerequisites To deploy an Azure TRE instance, the following assets and tools are required: Azure subscription Azure Active Directory (AAD) tenant in which you can create application registrations Git client such as Git or GitHub Desktop Docker Desktop Development container The AzureTRE Deployment solution contains a development container with all the required tooling to develop and deploy the AzureTRE and your custom templates to it. To deploy and extend an AzureTRE instance using the provided development container you will also need: Visual Studio Code Remote containers extension for Visual Studio Code The files in AzureTRE Deployment repo for the dev container are located in /.devcontainer/ folder. Having the prerequisites and the development container, to start local development follow the next steps: Clone the project you have created from the AzureTRE Deployment template git clone <your_project> Open it in Visual Studio Code VSCode will recognize the devcontainer is set up in and will ask to reopen in Devcontainer: After the devcontainer is built, you will see the AzureTRE folder which you can use as a reference for your templates. In addition the sample.env files will be added. Local Deployment To run AzureTRE deploy locally: Open your project in VScode devcontainer. Fill in all the required configuration. Follow this guide to set it up. run make all Tip The Makefile in the AzureTRE deployment repository sources the make commands from AzureTRE that it references. This allows you to add your commands and also use the same make commands used in the AzureTRE. Having all the env vars in place: How to Contribute to our Documentation If you have any comments or suggestions about our documentation then you can visit our GitHub project and either raise a new issue, or comment on one of the existing ones. You can find our existing documentation issues on GitHub by clicking on the link below: Existing Documentation Issues Or, you can raise a new issue by clicking on this link: Report an Issue or Make a Suggestion Thank you for your patience and support!","title":"Local Development"},{"location":"using-tre/local-development/local-development/#local-development","text":"This guide will cover how to setup local development environment to add custom templates to AzureTRE and deploy AzureTRE from the local machine.","title":"Local Development"},{"location":"using-tre/local-development/local-development/#local-development-setup","text":"","title":"Local Development Setup"},{"location":"using-tre/local-development/local-development/#prerequisites","text":"To deploy an Azure TRE instance, the following assets and tools are required: Azure subscription Azure Active Directory (AAD) tenant in which you can create application registrations Git client such as Git or GitHub Desktop Docker Desktop","title":"Prerequisites"},{"location":"using-tre/local-development/local-development/#development-container","text":"The AzureTRE Deployment solution contains a development container with all the required tooling to develop and deploy the AzureTRE and your custom templates to it. To deploy and extend an AzureTRE instance using the provided development container you will also need: Visual Studio Code Remote containers extension for Visual Studio Code The files in AzureTRE Deployment repo for the dev container are located in /.devcontainer/ folder. Having the prerequisites and the development container, to start local development follow the next steps: Clone the project you have created from the AzureTRE Deployment template git clone <your_project> Open it in Visual Studio Code VSCode will recognize the devcontainer is set up in and will ask to reopen in Devcontainer: After the devcontainer is built, you will see the AzureTRE folder which you can use as a reference for your templates. In addition the sample.env files will be added.","title":"Development container"},{"location":"using-tre/local-development/local-development/#local-deployment","text":"To run AzureTRE deploy locally: Open your project in VScode devcontainer. Fill in all the required configuration. Follow this guide to set it up. run make all Tip The Makefile in the AzureTRE deployment repository sources the make commands from AzureTRE that it references. This allows you to add your commands and also use the same make commands used in the AzureTRE. Having all the env vars in place:","title":"Local Deployment"},{"location":"using-tre/local-development/local-development/#how-to-contribute-to-our-documentation","text":"If you have any comments or suggestions about our documentation then you can visit our GitHub project and either raise a new issue, or comment on one of the existing ones. You can find our existing documentation issues on GitHub by clicking on the link below: Existing Documentation Issues Or, you can raise a new issue by clicking on this link: Report an Issue or Make a Suggestion Thank you for your patience and support!","title":"How to Contribute to our Documentation"},{"location":"using-tre/templates/","text":"Creating Custom templates This document will show how to create custom templates and integrate them into your CI/CD pipelines. Templates types There are 3 types of templates: Workspace Workspace Service User Resource Read more about them here How to add custom templates AzureTRE deployment repository has directories set up for workspace, workspace service and user resource template definitions. See the template authoring guide to learn more about how to author templates. To add your custom templates follow the next steps: Deployment requirements: 1. Add your template under the relevant folder (For example: if you are adding a new workspace template then place it under /templates/workspaces folder). 2. Use existing templates in AzureTRE as a reference. 3. Add porter configuration - AzureTRE uses Porter as a solution for implementing and deploying workspaces and workspace, learn more about how it is used in AzureTRE here . 4. Add terraform scripts to set up your deployment plan. - Define resource template in the API - follow this readme to register your template. - Use the AzureTRE UI to deploy your resources - Add your custom templates to CI/CD workflows - in Deploy Azure TRE Reusable workflow make sure to add your bundles under register_bundles and publish_bundles steps. Publish and Register Custom templates in the CI/CD See the pipelines documentation to learn more about publishing and registering your custom templates as part of the CI/CD/ How to Contribute to our Documentation If you have any comments or suggestions about our documentation then you can visit our GitHub project and either raise a new issue or comment on one of the existing ones. You can find our existing documentation issues on GitHub by clicking on the link below: Existing Documentation Issues Or, you can raise a new issue by clicking on this link: Report an Issue or Make a Suggestion Thank you for your patience and support!","title":"Custom Templates"},{"location":"using-tre/templates/#creating-custom-templates","text":"This document will show how to create custom templates and integrate them into your CI/CD pipelines.","title":"Creating Custom templates"},{"location":"using-tre/templates/#templates-types","text":"There are 3 types of templates: Workspace Workspace Service User Resource Read more about them here","title":"Templates types"},{"location":"using-tre/templates/#how-to-add-custom-templates","text":"AzureTRE deployment repository has directories set up for workspace, workspace service and user resource template definitions. See the template authoring guide to learn more about how to author templates. To add your custom templates follow the next steps: Deployment requirements: 1. Add your template under the relevant folder (For example: if you are adding a new workspace template then place it under /templates/workspaces folder). 2. Use existing templates in AzureTRE as a reference. 3. Add porter configuration - AzureTRE uses Porter as a solution for implementing and deploying workspaces and workspace, learn more about how it is used in AzureTRE here . 4. Add terraform scripts to set up your deployment plan. - Define resource template in the API - follow this readme to register your template. - Use the AzureTRE UI to deploy your resources - Add your custom templates to CI/CD workflows - in Deploy Azure TRE Reusable workflow make sure to add your bundles under register_bundles and publish_bundles steps.","title":"How to add custom templates"},{"location":"using-tre/templates/#publish-and-register-custom-templates-in-the-cicd","text":"See the pipelines documentation to learn more about publishing and registering your custom templates as part of the CI/CD/","title":"Publish and Register Custom templates in the CI/CD"},{"location":"using-tre/templates/#how-to-contribute-to-our-documentation","text":"If you have any comments or suggestions about our documentation then you can visit our GitHub project and either raise a new issue or comment on one of the existing ones. You can find our existing documentation issues on GitHub by clicking on the link below: Existing Documentation Issues Or, you can raise a new issue by clicking on this link: Report an Issue or Make a Suggestion Thank you for your patience and support!","title":"How to Contribute to our Documentation"},{"location":"using-tre/tre-for-research/","text":"Using the Azure TRE for Research This section contains information relevant on how to conduct research in a TRE workspace.","title":"Introduction"},{"location":"using-tre/tre-for-research/#using-the-azure-tre-for-research","text":"This section contains information relevant on how to conduct research in a TRE workspace.","title":"Using the Azure TRE for Research"},{"location":"using-tre/tre-for-research/importing-exporting-data-airlock/","text":"Importing and exporting data with Airlock This guide will take you through the process of importing data into a TRE workspace, and exporting data from a workspace to the outside world, using the Airlock feature. The Airlock feature is intended for ad-hoc use when you need to bring in and export out files that you need for your research. It ensures that when you import or export this data all the appropriate approvals and procedures configured by your organisation take place. You can read more about the Airlock feature in the Airlock documentation . Importing data to a workspace To bring in external data to a secure TRE workspace so you can use it for your research, follow the steps outlined below. Step 1: Create a draft import request Open your TRE UI and navigate to the workspace you wish to import data into Navigate to the Airlock tab (in the left-hand menu) Click Create new and select Import Fill in a suitable Title for your request (make this short but descriptive to help you and others identify it in a list of many other requests) Provide a Business Justification for bringing the data into the workspace (this will be used to help your organisation's data stewards decide whether to approve or reject the request) Click Create when ready. This will create your draft request and allow you to proceed with adding the data you'd like to import Step 2: Add data to your import request The request you've just created should pop up automatically; however, you can return to it at any time within the Airlock page by finding it in the list of requests. (Use the My requests quick filter to find it more easily) Click Generate in the Files section to generate a Storage SAS URL to use for uploading your data. Copy the URL and use it to upload your data to the Azure Storage account. You can use several tools for this that accept SAS URLs, such as the Azure Storage Explorer, or the Azure CLI, depending on your preference. - To use Storage Explorer, follow this guide - With the Azure CLI, you can run az storage blob upload -f /path/to/file --blob-url SAS_URL . More info Warning Airlock only supports a single file per request. If you need to import multiple files, please zip them before uploading to the request's storage container. Once you've uploaded your data, head back to the TRE UI and click Submit on your draft request. This will submit your request for approval. Step 3: Get your approved data The request will be in an In Review state until it is either approved or rejected by your Airlock Manager(s) manually or by an automated workflow (depending on your organisation's specific configuration). Note Your organisation may have the Airlock Notifier service configured which will send email notifications when your request has been approved/rejected, or you may have another mechanism in place. Please check with your TRE administrator. If the request is rejected, your data will be deleted and your request will move into a Rejected state. You will be able to see feedback in the Reviews section on why your request was rejected so you can create a new request that addresses any concerns. If your request is approved, you can follow the below steps to get your data from within your workspace: Head back to your Airlock request in the TRE UI. You should find that it is now in an Approved state and ready for you to get your data. You can also see the notes from the reviewer in the Reviews section. Click Generate in the Files section to generate another Storage SAS URL which you'll use for downloading your data. Paste this link into your Workspace VM (or whichever workspace resource you're wanting to access the data from). Like before, use your preferred tool to access the data using the SAS URL, but this time to download the data. - With the Azure CLI, you can use az storage blob download --file /path/to/write/to --blob-url SAS_URL . More info Tip If you are using a Workspace VM that uses one of the standard TRE Data Science VM images, you will likely have both Storage Explorer and the Azure CLI pre-installed. Exporting data from a workspace Exporting data from a secure TRE workspace to the outside world involves similar steps to Import, but with a couple of key differences. Follow these steps: Open your TRE UI and navigate to the workspace you wish to export data from Navigate to the Airlock tab (in the left-hand menu) and click Create new , then select Export Fill in a suitable Title and Business Justification for the request then hit Create Once the draft request pop-out opens, click Generate in the Files section to generate a Storage SAS URL to use for uploading your data. You now need to head into your Workspace VM/resource containing the data you wish to export, and paste in the SAS URL you've just generated. Use your preferred storage tool to upload the data to the request container. See Step 2 in the Importing data section for more details on using these tools Once you've uploaded your data, head back to the TRE UI in your host and click Submit on your draft request. This will submit your request for approval. Like in Step 3 of Importing data , your request will be in an In Review state until it's either approved or rejected by your organisation's approval workflow. Once it's approved, head back to your request in the UI and click Generate a second time to get a download link. In your host, you can use this link with your tool of choice to download the data from the request container. How to Contribute to our Documentation Contribute to Documentation","title":"Importing/exporting data with Airlock"},{"location":"using-tre/tre-for-research/importing-exporting-data-airlock/#importing-and-exporting-data-with-airlock","text":"This guide will take you through the process of importing data into a TRE workspace, and exporting data from a workspace to the outside world, using the Airlock feature. The Airlock feature is intended for ad-hoc use when you need to bring in and export out files that you need for your research. It ensures that when you import or export this data all the appropriate approvals and procedures configured by your organisation take place. You can read more about the Airlock feature in the Airlock documentation .","title":"Importing and exporting data with Airlock"},{"location":"using-tre/tre-for-research/importing-exporting-data-airlock/#importing-data-to-a-workspace","text":"To bring in external data to a secure TRE workspace so you can use it for your research, follow the steps outlined below.","title":"Importing data to a workspace"},{"location":"using-tre/tre-for-research/importing-exporting-data-airlock/#step-1-create-a-draft-import-request","text":"Open your TRE UI and navigate to the workspace you wish to import data into Navigate to the Airlock tab (in the left-hand menu) Click Create new and select Import Fill in a suitable Title for your request (make this short but descriptive to help you and others identify it in a list of many other requests) Provide a Business Justification for bringing the data into the workspace (this will be used to help your organisation's data stewards decide whether to approve or reject the request) Click Create when ready. This will create your draft request and allow you to proceed with adding the data you'd like to import","title":"Step 1: Create a draft import request"},{"location":"using-tre/tre-for-research/importing-exporting-data-airlock/#step-2-add-data-to-your-import-request","text":"The request you've just created should pop up automatically; however, you can return to it at any time within the Airlock page by finding it in the list of requests. (Use the My requests quick filter to find it more easily) Click Generate in the Files section to generate a Storage SAS URL to use for uploading your data. Copy the URL and use it to upload your data to the Azure Storage account. You can use several tools for this that accept SAS URLs, such as the Azure Storage Explorer, or the Azure CLI, depending on your preference. - To use Storage Explorer, follow this guide - With the Azure CLI, you can run az storage blob upload -f /path/to/file --blob-url SAS_URL . More info Warning Airlock only supports a single file per request. If you need to import multiple files, please zip them before uploading to the request's storage container. Once you've uploaded your data, head back to the TRE UI and click Submit on your draft request. This will submit your request for approval.","title":"Step 2: Add data to your import request"},{"location":"using-tre/tre-for-research/importing-exporting-data-airlock/#step-3-get-your-approved-data","text":"The request will be in an In Review state until it is either approved or rejected by your Airlock Manager(s) manually or by an automated workflow (depending on your organisation's specific configuration). Note Your organisation may have the Airlock Notifier service configured which will send email notifications when your request has been approved/rejected, or you may have another mechanism in place. Please check with your TRE administrator. If the request is rejected, your data will be deleted and your request will move into a Rejected state. You will be able to see feedback in the Reviews section on why your request was rejected so you can create a new request that addresses any concerns. If your request is approved, you can follow the below steps to get your data from within your workspace: Head back to your Airlock request in the TRE UI. You should find that it is now in an Approved state and ready for you to get your data. You can also see the notes from the reviewer in the Reviews section. Click Generate in the Files section to generate another Storage SAS URL which you'll use for downloading your data. Paste this link into your Workspace VM (or whichever workspace resource you're wanting to access the data from). Like before, use your preferred tool to access the data using the SAS URL, but this time to download the data. - With the Azure CLI, you can use az storage blob download --file /path/to/write/to --blob-url SAS_URL . More info Tip If you are using a Workspace VM that uses one of the standard TRE Data Science VM images, you will likely have both Storage Explorer and the Azure CLI pre-installed.","title":"Step 3: Get your approved data"},{"location":"using-tre/tre-for-research/importing-exporting-data-airlock/#exporting-data-from-a-workspace","text":"Exporting data from a secure TRE workspace to the outside world involves similar steps to Import, but with a couple of key differences. Follow these steps: Open your TRE UI and navigate to the workspace you wish to export data from Navigate to the Airlock tab (in the left-hand menu) and click Create new , then select Export Fill in a suitable Title and Business Justification for the request then hit Create Once the draft request pop-out opens, click Generate in the Files section to generate a Storage SAS URL to use for uploading your data. You now need to head into your Workspace VM/resource containing the data you wish to export, and paste in the SAS URL you've just generated. Use your preferred storage tool to upload the data to the request container. See Step 2 in the Importing data section for more details on using these tools Once you've uploaded your data, head back to the TRE UI in your host and click Submit on your draft request. This will submit your request for approval. Like in Step 3 of Importing data , your request will be in an In Review state until it's either approved or rejected by your organisation's approval workflow. Once it's approved, head back to your request in the UI and click Generate a second time to get a download link. In your host, you can use this link with your tool of choice to download the data from the request container.","title":"Exporting data from a workspace"},{"location":"using-tre/tre-for-research/importing-exporting-data-airlock/#how-to-contribute-to-our-documentation","text":"Contribute to Documentation","title":"How to Contribute to our Documentation"},{"location":"using-tre/tre-for-research/review-airlock-request/","text":"Reviewing Airlock Requests This document is intended for a user assuming the Airlock Manager role in the workspace. It explains how to review Airlock Requests, both for data import and data export. Accessing Airlock Requests Airlock Requests page can be found under Airlock menu for the relevant workspace. The view allows to select requests \"Awaiting my review\" to quickly get to requests that need to be reviewed for this workspace. Other filters are also available by clicking on the column name. Only requests that are in in_review state can be reviewed. Reviewing a request The following steps are the same for import and export request types. Request page is available by double-clicking on one of the requests. This gives an overview of the request, including information on who created the request, the title and business justification of the request, when it was created, in what workspace, and type of the request (import or export). Reviewing menu is available by clicking on Review button at the bottom. This screen offers an option to create a VM from which the imported or exported data can be reviewed. To create a VM, click on \"Create\" button. The display will show that the VM is \"Awaiting Deployment\", and then \"Deploying\". After several minutes, the display will show that the VM is \"Running\", and a \"View Data\" button will become available. When it's clicked, a Guacamole session is opened in a new tab. On the VM, the data to review will be readily available on Desktop, in ReviewData folder. Back on the request display on the UI, there is a button \"Proceed to review\" which will show a dialogue for providing an explanation for the request decision. It must be filled in before the request can be either approved or rejected. After the decision is submitted, TRE will automatically start deletion of the VM that was created to review this request.","title":"Reviewing Airlock Requests"},{"location":"using-tre/tre-for-research/review-airlock-request/#reviewing-airlock-requests","text":"This document is intended for a user assuming the Airlock Manager role in the workspace. It explains how to review Airlock Requests, both for data import and data export.","title":"Reviewing Airlock Requests"},{"location":"using-tre/tre-for-research/review-airlock-request/#accessing-airlock-requests","text":"Airlock Requests page can be found under Airlock menu for the relevant workspace. The view allows to select requests \"Awaiting my review\" to quickly get to requests that need to be reviewed for this workspace. Other filters are also available by clicking on the column name. Only requests that are in in_review state can be reviewed.","title":"Accessing Airlock Requests"},{"location":"using-tre/tre-for-research/review-airlock-request/#reviewing-a-request","text":"The following steps are the same for import and export request types. Request page is available by double-clicking on one of the requests. This gives an overview of the request, including information on who created the request, the title and business justification of the request, when it was created, in what workspace, and type of the request (import or export). Reviewing menu is available by clicking on Review button at the bottom. This screen offers an option to create a VM from which the imported or exported data can be reviewed. To create a VM, click on \"Create\" button. The display will show that the VM is \"Awaiting Deployment\", and then \"Deploying\". After several minutes, the display will show that the VM is \"Running\", and a \"View Data\" button will become available. When it's clicked, a Guacamole session is opened in a new tab. On the VM, the data to review will be readily available on Desktop, in ReviewData folder. Back on the request display on the UI, there is a button \"Proceed to review\" which will show a dialogue for providing an explanation for the request decision. It must be filled in before the request can be either approved or rejected. After the decision is submitted, TRE will automatically start deletion of the VM that was created to review this request.","title":"Reviewing a request"},{"location":"using-tre/tre-for-research/using-vms/","text":"Set up of a Virtual Machine This document will talk you through how to deploy a Virtual Machine via the Guacamole Workspace Service and access imported data. Creating your VM Open the UI link https://<TRE_ID>.<LOCATION>.cloudapp.azure.com/ You will need the Microsoft Authenticator app on your phone. The above will take you through the set up process. Within the UI, under the Workspaces tab you should be able to see any Workspaces assigned to you. Click on the title of the Workspace to go into it. Within there should be the Guacamole Workspace Service, click the title to go into the Workspace Service. Clicking Connect will take you to the Guacamole Home Page where it will list out all of your deployed VMs. Within the Workspace Service tab, you\u2019ll need to choose Create new to create a user resource. This will be your VM. Choose the template you\u2019d like to base your VM on, at the moment the choice will be between a Windows or Linux VM. Fill in all of the details to your requirements. Once the resource is deployed, you should be able to choose Connect and view your VM in a browser. You may see a pop-up asking for guacamole to have permission to use your clipboard, please allow that. Accessing Data You may have data pre-provisioned into your workspace, or you may import data via the airlock. Starting and Stopping your VM When you are no longer using a VM, it is good practice to stop it so that the VM is deallocated and no unnecessary costs will be applied. To do this, navigate to the UI and find your VM. Click on the three small dots in the top right of the user resource card and choose Actions and then Stop. It will take a few minutes to take effect and the card should then display 'VM deallocated'. The same steps can be followed to Start your VM. Deleting your VM If you no longer wish to use the VM you have created there is an option to delete it. First you'll need to disable the VM, similar to above when stopping it: Click on the three small dots in the top right and choose Disable. Once it is disabled (this can take a few minutes), click on the three dots again and you should then have the option to delete it. VM Actions Whilst the VM is currently updating due to an invoked action it will display a message similar to the one below. This will occur any time a service or user resource is deployed, disabled, deleted etc. You can also view any current operations by clicking on the bell in the top right hand corner of the screen. How to Contribute to our Documentation Contribute to Documentation","title":"Set up of a Virtual Machine"},{"location":"using-tre/tre-for-research/using-vms/#set-up-of-a-virtual-machine","text":"This document will talk you through how to deploy a Virtual Machine via the Guacamole Workspace Service and access imported data.","title":"Set up of a Virtual Machine"},{"location":"using-tre/tre-for-research/using-vms/#creating-your-vm","text":"Open the UI link https://<TRE_ID>.<LOCATION>.cloudapp.azure.com/ You will need the Microsoft Authenticator app on your phone. The above will take you through the set up process. Within the UI, under the Workspaces tab you should be able to see any Workspaces assigned to you. Click on the title of the Workspace to go into it. Within there should be the Guacamole Workspace Service, click the title to go into the Workspace Service. Clicking Connect will take you to the Guacamole Home Page where it will list out all of your deployed VMs. Within the Workspace Service tab, you\u2019ll need to choose Create new to create a user resource. This will be your VM. Choose the template you\u2019d like to base your VM on, at the moment the choice will be between a Windows or Linux VM. Fill in all of the details to your requirements. Once the resource is deployed, you should be able to choose Connect and view your VM in a browser. You may see a pop-up asking for guacamole to have permission to use your clipboard, please allow that.","title":"Creating your VM"},{"location":"using-tre/tre-for-research/using-vms/#accessing-data","text":"You may have data pre-provisioned into your workspace, or you may import data via the airlock.","title":"Accessing Data"},{"location":"using-tre/tre-for-research/using-vms/#starting-and-stopping-your-vm","text":"When you are no longer using a VM, it is good practice to stop it so that the VM is deallocated and no unnecessary costs will be applied. To do this, navigate to the UI and find your VM. Click on the three small dots in the top right of the user resource card and choose Actions and then Stop. It will take a few minutes to take effect and the card should then display 'VM deallocated'. The same steps can be followed to Start your VM.","title":"Starting and Stopping your VM"},{"location":"using-tre/tre-for-research/using-vms/#deleting-your-vm","text":"If you no longer wish to use the VM you have created there is an option to delete it. First you'll need to disable the VM, similar to above when stopping it: Click on the three small dots in the top right and choose Disable. Once it is disabled (this can take a few minutes), click on the three dots again and you should then have the option to delete it.","title":"Deleting your VM"},{"location":"using-tre/tre-for-research/using-vms/#vm-actions","text":"Whilst the VM is currently updating due to an invoked action it will display a message similar to the one below. This will occur any time a service or user resource is deployed, disabled, deleted etc. You can also view any current operations by clicking on the bell in the top right hand corner of the screen.","title":"VM Actions"},{"location":"using-tre/tre-for-research/using-vms/#how-to-contribute-to-our-documentation","text":"Contribute to Documentation","title":"How to Contribute to our Documentation"},{"location":"using-tre/wks/","text":"Workspaces Info Coming soon We're working to improve our documentation, and fill in some gaps. Unfortunately, this particular page is one of the gaps we're looking to fill and isn't yet available. How to Contribute to our Documentation If you have any comments or suggestions about our documentation then you can visit our GitHub project and either raise a new issue, or comment on one of the existing ones. You can find our existing documentation issues on GitHub by clicking on the link below: Existing Documentation Issues Or, you can raise a new issue by clicking on this link: Report an Issue or Make a Suggestion Thank you for your patience and support!","title":"Workspaces"},{"location":"using-tre/wks/#workspaces","text":"Info Coming soon We're working to improve our documentation, and fill in some gaps. Unfortunately, this particular page is one of the gaps we're looking to fill and isn't yet available.","title":"Workspaces"},{"location":"using-tre/wks/#how-to-contribute-to-our-documentation","text":"If you have any comments or suggestions about our documentation then you can visit our GitHub project and either raise a new issue, or comment on one of the existing ones. You can find our existing documentation issues on GitHub by clicking on the link below: Existing Documentation Issues Or, you can raise a new issue by clicking on this link: Report an Issue or Make a Suggestion Thank you for your patience and support!","title":"How to Contribute to our Documentation"},{"location":"using-tre/wks/using-wks/","text":"Using Workspaces Info Coming soon We're working to improve our documentation, and fill in some gaps. Unfortunately, this particular page is one of the gaps we're looking to fill and isn't yet available. How to Contribute to our Documentation If you have any comments or suggestions about our documentation then you can visit our GitHub project and either raise a new issue, or comment on one of the existing ones. You can find our existing documentation issues on GitHub by clicking on the link below: Existing Documentation Issues Or, you can raise a new issue by clicking on this link: Report an Issue or Make a Suggestion Thank you for your patience and support!","title":"Using Workspaces"},{"location":"using-tre/wks/using-wks/#using-workspaces","text":"Info Coming soon We're working to improve our documentation, and fill in some gaps. Unfortunately, this particular page is one of the gaps we're looking to fill and isn't yet available.","title":"Using Workspaces"},{"location":"using-tre/wks/using-wks/#how-to-contribute-to-our-documentation","text":"If you have any comments or suggestions about our documentation then you can visit our GitHub project and either raise a new issue, or comment on one of the existing ones. You can find our existing documentation issues on GitHub by clicking on the link below: Existing Documentation Issues Or, you can raise a new issue by clicking on this link: Report an Issue or Make a Suggestion Thank you for your patience and support!","title":"How to Contribute to our Documentation"},{"location":"using-tre/wks/wks-owner/","text":"Workspace Owners Info Coming soon We're working to improve our documentation, and fill in some gaps. Unfortunately, this particular page is one of the gaps we're looking to fill and isn't yet available. How to Contribute to our Documentation If you have any comments or suggestions about our documentation then you can visit our GitHub project and either raise a new issue, or comment on one of the existing ones. You can find our existing documentation issues on GitHub by clicking on the link below: Existing Documentation Issues Or, you can raise a new issue by clicking on this link: Report an Issue or Make a Suggestion Thank you for your patience and support!","title":"Workspace Owners"},{"location":"using-tre/wks/wks-owner/#workspace-owners","text":"Info Coming soon We're working to improve our documentation, and fill in some gaps. Unfortunately, this particular page is one of the gaps we're looking to fill and isn't yet available.","title":"Workspace Owners"},{"location":"using-tre/wks/wks-owner/#how-to-contribute-to-our-documentation","text":"If you have any comments or suggestions about our documentation then you can visit our GitHub project and either raise a new issue, or comment on one of the existing ones. You can find our existing documentation issues on GitHub by clicking on the link below: Existing Documentation Issues Or, you can raise a new issue by clicking on this link: Report an Issue or Make a Suggestion Thank you for your patience and support!","title":"How to Contribute to our Documentation"}]}